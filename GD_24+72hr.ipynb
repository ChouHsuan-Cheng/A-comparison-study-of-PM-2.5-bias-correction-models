{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a72127d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch ver .  1.11.0+cu113\n",
      "Is CUDA available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luhung3080/miniconda3/envs/chou/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "print(\"pytorch ver . \",torch.__version__)\n",
    "print(\"Is CUDA available?\",torch.cuda.is_available())\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce9915",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59b70f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('/home/luhung3080/Desktop/PycharmProjects/NCHUproject/Transformer/data_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55c760f",
   "metadata": {},
   "source": [
    "# Generate X Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef166d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(604, 1704)\n",
      "(604, 5112)\n"
     ]
    }
   ],
   "source": [
    "x1=np.zeros([604,1704])\n",
    "x2=np.zeros([604,5112])\n",
    "\n",
    "#x1 (0th~1703th column as x)\n",
    "for i in range (0,604):\n",
    "    for j in range (0,71):\n",
    "        a=np.array(data['pm25_obs'][5112*i+72*j:5112*i+72*j+24])\n",
    "        for k in range (0,24):\n",
    "            x1[i][j*24+k]=a[k]\n",
    "\n",
    "#x2 (1704th~8519th column as x)\n",
    "for i in range (1,604):\n",
    "    b=np.array(data['pm25_cal'][5112*i:5112*i+5112])\n",
    "    for j in range(0,5112):\n",
    "        x2[i-1][j]=b[j]\n",
    "        \n",
    "print(np.shape(x1))\n",
    "print(np.shape(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63cbbb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(604, 1704)\n",
      "(604, 5112)\n"
     ]
    }
   ],
   "source": [
    "x1Restruct_Fun=x1\n",
    "x2Restruct_Fun=x2\n",
    "print(np.shape(x1Restruct_Fun))\n",
    "print(np.shape(x2Restruct_Fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e320247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(601, 5112)\n"
     ]
    }
   ],
   "source": [
    "YRestruct_Fun=np.zeros([601,5112])\n",
    "for j in range (0,71):\n",
    "    for i in range(0,601):\n",
    "        YRestruct_Fun[i][72*j:72*j+24]=x1Restruct_Fun[1+i][24*j:24*j+24]\n",
    "        YRestruct_Fun[i][72*j+24:72*j+48]=x1Restruct_Fun[1+i+1][24*j:24*j+24]\n",
    "        YRestruct_Fun[i][72*j+48:72*j+72]=x1Restruct_Fun[1+i+2][24*j:24*j+24]\n",
    "print(np.shape(YRestruct_Fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0e49fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(601, 6816)\n"
     ]
    }
   ],
   "source": [
    "XRestruct_Fun=np.zeros([601,6816])\n",
    "for i in range (0,601):\n",
    "    for j in range (0,1704):\n",
    "        XRestruct_Fun[i][j]=x1Restruct_Fun[i][j]\n",
    "    for j in range (1704,6816):\n",
    "        XRestruct_Fun[i][j]=x2Restruct_Fun[i][j-1704]\n",
    "print(np.shape(XRestruct_Fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af55b387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1hat_train\n",
      "(540, 1704)\n",
      "X2hat_train\n",
      "(540, 5112)\n",
      "Yhat_train\n",
      "(540, 5112)\n",
      "X1hat_test\n",
      "(61, 1704)\n",
      "X2hat_test\n",
      "(61, 5112)\n",
      "Yhat_test\n",
      "(61, 5112)\n"
     ]
    }
   ],
   "source": [
    "Xhat=XRestruct_Fun\n",
    "Yhat=YRestruct_Fun\n",
    "X1hat_train = np.zeros([540,1704])\n",
    "X2hat_train = np.zeros([540,5112])\n",
    "Yhat_train = np.zeros([540,5112])\n",
    "X1hat_test = np.zeros([61,1704])\n",
    "X2hat_test = np.zeros([61,5112])\n",
    "Yhat_test = np.zeros([61,5112])\n",
    "for i in range (0,540):\n",
    "    for j in range (0,1704):\n",
    "        X1hat_train[i][j] = Xhat[i][j]\n",
    "    for j in range (1704,6816):\n",
    "        X2hat_train[i][j-1704] = Xhat[i][j]\n",
    "    for j in range (0,5112):\n",
    "        Yhat_train[i][j] = Yhat[i][j]\n",
    "for i in range (540,601):\n",
    "    for j in range (0,1704):\n",
    "        X1hat_test[i-540][j] = Xhat[i][j]    \n",
    "    for j in range (1704,6816):\n",
    "        X2hat_test[i-540][j-1704] = Xhat[i][j]\n",
    "    for j in range (0,5112):     \n",
    "        Yhat_test[i-540][j] = Yhat[i][j]\n",
    "        \n",
    "print('X1hat_train')\n",
    "#print(X1hat_train)\n",
    "print(np.shape(X1hat_train))\n",
    "print('X2hat_train')\n",
    "#print(X2hat_train)\n",
    "print(np.shape(X2hat_train))\n",
    "print('Yhat_train')\n",
    "#print(Yhat_train)\n",
    "print(np.shape(Yhat_train))\n",
    "print('X1hat_test')\n",
    "#print(X1hat_test)\n",
    "print(np.shape(X1hat_test))\n",
    "print('X2hat_test')\n",
    "#print(X2hat_test)\n",
    "print(np.shape(X2hat_test))\n",
    "print('Yhat_test')\n",
    "#print(Yhat_test)\n",
    "print(np.shape(Yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2197b8e",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66629602",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = X1hat_train\n",
    "x2 = X2hat_train\n",
    "y = Yhat_train\n",
    "xt1 = X1hat_test\n",
    "xt2 = X2hat_test\n",
    "yt = Yhat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54d3e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model (x1,x2,b0,b1,b2):\n",
    "    y = b0 +  torch.matmul(x1,b1) + torch.matmul(x2,b2)\n",
    "#    y = b0 + torch.matmul(x2,b2)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10fc4656",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training loss 94251.3672, Testing loss 99211.3229\n",
      "Epoch 1, Training loss 94157.1016, Testing loss 99112.0035\n",
      "Epoch 2, Training loss 94062.8438, Testing loss 99012.6836\n",
      "Epoch 3, Training loss 93968.5703, Testing loss 98913.3581\n",
      "Epoch 4, Training loss 93874.3125, Testing loss 98814.0281\n",
      "Epoch 5, Training loss 93780.0391, Testing loss 98714.7157\n",
      "Epoch 6, Training loss 93685.7812, Testing loss 98615.4018\n",
      "Epoch 7, Training loss 93591.5312, Testing loss 98516.0701\n",
      "Epoch 8, Training loss 93497.2500, Testing loss 98416.7487\n",
      "Epoch 9, Training loss 93402.9844, Testing loss 98317.4209\n",
      "Epoch 10, Training loss 93308.7188, Testing loss 98218.1048\n",
      "Epoch 20, Training loss 92366.0625, Testing loss 97224.9121\n",
      "Epoch 30, Training loss 91423.4141, Testing loss 96231.6494\n",
      "Epoch 40, Training loss 90480.7656, Testing loss 95238.4402\n",
      "Epoch 50, Training loss 89538.1016, Testing loss 94245.2122\n",
      "Epoch 60, Training loss 88595.4609, Testing loss 93251.9930\n",
      "Epoch 70, Training loss 87652.8125, Testing loss 92258.7816\n",
      "Epoch 80, Training loss 86710.1484, Testing loss 91265.5516\n",
      "Epoch 90, Training loss 85767.5000, Testing loss 90272.3267\n",
      "Epoch 100, Training loss 84824.8438, Testing loss 89279.1033\n",
      "Epoch 110, Training loss 83882.1953, Testing loss 88285.8787\n",
      "Epoch 120, Training loss 82939.5625, Testing loss 87292.6604\n",
      "Epoch 130, Training loss 81996.8984, Testing loss 86299.4366\n",
      "Epoch 140, Training loss 81054.2422, Testing loss 85306.2196\n",
      "Epoch 150, Training loss 80111.5938, Testing loss 84312.9909\n",
      "Epoch 160, Training loss 79168.9375, Testing loss 83319.7766\n",
      "Epoch 170, Training loss 78226.2891, Testing loss 82326.5502\n",
      "Epoch 180, Training loss 77283.6328, Testing loss 81333.3321\n",
      "Epoch 190, Training loss 76340.9688, Testing loss 80340.1063\n",
      "Epoch 200, Training loss 75398.3281, Testing loss 79346.8876\n",
      "Epoch 210, Training loss 74455.6797, Testing loss 78353.6717\n",
      "Epoch 220, Training loss 73513.0234, Testing loss 77360.4498\n",
      "Epoch 230, Training loss 72570.3750, Testing loss 76367.2197\n",
      "Epoch 240, Training loss 71627.7109, Testing loss 75374.0112\n",
      "Epoch 250, Training loss 70685.0547, Testing loss 74380.7829\n",
      "Epoch 260, Training loss 69742.4219, Testing loss 73387.5525\n",
      "Epoch 270, Training loss 68799.7734, Testing loss 72394.3427\n",
      "Epoch 280, Training loss 67857.1172, Testing loss 71401.1138\n",
      "Epoch 290, Training loss 66914.4609, Testing loss 70407.8920\n",
      "Epoch 300, Training loss 65971.8125, Testing loss 69414.6690\n",
      "Epoch 310, Training loss 65029.1562, Testing loss 68421.4485\n",
      "Epoch 320, Training loss 64086.5000, Testing loss 67428.2224\n",
      "Epoch 330, Training loss 63143.8477, Testing loss 66435.0053\n",
      "Epoch 340, Training loss 62201.2031, Testing loss 65441.7847\n",
      "Epoch 350, Training loss 61258.5430, Testing loss 64448.5599\n",
      "Epoch 360, Training loss 60315.8984, Testing loss 63455.3405\n",
      "Epoch 370, Training loss 59373.2344, Testing loss 62462.1152\n",
      "Epoch 380, Training loss 58430.5938, Testing loss 61468.8972\n",
      "Epoch 390, Training loss 57487.9414, Testing loss 60475.6808\n",
      "Epoch 400, Training loss 56545.2773, Testing loss 59482.4536\n",
      "Epoch 410, Training loss 55602.6289, Testing loss 58489.2298\n",
      "Epoch 420, Training loss 54659.9727, Testing loss 57496.0065\n",
      "Epoch 430, Training loss 53717.3320, Testing loss 56502.7866\n",
      "Epoch 440, Training loss 52774.6680, Testing loss 55509.5552\n",
      "Epoch 450, Training loss 51832.0156, Testing loss 54516.3403\n",
      "Epoch 460, Training loss 50889.3711, Testing loss 53523.1225\n",
      "Epoch 470, Training loss 49946.7188, Testing loss 52529.9003\n",
      "Epoch 480, Training loss 49004.0664, Testing loss 51536.6758\n",
      "Epoch 490, Training loss 48061.4141, Testing loss 50543.4530\n",
      "Epoch 500, Training loss 47118.7656, Testing loss 49550.2317\n",
      "Epoch 510, Training loss 46176.1016, Testing loss 48557.0099\n",
      "Epoch 520, Training loss 45233.4531, Testing loss 47563.7788\n",
      "Epoch 530, Training loss 44290.8008, Testing loss 46570.5655\n",
      "Epoch 540, Training loss 43348.1523, Testing loss 45577.3448\n",
      "Epoch 550, Training loss 42405.4922, Testing loss 44584.1260\n",
      "Epoch 560, Training loss 41462.8438, Testing loss 43590.9022\n",
      "Epoch 570, Training loss 40520.1914, Testing loss 42597.6803\n",
      "Epoch 580, Training loss 39577.5391, Testing loss 41604.4553\n",
      "Epoch 590, Training loss 38634.8867, Testing loss 40611.2369\n",
      "Epoch 600, Training loss 37692.2383, Testing loss 39618.0102\n",
      "Epoch 610, Training loss 36749.5820, Testing loss 38624.7998\n",
      "Epoch 620, Training loss 35806.9336, Testing loss 37631.5734\n",
      "Epoch 630, Training loss 34864.2812, Testing loss 36638.3496\n",
      "Epoch 640, Training loss 33921.6289, Testing loss 35645.1353\n",
      "Epoch 650, Training loss 32978.9766, Testing loss 34651.9061\n",
      "Epoch 660, Training loss 32036.3203, Testing loss 33658.6851\n",
      "Epoch 670, Training loss 31093.6719, Testing loss 32665.4633\n",
      "Epoch 680, Training loss 30151.0156, Testing loss 31672.2402\n",
      "Epoch 690, Training loss 29208.3672, Testing loss 30679.0172\n",
      "Epoch 700, Training loss 28265.7148, Testing loss 29685.7977\n",
      "Epoch 710, Training loss 27323.0605, Testing loss 28692.5789\n",
      "Epoch 720, Training loss 26380.4082, Testing loss 27699.3522\n",
      "Epoch 730, Training loss 25437.7578, Testing loss 26706.1329\n",
      "Epoch 740, Training loss 24495.1094, Testing loss 25712.9095\n",
      "Epoch 750, Training loss 23552.4512, Testing loss 24719.6873\n",
      "Epoch 760, Training loss 22609.7930, Testing loss 23726.4576\n",
      "Epoch 770, Training loss 21667.1387, Testing loss 22733.2304\n",
      "Epoch 780, Training loss 20724.4785, Testing loss 21740.0043\n",
      "Epoch 790, Training loss 19781.8184, Testing loss 20746.7747\n",
      "Epoch 800, Training loss 18839.1602, Testing loss 19753.5463\n",
      "Epoch 810, Training loss 17896.5039, Testing loss 18760.3169\n",
      "Epoch 820, Training loss 16953.8438, Testing loss 17767.0902\n",
      "Epoch 830, Training loss 16011.1875, Testing loss 16773.8621\n",
      "Epoch 840, Training loss 15068.5283, Testing loss 15780.6339\n",
      "Epoch 850, Training loss 14125.8691, Testing loss 14787.4058\n",
      "Epoch 860, Training loss 13183.2139, Testing loss 13794.1777\n",
      "Epoch 870, Training loss 12240.5527, Testing loss 12800.9500\n",
      "Epoch 880, Training loss 11297.8955, Testing loss 11807.7219\n",
      "Epoch 890, Training loss 10355.2383, Testing loss 10814.4933\n",
      "Epoch 900, Training loss 9412.5801, Testing loss 9821.2663\n",
      "Epoch 910, Training loss 8469.9229, Testing loss 8828.0384\n",
      "Epoch 920, Training loss 7527.2637, Testing loss 7834.8116\n",
      "Epoch 930, Training loss 6584.6064, Testing loss 6841.5834\n",
      "Epoch 940, Training loss 5641.9482, Testing loss 5848.3558\n",
      "Epoch 950, Training loss 4699.2900, Testing loss 4855.1276\n",
      "Epoch 960, Training loss 3756.6323, Testing loss 3861.8997\n",
      "Epoch 970, Training loss 2813.9741, Testing loss 2868.6717\n",
      "Epoch 980, Training loss 1871.3162, Testing loss 1875.4437\n",
      "Epoch 990, Training loss 928.6579, Testing loss 882.2158\n",
      "Epoch 1000, Training loss 14.0086, Testing loss 91.3021\n",
      "Epoch 1010, Training loss 177.4473, Testing loss 146.9759\n",
      "Epoch 1020, Training loss 98.3084, Testing loss 87.1531\n",
      "Epoch 1030, Training loss 19.2719, Testing loss 17.6618\n",
      "Epoch 1040, Training loss 23.0043, Testing loss 8.4666\n",
      "Epoch 1050, Training loss 9.7066, Testing loss 14.2362\n",
      "Epoch 1060, Training loss 8.8296, Testing loss 7.0390\n",
      "Epoch 1070, Training loss 5.8946, Testing loss 7.0061\n",
      "Epoch 1080, Training loss 5.2556, Testing loss 5.6471\n",
      "Epoch 1090, Training loss 4.8023, Testing loss 5.2154\n",
      "Epoch 1100, Training loss 4.5145, Testing loss 5.0303\n",
      "Epoch 1110, Training loss 4.2937, Testing loss 4.9766\n",
      "Epoch 1120, Training loss 4.1187, Testing loss 5.0050\n",
      "Epoch 1130, Training loss 3.9957, Testing loss 5.0180\n",
      "Epoch 1140, Training loss 3.8956, Testing loss 5.0500\n",
      "Epoch 1150, Training loss 3.8234, Testing loss 5.0949\n",
      "Epoch 1160, Training loss 3.7711, Testing loss 5.1399\n",
      "Epoch 1170, Training loss 3.7142, Testing loss 5.1861\n",
      "Epoch 1180, Training loss 3.7143, Testing loss 5.2536\n",
      "Epoch 1190, Training loss 3.6931, Testing loss 5.3197\n",
      "Epoch 1200, Training loss 3.7289, Testing loss 5.4257\n",
      "Epoch 1210, Training loss 3.7541, Testing loss 5.4869\n",
      "Epoch 1220, Training loss 3.8222, Testing loss 5.6161\n",
      "Epoch 1230, Training loss 3.8950, Testing loss 5.7232\n",
      "Epoch 1240, Training loss 3.9854, Testing loss 5.8379\n",
      "Epoch 1250, Training loss 4.0543, Testing loss 5.9314\n",
      "Epoch 1260, Training loss 4.1420, Testing loss 6.0605\n",
      "Epoch 1270, Training loss 4.2895, Testing loss 6.1844\n",
      "Epoch 1280, Training loss 4.4010, Testing loss 6.3343\n",
      "Epoch 1290, Training loss 4.5209, Testing loss 6.4707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1300, Training loss 4.6463, Testing loss 6.5533\n",
      "Epoch 1310, Training loss 4.7598, Testing loss 6.7171\n",
      "Epoch 1320, Training loss 4.9274, Testing loss 6.8070\n",
      "Epoch 1330, Training loss 4.9417, Testing loss 6.8947\n",
      "Epoch 1340, Training loss 5.1124, Testing loss 6.9655\n",
      "Epoch 1350, Training loss 5.2051, Testing loss 7.1257\n",
      "Epoch 1360, Training loss 5.2191, Testing loss 7.1722\n",
      "Epoch 1370, Training loss 5.3030, Testing loss 7.2666\n",
      "Epoch 1380, Training loss 5.4309, Testing loss 7.3878\n",
      "Epoch 1390, Training loss 5.3960, Testing loss 7.3938\n",
      "Epoch 1400, Training loss 5.4279, Testing loss 7.3925\n",
      "Epoch 1410, Training loss 5.5086, Testing loss 7.4695\n",
      "Epoch 1420, Training loss 5.5795, Testing loss 7.5880\n",
      "Epoch 1430, Training loss 5.6629, Testing loss 7.5991\n",
      "Epoch 1440, Training loss 5.6940, Testing loss 7.6627\n",
      "Epoch 1450, Training loss 5.6699, Testing loss 7.7053\n",
      "Epoch 1460, Training loss 5.7150, Testing loss 7.7440\n",
      "Epoch 1470, Training loss 5.7346, Testing loss 7.7366\n",
      "Epoch 1480, Training loss 5.8456, Testing loss 7.8183\n",
      "Epoch 1490, Training loss 5.8364, Testing loss 7.8068\n",
      "Epoch 1500, Training loss 5.8907, Testing loss 7.9086\n",
      "Epoch 1510, Training loss 5.8656, Testing loss 7.9421\n",
      "Epoch 1520, Training loss 5.9115, Testing loss 7.9921\n",
      "Epoch 1530, Training loss 5.9486, Testing loss 7.9780\n",
      "Epoch 1540, Training loss 5.9283, Testing loss 8.1370\n",
      "Epoch 1550, Training loss 5.9762, Testing loss 8.0329\n",
      "Epoch 1560, Training loss 6.0427, Testing loss 8.1550\n",
      "Epoch 1570, Training loss 6.0535, Testing loss 8.1909\n",
      "Epoch 1580, Training loss 6.1403, Testing loss 8.2460\n",
      "Epoch 1590, Training loss 6.1667, Testing loss 8.2239\n",
      "Epoch 1600, Training loss 6.1832, Testing loss 8.3991\n",
      "Epoch 1610, Training loss 6.3148, Testing loss 8.3749\n",
      "Epoch 1620, Training loss 6.3968, Testing loss 8.4401\n",
      "Epoch 1630, Training loss 6.3890, Testing loss 8.4733\n",
      "Epoch 1640, Training loss 6.4506, Testing loss 8.4655\n",
      "Epoch 1650, Training loss 6.4744, Testing loss 8.5531\n",
      "Epoch 1660, Training loss 6.5519, Testing loss 8.5664\n",
      "Epoch 1670, Training loss 6.4455, Testing loss 8.5899\n",
      "Epoch 1680, Training loss 6.5948, Testing loss 8.6224\n",
      "Epoch 1690, Training loss 6.5965, Testing loss 8.6940\n",
      "Epoch 1700, Training loss 6.5781, Testing loss 8.6902\n",
      "Epoch 1710, Training loss 6.6906, Testing loss 8.7839\n",
      "Epoch 1720, Training loss 6.7307, Testing loss 8.7951\n",
      "Epoch 1730, Training loss 6.6746, Testing loss 8.7900\n",
      "Epoch 1740, Training loss 6.8274, Testing loss 8.7883\n",
      "Epoch 1750, Training loss 6.7317, Testing loss 8.8460\n",
      "Epoch 1760, Training loss 6.7519, Testing loss 8.8692\n",
      "Epoch 1770, Training loss 6.8454, Testing loss 8.9146\n",
      "Epoch 1780, Training loss 6.8308, Testing loss 8.8960\n",
      "Epoch 1790, Training loss 6.7726, Testing loss 8.9294\n",
      "Epoch 1800, Training loss 6.9232, Testing loss 8.9227\n",
      "Epoch 1810, Training loss 6.8302, Testing loss 8.9509\n",
      "Epoch 1820, Training loss 6.8884, Testing loss 8.9415\n",
      "Epoch 1830, Training loss 6.9466, Testing loss 9.0902\n",
      "Epoch 1840, Training loss 6.9129, Testing loss 9.0212\n",
      "Epoch 1850, Training loss 6.8317, Testing loss 9.0390\n",
      "Epoch 1860, Training loss 6.9763, Testing loss 9.1411\n",
      "Epoch 1870, Training loss 6.9951, Testing loss 9.1240\n",
      "Epoch 1880, Training loss 6.9339, Testing loss 9.0573\n",
      "Epoch 1890, Training loss 7.0429, Testing loss 9.3377\n",
      "Epoch 1900, Training loss 7.1199, Testing loss 9.1998\n",
      "Epoch 1910, Training loss 7.0545, Testing loss 9.1481\n",
      "Epoch 1920, Training loss 7.0805, Testing loss 9.2885\n",
      "Epoch 1930, Training loss 7.0901, Testing loss 9.2720\n",
      "Epoch 1940, Training loss 7.0815, Testing loss 9.1974\n",
      "Epoch 1950, Training loss 7.1305, Testing loss 9.2624\n",
      "Epoch 1960, Training loss 7.1333, Testing loss 9.3373\n",
      "Epoch 1970, Training loss 7.2028, Testing loss 9.2707\n",
      "Epoch 1980, Training loss 7.1600, Testing loss 9.4022\n",
      "Epoch 1990, Training loss 7.2833, Testing loss 9.3249\n",
      "Epoch 1991, Training loss 7.1991, Testing loss 9.3780\n",
      "Epoch 1992, Training loss 7.2340, Testing loss 9.4340\n",
      "Epoch 1993, Training loss 7.2833, Testing loss 9.3966\n",
      "Epoch 1994, Training loss 7.2407, Testing loss 9.3877\n",
      "Epoch 1995, Training loss 7.2341, Testing loss 9.4173\n",
      "Epoch 1996, Training loss 7.2609, Testing loss 9.3781\n",
      "Epoch 1997, Training loss 7.2454, Testing loss 9.4015\n",
      "Epoch 1998, Training loss 7.2669, Testing loss 9.4147\n",
      "Epoch 1999, Training loss 7.2823, Testing loss 9.3511\n",
      "Epoch 2000, Training loss 7.2028, Testing loss 9.4102\n"
     ]
    }
   ],
   "source": [
    "features1 = torch.from_numpy(x1)\n",
    "features2 = torch.from_numpy(x2)\n",
    "targets = torch.from_numpy(y)\n",
    "x_test1 = torch.from_numpy(xt1)\n",
    "x_test2 = torch.from_numpy(xt2)\n",
    "y_test = torch.from_numpy(yt)\n",
    "\n",
    "\n",
    "beta0 = torch.ones(5112 , requires_grad = True)\n",
    "beta1 = torch.ones([1704,5112], requires_grad = True)\n",
    "beta2 = torch.ones([5112,5112], requires_grad = True)\n",
    "#beta2 = torch.ones([6816,5112], requires_grad = True)\n",
    "\n",
    "rate = 1e-3\n",
    "optimizer = optim.Adam([beta0 , beta1 , beta2], lr=rate)\n",
    "\n",
    "epo = 2001\n",
    "loss = nn.L1Loss()\n",
    "train_error = np.zeros(epo)\n",
    "test_error = np.zeros(epo)\n",
    "\n",
    "\n",
    "for epoch in range (epo):\n",
    "    yhats_train = model(features1.float() , features2.float(), beta0 , beta1 , beta2)\n",
    "    train_loss = loss(targets.float() , yhats_train)\n",
    "    train_error[epoch] = train_loss\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward() \n",
    "    optimizer.step()    \n",
    "\n",
    "    yhats_test = model(x_test1.float(), x_test2.float() , beta0, beta1 , beta2) \n",
    "    r = torch.abs(yhats_test - y_test)\n",
    "    test_loss = torch.mean(r)\n",
    "    test_error[epoch] = test_loss\n",
    "\n",
    "    if epoch <= 10 or epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\n",
    "                    f\" Testing loss {test_loss.item():.4f}\")      \n",
    "    else :\n",
    "        if epoch >= epo-10 :\n",
    "            print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\n",
    "                        f\" Testing loss {test_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1da028",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8801557b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAs0klEQVR4nO3deXiU9bnG8e+TPSGEBAgICcgqyA6ZAq4FN8AN3EEhWC2gqLhWUWu19mi19dTWKiKoVdQqKFqxRREXjlZFDIvsSFiUIEsMEDYTsvzOH/MGh5hA9slyf65rrsz83mWevEnmzrvMM+acQ0REpCQhwS5ARERqL4WEiIiUSiEhIiKlUkiIiEipFBIiIlIqhYSIiJRKISEiIqVSSIhUkJltNrNDZta82PhSM3Nm1i5g7AFvbECxea82swIz21/s1rqGvg2Ro1JIiFTOJmBU0QMz6wnEBM5gZgakAru8r8V94ZyLLXb7vjqLFikrhYRI5bzEkS/8Y4EZxeY5DWgFTAJGmllEDdUmUmkKCZHKWQjEmdmJZhYKjAReLjbPWOAdYJb3+IIarE+kUhQSIpVXtDdxNrAG2Fo0wcxigMuAfzrn8oA3+Pkhp4FmtifgtqGG6hY5prBgFyBSD7wEfAK05+eHmi4C8oG53uNXgA/MLNE5l+mNLXTOnVojlYqUk/YkRCrJOfct/hPY5wJvFps8FogFvjOz7cDrQDhwZY0WKVJB2pMQqRrXAgnOuQNmVvR3lQScCQwDlgfMewv+Q05/q9EKRSpAISFSBZxzJZ1HOA1Y5px7P3DQzJ4AbjezHt7QSWa2v9iyg51zX1VDqSLlYvrQIRERKY3OSYiISKkUEiIiUiqFhIiIlEohISIipap3Vzc1b97ctWvXLthliIjUKYsXL/7BOZdYfLzehUS7du1IS0sLdhkiInWKmX1b0rgON4mISKkUEiIiUiqFhIiIlKrenZMoSV5eHhkZGeTk5AS7lFotKiqK5ORkwsPDg12KiNQSxwwJM3seOB/Y6Zzr4Y01BWYC7YDNwOXOud3exzT+DX83zIPA1c65Jd4yY4Hfeqv9H+fci954CvACEI2/nfLNzjlX2nNU5JvMyMigcePGtGvXDn+JUpxzjqysLDIyMmjfvn2wyxGRWqIsh5teAIYWG5sMfOic6wx86D0Gf7fLzt5tPPA0HA6V+4EBQH/gfjNL8JZ5GhgXsNzQYzxHueXk5NCsWTMFxFGYGc2aNdPelogc4Zgh4Zz7BP8HuAcaDrzo3X8RGBEwPsP5LQTizawVMASY75zb5e0NzAeGetPinHMLnb/T4Ixi6yrpOSpEAXFs2kYiUlxFT1y3dM5t8+5vB1p695OALQHzZXhjRxvPKGH8aM/xM2Y23szSzCwtMzOztNmOLicbDvxQsWVFROqpSl/d5O0BVGu/8WM9h3NumnPO55zzJSb+7A2DZXkCf0BkZ8ChA5WotGRZWVn06dOHPn36cNxxx5GUlHT48aFDh466bFpaGpMmTTrmc5x88slVVa6IyGEVvbpph5m1cs5t8w4Z7fTGtwJtAuZL9sa2AoOKjS/wxpNLmP9oz1H1zCDheMhcB7s2QWJXCK26C7+aNWvGsmXLAHjggQeIjY3ljjvuODw9Pz+fsLCSn8/n8+Hz+Y75HJ9//nmV1CoiEqiiexJz8H92L97XtwPGU81vIJDtHTKaB5xjZgneCetzgHnetL1mNtC7Miq12LpKeo7qERIGCe2hMB/2bPbvXVSjq6++muuuu44BAwZw5513smjRIk466ST69u3LySefzLp16wBYsGAB559/PuAPmGuuuYZBgwbRoUMHnnjiicPri42NPTz/oEGDuPTSS+natStXXXUVRR8sNXfuXLp27UpKSgqTJk06vF4RkdKU5RLYV/HvBTQ3swz8Vyk9Aswys2uBb4HLvdnn4r/8NR3/JbC/AnDO7TKzPwBFH8f4oHOu6GT4RH66BPZd78ZRnqNSfv/OKlZ/v7f0GQrzID8TQrdCaESZ1tmtdRz3X9C93LVkZGTw+eefExoayt69e/n0008JCwvjgw8+4J577mH27Nk/W2bt2rV8/PHH7Nu3jy5dunD99df/7H0NS5cuZdWqVbRu3ZpTTjmFzz77DJ/Px4QJE/jkk09o3749o0aNKne9ItLwHDMknHOlvZqcWcK8DrihlPU8Dzxfwnga0KOE8aySnqPahYRDSAEUHAILhZDQanuqyy67jNBQ//qzs7MZO3Ys69evx8zIy8srcZnzzjuPyMhIIiMjadGiBTt27CA5OfmIefr37394rE+fPmzevJnY2Fg6dOhw+D0Qo0aNYtq0adX2vYlI/dAg3nEdqEz/8RcWwA/fQEGe//xEWNn2KMqrUaNGh+/fd999DB48mLfeeovNmzczaNCgEpeJjIw8fD80NJT8/PwKzSMiUhbq3VSSkFD/+Qkc7N4ErrDanzI7O5ukJP/Vvy+88EKVr79Lly5s3LiRzZs3AzBz5swqfw4RqX8UEqUJj4L4tpB3EPZ+X+1Pd+edd3L33XfTt2/favnPPzo6milTpjB06FBSUlJo3LgxTZo0qfLnEZH6xVw1X8VT03w+nyv+oUNr1qzhxBNPrNgKszPgQCbEHw8xTaugwuDZv38/sbGxOOe44YYb6Ny5M7feeusR81RqW4lInWVmi51zP7veXnsSnqz9uezYW0LforjWEN4IsrdAXt3uazR9+nT69OlD9+7dyc7OZsKECcEuSURquQZ34rokzjkOHipg98FDRIWH0iQ64JJSC4Gm7fxvtNu9CZqfUK1XPFWnW2+99Wd7DiIiR6M9CfyN7ZLio4mJCGPLroPk5BUcOUNoBCS0g/wc2LOl2t9oJyJSWygkPCEhxvHNYggNMTZnHSC/oNgVTZGNoXEryNkNB9UIUEQaBoVEgPDQENo2jSGvwPHdroP87KR+bEuIjIPsrdXSCFBEpLZRSBTTKDKMpPho9ufmsy272IlqM/9VTqHhsHszFOhNaiJSv+nEdQmaNoogJ6+AH/bnEh0eSkKjgHdch4b5z0/8sN7fCLBpR394HEVWVhZnnunvMLJ9+3ZCQ0Mpamm+aNEiIiKO/o7uBQsWEBERcbgd+NSpU4mJiSE1NbXC36OISFkoJEpxXJMocvIKyNjzI5HhIcREBGyqiEbQJNl/Wez+7f5zFUdxrFbhx7JgwQJiY2MPh8R1111X7u9HRKQidLipFCFmtG0aQ3iI8W3WQfKKn8iOaQbRTWHfdsg5SlfZUixevJhf/vKXpKSkMGTIELZt838I3xNPPEG3bt3o1asXI0eOZPPmzUydOpXHH3+cPn368Omnn/LAAw/w2GOPATBo0CDuuusu+vfvzwknnMCnn34KwMGDB7n88svp1q0bF110EQMGDKD4mwxFRI6l4e1JvDsZtq8o06xhQGfnyMkrIN+MsPAQjMBDS87ftqNpJxgxpcyNAJ1z3HTTTbz99tskJiYyc+ZM7r33Xp5//nkeeeQRNm3aRGRkJHv27CE+Pp7rrrvuiL2PDz/88Ij15efns2jRIubOncvvf/97PvjgA6ZMmUJCQgKrV69m5cqV9OnTp0y1iYgEanghUU6hZkSGhZCTV8ih/EIiwgKDwiAsmsONAJt39r/57hhyc3NZuXIlZ599NgAFBQW0auU/ZNWrVy+uuuoqRowYwYgRI8pU48UXXwxASkrK4QZ+//3vf7n55psB6NGjB7169Srz9ywiUqThhcSwR8q9SBiwPzuHnftySIqPplls5JEz/Ljbf7XT3u/95yqOwTlH9+7d+eKLL3427T//+Q+ffPIJ77zzDg899BArVhx7r6eoNbjagotIVdM5iTJqGRdJXFQ43+/JYX9usRfi6ARolOhvBHhwV8krCBAZGUlmZubhkMjLy2PVqlUUFhayZcsWBg8ezKOPPkp2djb79++ncePG7Nu3r1z1nnLKKcyaNQuA1atXlylsRESKU0iUkZnRpmk0EWEhfJd1kEP5xVp3lKMRYEhICG+88QZ33XUXvXv3pk+fPnz++ecUFBQwevRoevbsSd++fZk0aRLx8fFccMEFvPXWW4dPXJfFxIkTyczMpFu3bvz2t7+le/fuag0uIuWmVuHllJNXwIbM/USEhtAxMZaQkIAT2QWH/I0AQ8KC3giwoKCAvLw8oqKi2LBhA2eddRbr1q075nsy1CpcpGEqrVV4wzsnUUlR4aG0SYhhc9YBMnYfpE3TGKzozXRFjQCz0v2NABOOP+Yb7arLwYMHGTx4MHl5eTjnmDJlyjEDQkSkOIVEBcRFh3Nckyi2Z+cQtT+XFo2jfppY1Ahw3zY42Mh/riIIGjdurPdFiEilNZhzElV9WC0xNpL46Ai2Z+ew98e8IyfW0UaA9e3Qo4hUXoMIiaioKLKysqr0RdDMSE6IJjo89OefQVEHGwE658jKyiIqKurYM4tIg9EgDjclJyeTkZFBZmZmla87v7CQzL25ZGYYiY0jCQk8B5GfD/t3wHdZ0Kh50M5PlFVUVBTJycd+n4eINBwNIiTCw8Np3759ta1/4cYsRj/7JaefkMj0VB+hgVc8pT0P/74VBt0Dg+6qthpERKpDgzjcVN0GdmjG/Rd046O1O/nL/HVHTkz5FfQaCQv+COkflrwCEZFaSiFRRUYPPJ5R/dvw1Mcb+Pfy73+aYAbnPw4tToTZv4bsjOAVKSJSTgqJKmJm/P7CHqQcn8BvXl/Oqu+zf5oYEQOXvwQFeTBrLOQfCl6hIiLloJCoQhFhITw9uh9NosMZP2MxWftzf5rYvBMMfxK2psH7vw1ekSIi5aCQqGItGkcxLTWFzP253PDPJUd+WFH3ETBwIix6BlbODlqNIiJlVamQMLNbzWyVma00s1fNLMrM2pvZl2aWbmYzzSzCmzfSe5zuTW8XsJ67vfF1ZjYkYHyoN5ZuZpMrU2tN6pUczyMX92Thxl38z79XHznx7AehzQCYMwkyvwlOgSIiZVThkDCzJGAS4HPO9QBCgZHAo8DjzrlOwG7gWm+Ra4Hd3vjj3nyYWTdvue7AUGCKmYWaWSjwFDAM6AaM8uatEy7ul8yvT23Pi198y6yvtvw0ITQcLnsBwqJg1hjI3R+0GkVEjqWyh5vCgGgzCwNigG3AGcAb3vQXgRHe/eHeY7zpZ5q/M95w4DXnXK5zbhOQDvT3bunOuY3OuUPAa968dcbkYV05rXNzfvuvlSz+dvdPE+Jaw6XPwQ/fwL9vAbXDEJFaqsIh4ZzbCjwGfIc/HLKBxcAe51xRH4oMIMm7nwRs8ZbN9+ZvFjhebJnSxuuMsNAQ/j6qL8c1ieK6lxezPTvgcyY6DILB98CK1+GrZ4NWo4jI0VTmcFMC/v/s2wOtgUb4DxfVODMbb2ZpZpZWHa03KiM+JoJnx/o4mJvPhJcXH9nj6dTbofMQeO9uyFgcvCJFREpRmcNNZwGbnHOZzrk84E3gFCDeO/wEkAxs9e5vBdoAeNObAFmB48WWKW38Z5xz05xzPuecLzExOK25j+aElo35yxV9+HrLHu59a+VPjQZDQuCiqRDXCl4fW6aPPhURqUmVCYnvgIFmFuOdWzgTWA18DFzqzTMWeNu7P8d7jDf9I+d/tZwDjPSufmoPdAYWAV8Bnb2rpSLwn9yeU4l6g2pI9+O45azOzF6SwT8+2/zThJimcNmL/kaAb46DwsJS1yEiUtMqc07iS/wnoJcAK7x1TQPuAm4zs3T85xye8xZ5Dmjmjd8GTPbWswqYhT9g3gNucM4VeOctbgTmAWuAWd68ddakMzpzTreWPDR3DZ+l//DThKR+MPQRSP8APvlz8AoUESmmQXzGdW2yPzefi6d8xs59ucy54VTaNovxT3AO3poAy2fB6NnQ6czgFioiDUppn3Gtd1zXsNjIMKan+nAOxs1I40CudyFYUSPAxK5qBCgitYZCIgiOb9aIJ6/sy/qd+7jj9a8pLPT25iIawRVeI8DXr1YjQBEJOoVEkJzWOZF7zj2Rd1du58mP03+a0LyzvxFgxlcw/77gFSgigkIiqK49tT0X9U3iL/O/4f1V23+aUNQI8MupagQoIkGlkAgiM+OPF/ekV3ITbp25jPU79v00UY0ARaQWUEgEWVR4KM+MSSE6IoxxM9LIPpjnn6BGgCJSCygkaoFWTaKZOrofW/f8yI2vLqGg6ES2GgGKSJApJGoJX7umPDi8B5+u/4E/vbf2pwlqBCgiQaSQqEVG9W/LmIHH88wnG/nX0oA2VafeDp3PUSNAEalxCola5ncXdKN/+6bcNXs5KzKy/YMhIXDRM9BYjQBFpGYpJGqZ8NAQplzVj+axkYx/KY3Mfbn+CTFN4XI1AhSRmqWQqIWax0byzJgUdh88xMRXFnMo3wsENQIUkRqmkKileiQ14U+X9uarzbt54J2A5re+a6DXFbDgj7Dho+AVKCINgkKiFruwd2uu+2VH/vnld7y88Fv/oBoBikgNUkjUcr8Z0oVBXRJ5YM4qFm3yTlgXNQLMP6RGgCJSrRQStVxoiPG3kX1p2zSG619ezNY9P/onqBGgiNQAhUQd0CQ6nGmpPg7lFzLhpTR+PFTgn6BGgCJSzRQSdUSnFrH8dWQfVn2/l8lvLufwJwqqEaCIVCOFRB1y5oktueOcLry97HumfbLRPxgaDpf+A8Ii1QhQRKqcQqKOmTioI+f1bMWj761lwbqd/sEmSXDJc5C5To0ARaRKKSTqGDPjz5f14oSWjbnp1aVs+uGAf0LHwTD4XjUCFJEqpZCog2Iiwpie6iMsxBg3I419Od5nUJymRoAiUrUUEnVUm6YxPHVVPzb9cIBbZy6jsNCpEaCIVDmFRB12csfm3HfeiXywZid//cC7skmNAEWkCikk6rixJ7fjcl8yT3yUzrsrtvkHAxsBfvpYcAsUkTpNIVHHmRl/GNGDvm3juf31r1m7fa9/QlEjwI8fViNAEakwhUQ9EBkWytTRKcRGhjFuRhq7DxxSI0ARqRIKiXqiZVwUz4xJYUd2Ljf8cwn5BYUBjQBz1QhQRCpEIVGP9G2bwEMX9eDzDVk8PHetf1CNAEWkEsKCXYBUrct8bVi9bS/Pf7aJbq3juDQlGbpfBN99CV8+DW36Q49Lgl2miNQR2pOoh+4990RO7tiMe95awdLvdvsHz34QkvurEaCIlEulQsLM4s3sDTNba2ZrzOwkM2tqZvPNbL33NcGb18zsCTNLN7PlZtYvYD1jvfnXm9nYgPEUM1vhLfOEmVll6m0owkJDeOrKfrSMi+S6lxezc28OhEXAZS+oEaCIlEtl9yT+BrznnOsK9AbWAJOBD51znYEPvccAw4DO3m088DSAmTUF7gcGAP2B+4uCxZtnXMByQytZb4OR0CiCaWN87P0xnwkvLyY3v0CNAEWk3CocEmbWBDgdeA7AOXfIObcHGA686M32IjDCuz8cmOH8FgLxZtYKGALMd87tcs7tBuYDQ71pcc65hc7/4QkzAtYlZXBiqzj+cnlvln63h/v+tdL/GRRqBCgi5VCZPYn2QCbwDzNbambPmlkjoKVzznvrL9uBlt79JGBLwPIZ3tjRxjNKGP8ZMxtvZmlmlpaZmVmJb6n+GdazFTed0YlZaRnM+OJb/6AaAYpIGVUmJMKAfsDTzrm+wAF+OrQEgLcHUO3HNJxz05xzPuecLzExsbqfrs659awTOOvEFjz479V8vuEHNQIUkTKrTEhkABnOuS+9x2/gD40d3qEivK/eJ+OwFWgTsHyyN3a08eQSxqWcQkKMx6/oQ/vmjbjhlSVs2XWwWCPA8WoEKCIlqnBIOOe2A1vMrIs3dCawGpgDFF2hNBZ427s/B0j1rnIaCGR7h6XmAeeYWYJ3wvocYJ43ba+ZDfSuakoNWJeUU+OocKan+igodIybkcbBQ/kBjQDnqxGgiJSoslc33QS8YmbLgT7Aw8AjwNlmth44y3sMMBfYCKQD04GJAM65XcAfgK+824PeGN48z3rLbADerWS9DVr75o14YlRfvtmxj9+8vtx/Itt3DfS8XI0ARaRE5urZZZA+n8+lpaUFu4xa7Zn/28Af313Lb4Z04YbBneDQAZh+JhzYCRM+gSbJx16JiNQrZrbYOecrPq53XDdA40/vwIW9W/PY++v4cM0ONQIUkVIpJBogM+PRS3rRvXUcN7+2jPSd+9UIUERKpJBooKIjQnlmjI/IsBDGz0gj+8c8fyPAAdfDl1Nh5exglygitYBCogFLio/m6dEpfLfrIDe/tpSCQqdGgCJyBIVEA9e/fVMeuLA7C9Zl8tj769QIUESOoJAQRg88nisHtOXpBRuY8/X3xRoB3qpGgCINmEJCAHjggu78ol0Cd77xNSu3Zgc0ApwFac8FuzwRCRKFhAAQERbClKtSSIiJYMJLi/lhf66/EWCns/2NALeqEaBIQ6SQkMMSG0cybYyPH/bnMvGVJeQ54OJpENsSZqkRoEhDpJCQI/RMbsKjl/Ri0aZdPPjOajUCFGngFBLyMyP6JjH+9A68tPBbXl30HSSlwNA/qhGgSAOkkJAS3TW0K6d1bs7v3l5J2uZd4LtWjQBFGiCFhJQoNMR4clQ/kuKjue7lJWzbmwMX/BUSu8LsX0N2xjHXISJ1n0JCStUkJpxpqT5+PJTPhJcWk2NRagQo0sAoJOSoTmjZmMev6MPyjGzufnMFrlknNQIUaUAUEnJM53Q/jlvPOoG3lm7luf9uUiNAkQZEISFlctMZnRja/TgenruGT9dnqhGgSAOhkJAyCQkx/vfy3nRu0Zgb/7mUb7PzAhoBpvo/3U5E6h2FhJRZo8gwpqf6MINxM9LYH9USLnkWMtfCO7eoEaBIPaSQkHJp2yyGJ0f1I33nfm6ftYzC9oNh8D1qBChSTykkpNxO7dyce8/rxrxVO3jio/Vw2h1qBChSTykkpEKuOaUdl/RL5q8frGfemp1qBChSTykkpELMjIcu6kHv5CbcNnMZ3+wLVyNAkXpIISEVFhUeyjNjfMREhjFuRhp7EnqqEaBIPaOQkEo5rkkUU0ensG1PDje9upT8vr9SI0CRekQhIZWWcnwCfxjRnU/X/8Cj89apEaBIPaKQkCpxxS/aMvak45n+6SbeXLlbjQBF6gmFhFSZ357fjYEdmjL5zRUsz0mEC//uNQL8XbBLE5EKUkhIlQkPDeGpK/uRGBvJ+BmL2Xn8uTDgOvjyaVj5ZrDLE5EKUEhIlWoWG8m01BT2/HiI619eQu4ZD3iNAG9SI0CROkghIVWue+smPHZZbxZ/u5sH/rMed9k/1AhQpI6qdEiYWaiZLTWzf3uP25vZl2aWbmYzzSzCG4/0Hqd709sFrONub3ydmQ0JGB/qjaWb2eTK1io15/xerZk4qCOvLtrCy2sK1AhQpI6qij2Jm4E1AY8fBR53znUCdgPXeuPXAru98ce9+TCzbsBIoDswFJjiBU8o8BQwDOgGjPLmlTri9nO6cEbXFvx+ziq+tN5qBChSB1UqJMwsGTgPeNZ7bMAZwBveLC8CI7z7w73HeNPP9OYfDrzmnMt1zm0C0oH+3i3dObfROXcIeM2bV+qI0BDjryP70LZZDBNfWUJGz4lqBChSx1R2T+KvwJ1AUaOeZsAe51y+9zgDSPLuJwFbALzp2d78h8eLLVPa+M+Y2XgzSzOztMzMzEp+S1KV4qLCmZ7q41B+IRNeXsqP5z+tRoAidUiFQ8LMzgd2OueC/i+hc26ac87nnPMlJiYGuxwppmNiLH8b1YfV2/Zy57sZuMvUCFCkrqjMnsQpwIVmthn/oaAzgL8B8WYW5s2TDGz17m8F2gB405sAWYHjxZYpbVzqoDO6tuSOc7rwztffMzU9Xo0AReqICoeEc+5u51yyc64d/hPPHznnrgI+Bi71ZhsLvO3dn+M9xpv+kXPOeeMjvauf2gOdgUXAV0Bn72qpCO855lS0Xgm+iYM6cn6vVvxp3lo+jr0goBHgx8EuTURKUR3vk7gLuM3M0vGfcyi6lOU5oJk3fhswGcA5twqYBawG3gNucM4VeOctbgTm4b96apY3r9RRZsafLu1F1+PimDRzGZtOeggSu8DsayFbO4kitZG5enbNus/nc2lpacEuQ45iy66DDH/qMxJiwnl7ZAtiXzwbWnSDq/8DYRHBLk+kQTKzxc45X/FxveNaalybpjE8dWU/Nmcd5Ob5Byi84O+QsUiNAEVqIYWEBMVJHZtx/wXd+HDtTv7yfXc1AhSppRQSEjRjBh7PFb42PPlxOnNbTVQjQJFaSCEhQWNmPDiiO/3axnP77DV8c/qTagQoUssoJCSoIsNCmTo6hbjoMH715lb2njdVjQBFahGFhARdi7gonhnjI3N/LhM+i6Pgl3erEaBILaGQkFqhT5t4/nhRT77YmMX/7D1XjQBFagmFhNQal6Qkc+2p7fnHF9/xrw73qxGgSC2gkJBa5e5hXTm1U3Pu/E8Ga0//O+zbrkaAIkGkkJBaJSw0hL+P6stxTaJIfa+AvYP+4DUC/N9glybSICkkpNZJaBTB9FQf+3PzSV3ek4Lul8LHD6kRoEgQKCSkVupyXGP+cnlvlmVkc1/hOJwaAYoEhUJCaq2hPVox6czO/HNpFm91/iPk58LrV0P+oWCXJtJgKCSkVrvlzM6c3a0lv1mQw9oBD6sRoEgNU0hIrRYSYjx+RR86NG/EyM9asa/3tWoEKFKDFBJS68VGhjE91UdhoWPU5vMoSPqFGgGK1BCFhNQJ7Zo34skr+7F6Zw73hd2OUyNAkRqhkJA64/QTEpk8rCv/XFfI2x1+r0aAIjVAISF1yrjTOjCiT2tuSWvKhu43qRGgSDVTSEidYmY8ckkveiY1YcTKkznQdpAaAYpUI4WE1DlR4aE8MyaFyPAwrsy6lsJGLWDW1WoEKFINFBJSJ7WOj+bp0Sms3hPGH6Lvwu3bpkaAItVAISF11i/aNeX3F/bgH9824/22N6sRoEg1UEhInXblgLZcNaAtE9b2ZUvyeWoEKFLFFBJS591/QXf6t2vGBZsvIye+kxoBilQhhYTUeRFhIUwZ3Y+YRnH86sBNFOblqBGgSBVRSEi90Dw2kmmpPpb82IK/xUxSI0CRKqKQkHqjR1IT/nRpL/62oyefN79UjQBFqoBCQuqV4X2SmPDLDozNuJDM+F5qBChSSQoJqXfuHNKVk09oxcU7x5NnEWoEKFIJCgmpd0JDjCdG9iWsaRtuybsBp0aAIhVW4ZAwszZm9rGZrTazVWZ2szfe1Mzmm9l672uCN25m9oSZpZvZcjPrF7Cusd78681sbMB4ipmt8JZ5wsysMt+sNBxNYsKZnprC/xX05JXoK71GgM8HuyyROqcyexL5wO3OuW7AQOAGM+sGTAY+dM51Bj70HgMMAzp7t/HA0+APFeB+YADQH7i/KFi8ecYFLDe0EvVKA9OpRWP+ekUffrdnGGsa9ce9Nxm2Lgl2WSJ1SoVDwjm3zTm3xLu/D1gDJAHDgRe92V4ERnj3hwMznN9CIN7MWgFDgPnOuV3Oud3AfGCoNy3OObfQOeeAGQHrEimTs7q15NazujIq61r2hzWFWWPVCFCkHKrknISZtQP6Al8CLZ1z27xJ24GW3v0kYEvAYhne2NHGM0oYL+n5x5tZmpmlZWZmVu6bkXrnxjM6cXLPzozZN5FCNQIUKZdKh4SZxQKzgVucc3sDp3l7ANV+ttA5N80553PO+RITE6v76aSOMTP+fGlvclr05Y+FqWoEKFIOlQoJMwvHHxCvOOeK3rW0wztUhPd1pze+FWgTsHiyN3a08eQSxkXKrVFkGNNTfbxuQ/gw7Jc4NQIUKZPKXN1kwHPAGufcXwImzQGKrlAaC7wdMJ7qXeU0EMj2DkvNA84xswTvhPU5wDxv2l4zG+g9V2rAukTKrU3TGKZclcItB69mW3gbnBoBihxTZfYkTgHGAGeY2TLvdi7wCHC2ma0HzvIeA8wFNgLpwHRgIoBzbhfwB+Ar7/agN4Y3z7PeMhuAdytRrwgnd2rObef1Zcz+m8jLOahGgCLHYK6evcHI5/O5tLS0YJchtZhzjt+8sZycpa/zZMTfYcD1MOyRYy8oUo+Z2WLnnK/4uN5xLQ2OmfE/I3qQkTSMl91QNQIUOQqFhDRIUeGhPDMmhSnhV7My5ATc2zfCD+uDXZZIraOQkAarZVwUT6YOZGLuJPYVhOFmjlYjQJFiFBLSoPVrm8CNFw1iYs5EyFwH/75VjQBFAigkpMG73NeGTgMv4PG8S2D5TDUCFAmgkBAB7j3vRNLaXssnhb0pfFeNAEWKKCREgPDQEJ4c7eORmNvYWRhHwcxUNQIUQSEhcljTRhE8lnoGkwpupXDvNgpmj1MjQGnwFBIiAbq1jmPsZZfwYN5oQjd8gPv0sWCXJBJUCgmRYs7r1Yomp13P2wUnw8cPqxGgNGgKCZES3HZOF+a1v5t015q8WdeoEaA0WAoJkRKEhBiPXHkSDze6m7zcg+S+mqpGgNIgKSREShEXFc59v7qI33EdkdvTyJt3X7BLEqlxCgmRo+iQGMt5o27ghfwhhH81FbfyrWCXJFKjFBIixzC4Swtyz3iQJYWdyHtrohoBSoOikBApg/GDu/BWp4fZlx/K/pdGqRGgNBgKCZEyMDPuGXkWj8f9hpg96ex940Y1ApQGQSEhUkbREaFcf+14poVcRtw3b/LjF9ODXZJItVNIiJRDUnw0fUc/zCeFvQh7/x4KMtQIUOo3hYRIOQ3omMj2s/7OThfH/hlXqhGg1GsKCZEKuOy03vyr88NE5+5kx4upagQo9ZZCQqQCzIxxIy9nRtwEWu74lB1zHwp2SSLVQiEhUkERYSFcOO53zAs5jcS0/2XvqveDXZJIlVNIiFRCi7hoksY8w0bXGmb/mrzdW4JdkkiVUkiIVFKP9klsPvNpQgty2PbsKCjIC3ZJIlVGISFSBc46/ZfM6/hb2h5YwbqXbgl2OSJVRiEhUkUuvOpG3o8dTpfNL7NhwUvBLkekSigkRKpIWGgI/SdMYVXICRy34A52bloR7JJEKk0hIVKF4hvHEn3lSxxy4fz48lXkHNgb7JJEKkUhIVLFOnTqyobT/0qb/O9Y+cw1OL3RTuowhYRINfCdeSlfHj8O3975fDbzz8EuR6TCan1ImNlQM1tnZulmNjnY9YiU1YCxj7Ay+hf8Yu2fWLbwo2CXI1IhtTokzCwUeAoYBnQDRplZt+BWJVI2IaGhtBv/Ctkh8SS+N56vP5rFyoXzyPnxAIUFOgQldUNYsAs4hv5AunNuI4CZvQYMB1YHtSqRMopNaMm+S18k6fXzSPpknH/wPTjoIsm3UA4RwSGLpIBQ/B9hZDizIFZc9xj68KcioaNnk9ThxCpdZ20PiSQgsM9BBjCg+ExmNh4YD9C2bduaqUykjFp1P5UNWVPJ2LCKJq06cvC7pYQd2kehhRBSkEtIfg4hrgC8FztXhk+8MxwOhUkRBatf28ioKl9nbQ+JMnHOTQOmAfh8Pv1bIbVOx9NH0fH0oke/CmYpIuVSq89JAFuBNgGPk70xERGpAbU9JL4COptZezOLAEYCc4Jck4hIg1GrDzc55/LN7EZgHhAKPO+cWxXkskREGoxaHRIAzrm5wNxg1yEi0hDV9sNNIiISRAoJEREplUJCRERKpZAQEZFSWVne3VmXmFkm8G0FF28O/FCF5VQV1VU+qqt8VFf51Ne6jnfOJRYfrHchURlmluac8wW7juJUV/morvJRXeXT0OrS4SYRESmVQkJEREqlkDjStGAXUArVVT6qq3xUV/k0qLp0TkJEREqlPQkRESmVQkJEREqlkADMbKiZrTOzdDObXMPP3cbMPjaz1Wa2ysxu9sYfMLOtZrbMu50bsMzdXq3rzGxINda22cxWeM+f5o01NbP5Zrbe+5rgjZuZPeHVtdzM+lVTTV0CtskyM9trZrcEa3uZ2fNmttPMVgaMlXsbmdlYb/71Zja2mur6s5mt9Z77LTOL98bbmdmPAdtuasAyKd7vQLpXe6U+Aq6Uusr9s6vqv9lS6poZUNNmM1vmjdfI9jrKa0PN/n455xr0DX8L8g1AByAC+BroVoPP3wro591vDHwDdAMeAO4oYf5uXo2RQHuv9tBqqm0z0LzY2J+Ayd79ycCj3v1zgXcBAwYCX9bQz247cHywthdwOtAPWFnRbQQ0BTZ6XxO8+wnVUNc5QJh3/9GAutoFzldsPYu8Ws2rfVg11FWun111/M2WVFex6f8L/K4mt9dRXhtq9PdLexLQH0h3zm10zh0CXgOG19STO+e2OeeWePf3AWvwf7Z3aYYDrznncp1zm4B0/N9DTRkOvOjdfxEYETA+w/ktBOLNrFU113ImsME5d7R32Ffr9nLOfQLsKuE5y7ONhgDznXO7nHO7gfnA0Kquyzn3vnMu33u4EP8nPZbKqy3OObfQ+V9tZgR8L1VW11GU9rOr8r/Zo9Xl7Q1cDrx6tHVU9fY6ymtDjf5+KST8G31LwOMMjv4iXW3MrB3QF/jSG7rR2218vmiXkpqt1wHvm9liMxvvjbV0zm3z7m8HWgahriIjOfIPN9jbq0h5t1EwarwG/3+dRdqb2VIz+z8zO80bS/JqqYm6yvOzq+ntdRqwwzm3PmCsRrdXsdeGGv39UkjUEmYWC8wGbnHO7QWeBjoCfYBt+Hd3a9qpzrl+wDDgBjM7PXCi999SUK6hNv/H2V4IvO4N1Ybt9TPB3EalMbN7gXzgFW9oG9DWOdcXuA34p5nF1WBJtfJnF2AUR/4zUqPbq4TXhsNq4vdLIQFbgTYBj5O9sRpjZuH4fwlecc69CeCc2+GcK3DOFQLT+ekQSY3V65zb6n3dCbzl1bCj6DCS93VnTdflGQYscc7t8GoM+vYKUN5tVGM1mtnVwPnAVd4LDN7hnCzv/mL8x/tP8GoIPCRVLXVV4GdXk9srDLgYmBlQb41tr5JeG6jh3y+FBHwFdDaz9t5/pyOBOTX15N7xzueANc65vwSMBx7PvwgouupiDjDSzCLNrD3QGf/Jsqquq5GZNS66j/+k50rv+YuujhgLvB1QV6p3hcVAIDtgl7g6HPHfXbC3VzHl3UbzgHPMLME71HKON1alzGwocCdwoXPuYMB4opmFevc74N9GG73a9prZQO/3NDXge6nKusr7s6vJv9mzgLXOucOHkWpqe5X22kBN/35V9Mx7fbrhvyrgG/z/Edxbw899Kv7dxeXAMu92LvASsMIbnwO0CljmXq/WdVTyapOj1NUB/1UjXwOrirYL0Az4EFgPfAA09cYNeMqrawXgq8Zt1gjIApoEjAVle+EPqm1AHv5jvddWZBvhP0eQ7t1+VU11peM/Nl30ezbVm/cS72e8DFgCXBCwHh/+F+0NwJN4XRqquK5y/+yq+m+2pLq88ReA64rNWyPbi9JfG2r090ttOUREpFQ63CQiIqVSSIiISKkUEiIiUiqFhIiIlEohISIipVJIiIhIqRQSIiJSqv8HUu69khY20REAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1 = plt.figure(1)\n",
    "x=np.linspace(1,epo,epo)\n",
    "plt.plot(x,train_error, label = 'Training')\n",
    "plt.plot(x,test_error, label ='Testing')\n",
    "plt.legend(loc = 2)\n",
    "plt.title('MAE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cf586b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.976625332326482\n"
     ]
    }
   ],
   "source": [
    "print(np.min(test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54d8807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chou",
   "language": "python",
   "name": "chou"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
