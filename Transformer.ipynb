{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "518e65f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luhung3080/miniconda3/envs/chou/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch ver .  1.11.0+cu113\n",
      "Is CUDA available? True\n",
      "pynio ver .  1.5.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "print(\"pytorch ver . \",torch.__version__)\n",
    "print(\"Is CUDA available?\",torch.cuda.is_available())\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.utils.data as Data\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import xarray as xr\n",
    "import os\n",
    "os.environ['R_HOME'] = '/home/luhung3080/miniconda3/envs/chou/lib/R'\n",
    "from rpy2.robjects import r, numpy2ri\n",
    "numpy2ri.activate()\n",
    "from rpy2.robjects.packages import importr\n",
    "sinkr = importr('sinkr')\n",
    "import Nio\n",
    "print (\"pynio ver . \",Nio.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248b8a17",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fe6181b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>date</th>\n",
       "      <th>FCST_TIME</th>\n",
       "      <th>TAU</th>\n",
       "      <th>pm25_cal</th>\n",
       "      <th>pm25_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPA001</td>\n",
       "      <td>2020-02-24 08:00:00</td>\n",
       "      <td>2020-02-24 09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4.9510</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EPA001</td>\n",
       "      <td>2020-02-24 08:00:00</td>\n",
       "      <td>2020-02-24 10:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>4.4674</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EPA001</td>\n",
       "      <td>2020-02-24 08:00:00</td>\n",
       "      <td>2020-02-24 11:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>4.6159</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EPA001</td>\n",
       "      <td>2020-02-24 08:00:00</td>\n",
       "      <td>2020-02-24 12:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>3.9937</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EPA001</td>\n",
       "      <td>2020-02-24 08:00:00</td>\n",
       "      <td>2020-02-24 13:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>3.9602</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092755</th>\n",
       "      <td>EPA080</td>\n",
       "      <td>2021-10-30 08:00:00</td>\n",
       "      <td>2021-11-02 04:00:00</td>\n",
       "      <td>68</td>\n",
       "      <td>3.6190</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092756</th>\n",
       "      <td>EPA080</td>\n",
       "      <td>2021-10-30 08:00:00</td>\n",
       "      <td>2021-11-02 05:00:00</td>\n",
       "      <td>69</td>\n",
       "      <td>3.7908</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092757</th>\n",
       "      <td>EPA080</td>\n",
       "      <td>2021-10-30 08:00:00</td>\n",
       "      <td>2021-11-02 06:00:00</td>\n",
       "      <td>70</td>\n",
       "      <td>4.0454</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092758</th>\n",
       "      <td>EPA080</td>\n",
       "      <td>2021-10-30 08:00:00</td>\n",
       "      <td>2021-11-02 07:00:00</td>\n",
       "      <td>71</td>\n",
       "      <td>3.9015</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092759</th>\n",
       "      <td>EPA080</td>\n",
       "      <td>2021-10-30 08:00:00</td>\n",
       "      <td>2021-11-02 08:00:00</td>\n",
       "      <td>72</td>\n",
       "      <td>2.7468</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3092760 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SITE_ID                 date            FCST_TIME  TAU  pm25_cal  \\\n",
       "0        EPA001  2020-02-24 08:00:00  2020-02-24 09:00:00    1    4.9510   \n",
       "1        EPA001  2020-02-24 08:00:00  2020-02-24 10:00:00    2    4.4674   \n",
       "2        EPA001  2020-02-24 08:00:00  2020-02-24 11:00:00    3    4.6159   \n",
       "3        EPA001  2020-02-24 08:00:00  2020-02-24 12:00:00    4    3.9937   \n",
       "4        EPA001  2020-02-24 08:00:00  2020-02-24 13:00:00    5    3.9602   \n",
       "...         ...                  ...                  ...  ...       ...   \n",
       "3092755  EPA080  2021-10-30 08:00:00  2021-11-02 04:00:00   68    3.6190   \n",
       "3092756  EPA080  2021-10-30 08:00:00  2021-11-02 05:00:00   69    3.7908   \n",
       "3092757  EPA080  2021-10-30 08:00:00  2021-11-02 06:00:00   70    4.0454   \n",
       "3092758  EPA080  2021-10-30 08:00:00  2021-11-02 07:00:00   71    3.9015   \n",
       "3092759  EPA080  2021-10-30 08:00:00  2021-11-02 08:00:00   72    2.7468   \n",
       "\n",
       "         pm25_obs  \n",
       "0            10.0  \n",
       "1            13.0  \n",
       "2            11.0  \n",
       "3            11.0  \n",
       "4             9.0  \n",
       "...           ...  \n",
       "3092755       4.0  \n",
       "3092756       7.0  \n",
       "3092757       7.0  \n",
       "3092758       4.0  \n",
       "3092759       4.0  \n",
       "\n",
       "[3092760 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('/home/luhung3080/Desktop/PycharmProjects/NCHUproject/Transformer/data_final.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12468228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(604, 1704)\n",
      "(604, 5112)\n"
     ]
    }
   ],
   "source": [
    "x1=np.zeros([604,1704])\n",
    "x2=np.zeros([604,5112])\n",
    "\n",
    "#x1 (0th~1703th column as x)\n",
    "for i in range (0,604):\n",
    "    for j in range (0,71):\n",
    "        a=np.array(data['pm25_obs'][5112*i+72*j:5112*i+72*j+24])\n",
    "        for k in range (0,24):\n",
    "            x1[i][j*24+k]=a[k]\n",
    "\n",
    "#x2 (1704th~8519th column as x)\n",
    "for i in range (1,604):\n",
    "    b=np.array(data['pm25_cal'][5112*i:5112*i+5112])\n",
    "    for j in range(0,5112):\n",
    "        x2[i-1][j]=b[j]\n",
    "        \n",
    "print(np.shape(x1))\n",
    "print(np.shape(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6f1b58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(604, 1704)\n",
      "(604, 5112)\n"
     ]
    }
   ],
   "source": [
    "x1Restruct_Fun=x1\n",
    "x2Restruct_Fun=x2\n",
    "print(np.shape(x1Restruct_Fun))\n",
    "print(np.shape(x2Restruct_Fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07db70c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(601, 5112)\n"
     ]
    }
   ],
   "source": [
    "YRestruct_Fun=np.zeros([601,5112])\n",
    "for j in range (0,71):\n",
    "    for i in range(0,601):\n",
    "        YRestruct_Fun[i][72*j:72*j+24]=x1Restruct_Fun[1+i][24*j:24*j+24]\n",
    "        YRestruct_Fun[i][72*j+24:72*j+48]=x1Restruct_Fun[1+i+1][24*j:24*j+24]\n",
    "        YRestruct_Fun[i][72*j+48:72*j+72]=x1Restruct_Fun[1+i+2][24*j:24*j+24]\n",
    "print(np.shape(YRestruct_Fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f5665cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(601, 6816)\n"
     ]
    }
   ],
   "source": [
    "XRestruct_Fun=np.zeros([601,6816])\n",
    "for i in range (0,601):\n",
    "    for j in range (0,1704):\n",
    "        XRestruct_Fun[i][j]=x1Restruct_Fun[i][j]\n",
    "    for j in range (1704,6816):\n",
    "        XRestruct_Fun[i][j]=x2Restruct_Fun[i][j-1704]\n",
    "print(np.shape(XRestruct_Fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81052a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xhat_train\n",
      "(540, 6816)\n",
      "Yhat_train\n",
      "(540, 5112)\n",
      "Xhat_val\n",
      "(61, 6816)\n",
      "Yhat_val\n",
      "(61, 5112)\n",
      "Xhat_test\n",
      "(61, 6816)\n",
      "Yhat_test\n",
      "(61, 5112)\n"
     ]
    }
   ],
   "source": [
    "Xhat=XRestruct_Fun\n",
    "Yhat=YRestruct_Fun\n",
    "Xhat_train = np.zeros([540,6816])\n",
    "Yhat_train = np.zeros([540,5112])\n",
    "Xhat_val = np.zeros([61,6816])\n",
    "Yhat_val = np.zeros([61,5112])\n",
    "Xhat_test = np.zeros([61,6816])\n",
    "Yhat_test = np.zeros([61,5112])\n",
    "\n",
    "for i in range (0,540):\n",
    "    for j in range (0,1704):\n",
    "        Xhat_train[i][j] = Xhat[i][j]\n",
    "    for j in range (0,5112):    \n",
    "        Xhat_train[i][j+1704] = Xhat[i][j+1704]\n",
    "        Yhat_train[i][j] = Yhat[i][j]\n",
    "        \n",
    "for i in range (540,601):\n",
    "    for j in range (0,1704):\n",
    "        Xhat_val[i-540][j] = Xhat[i][j]\n",
    "    for j in range (0,5112):\n",
    "        Xhat_val[i-540][j+1704] = Xhat[i][j+1704]\n",
    "        Yhat_val[i-540][j] = Yhat[i][j]     \n",
    "        \n",
    "for i in range (540,601):\n",
    "    for j in range (0,1704):\n",
    "        Xhat_test[i-540][j] = Xhat[i][j]\n",
    "    for j in range (0,5112):\n",
    "        Xhat_test[i-540][j+1704] = Xhat[i][j+1704]\n",
    "        Yhat_test[i-540][j] = Yhat[i][j]\n",
    "        \n",
    "print('Xhat_train')\n",
    "print(np.shape(Xhat_train))\n",
    "print('Yhat_train')\n",
    "print(np.shape(Yhat_train))\n",
    "print('Xhat_val')\n",
    "print(np.shape(Xhat_val))\n",
    "print('Yhat_val')\n",
    "print(np.shape(Yhat_val))\n",
    "print('Xhat_test')\n",
    "print(np.shape(Xhat_test))\n",
    "print('Yhat_test')\n",
    "print(np.shape(Yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26f2887",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbe2ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(Xhat_train).float()\n",
    "y_train = torch.from_numpy(Yhat_train).float()\n",
    "x_val = torch.from_numpy(Xhat_val).float()\n",
    "y_val = torch.from_numpy(Yhat_val).float()\n",
    "x_test = torch.from_numpy(Xhat_test).float()\n",
    "y_test = torch.from_numpy(Yhat_test).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4542372a",
   "metadata": {},
   "source": [
    "## 會用到的函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67bddded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer_EncDec\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, c_in):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.downConv = nn.Conv1d(in_channels=c_in,\n",
    "                                  out_channels=c_in,\n",
    "                                  kernel_size=3,\n",
    "                                  padding=2,\n",
    "                                  padding_mode='circular')\n",
    "        self.norm = nn.BatchNorm1d(c_in)\n",
    "        self.activation = nn.ELU()\n",
    "        self.maxPool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.downConv(x.permute(0, 2, 1))\n",
    "        x = self.norm(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxPool(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        return x\n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.attention = attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        new_x, attn = self.attention(\n",
    "            x, x, x,\n",
    "            attn_mask=attn_mask\n",
    "        )\n",
    "        x = x + self.dropout(new_x)\n",
    "\n",
    "        y = x = self.norm1(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm2(x + y), attn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
    "        self.norm = norm_layer\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        # x [B, L, D]\n",
    "        attns = []\n",
    "        if self.conv_layers is not None:\n",
    "            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
    "                x = conv_layer(x)\n",
    "                attns.append(attn)\n",
    "            x, attn = self.attn_layers[-1](x)\n",
    "            attns.append(attn)\n",
    "        else:\n",
    "            for attn_layer in self.attn_layers:\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
    "                attns.append(attn)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        return x, attns\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n",
    "                 dropout=0.1, activation=\"relu\"):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.self_attention = self_attention\n",
    "        self.cross_attention = cross_attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None):\n",
    "        x = x + self.dropout(self.self_attention(\n",
    "            x, x, x,\n",
    "            attn_mask=x_mask\n",
    "        )[0])\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        x = x + self.dropout(self.cross_attention(\n",
    "            x, cross, cross,\n",
    "            attn_mask=cross_mask\n",
    "        )[0])\n",
    "\n",
    "        y = x = self.norm2(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm3(x + y)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layers, norm_layer=None, projection=None):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.norm = norm_layer\n",
    "        self.projection = projection\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        if self.projection is not None:\n",
    "            x = self.projection(x)\n",
    "        return x\n",
    "    \n",
    "#masking\n",
    "class TriangularCausalMask():\n",
    "    def __init__(self, B, L, device=\"cpu\"):\n",
    "        mask_shape = [B, 1, L, L]\n",
    "        with torch.no_grad():\n",
    "            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "\n",
    "\n",
    "class ProbMask():\n",
    "    def __init__(self, B, H, L, index, scores, device=\"cpu\"):\n",
    "        _mask = torch.ones(L, scores.shape[-1], dtype=torch.bool).to(device).triu(1)\n",
    "        _mask_ex = _mask[None, None, :].expand(B, H, L, scores.shape[-1])\n",
    "        indicator = _mask_ex[torch.arange(B)[:, None, None],\n",
    "                    torch.arange(H)[None, :, None],\n",
    "                    index, :].to(device)\n",
    "        self._mask = indicator.view(scores.shape).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "    \n",
    "# SelfAttention_Family\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from math import sqrt\n",
    "#from utils.masking import TriangularCausalMask, ProbMask\n",
    "import os\n",
    "\n",
    "\n",
    "class FullAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(FullAttention, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        scale = self.scale or 1. / sqrt(E)\n",
    "\n",
    "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n",
    "\n",
    "        if self.mask_flag:\n",
    "            if attn_mask is None:\n",
    "                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
    "\n",
    "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
    "        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return (V.contiguous(), A)\n",
    "        else:\n",
    "            return (V.contiguous(), None)\n",
    "\n",
    "\n",
    "class ProbAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(ProbAttention, self).__init__()\n",
    "        self.factor = factor\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def _prob_QK(self, Q, K, sample_k, n_top):  # n_top: c*ln(L_q)\n",
    "        # Q [B, H, L, D]\n",
    "        B, H, L_K, E = K.shape\n",
    "        _, _, L_Q, _ = Q.shape\n",
    "\n",
    "        # calculate the sampled Q_K\n",
    "        K_expand = K.unsqueeze(-3).expand(B, H, L_Q, L_K, E)\n",
    "        index_sample = torch.randint(L_K, (L_Q, sample_k))  # real U = U_part(factor*ln(L_k))*L_q\n",
    "        K_sample = K_expand[:, :, torch.arange(L_Q).unsqueeze(1), index_sample, :]\n",
    "        Q_K_sample = torch.matmul(Q.unsqueeze(-2), K_sample.transpose(-2, -1)).squeeze()\n",
    "\n",
    "        # find the Top_k query with sparisty measurement\n",
    "        M = Q_K_sample.max(-1)[0] - torch.div(Q_K_sample.sum(-1), L_K)\n",
    "        M_top = M.topk(n_top, sorted=False)[1]\n",
    "\n",
    "        # use the reduced Q to calculate Q_K\n",
    "        Q_reduce = Q[torch.arange(B)[:, None, None],\n",
    "                   torch.arange(H)[None, :, None],\n",
    "                   M_top, :]  # factor*ln(L_q)\n",
    "        Q_K = torch.matmul(Q_reduce, K.transpose(-2, -1))  # factor*ln(L_q)*L_k\n",
    "\n",
    "        return Q_K, M_top\n",
    "\n",
    "    def _get_initial_context(self, V, L_Q):\n",
    "        B, H, L_V, D = V.shape\n",
    "        if not self.mask_flag:\n",
    "            # V_sum = V.sum(dim=-2)\n",
    "            V_sum = V.mean(dim=-2)\n",
    "            contex = V_sum.unsqueeze(-2).expand(B, H, L_Q, V_sum.shape[-1]).clone()\n",
    "        else:  # use mask\n",
    "            assert (L_Q == L_V)  # requires that L_Q == L_V, i.e. for self-attention only\n",
    "            contex = V.cumsum(dim=-2)\n",
    "        return contex\n",
    "\n",
    "    def _update_context(self, context_in, V, scores, index, L_Q, attn_mask):\n",
    "        B, H, L_V, D = V.shape\n",
    "\n",
    "        if self.mask_flag:\n",
    "            attn_mask = ProbMask(B, H, L_Q, index, scores, device=V.device)\n",
    "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "        attn = torch.softmax(scores, dim=-1)  # nn.Softmax(dim=-1)(scores)\n",
    "\n",
    "        context_in[torch.arange(B)[:, None, None],\n",
    "        torch.arange(H)[None, :, None],\n",
    "        index, :] = torch.matmul(attn, V).type_as(context_in)\n",
    "        if self.output_attention:\n",
    "            attns = (torch.ones([B, H, L_V, L_V]) / L_V).type_as(attn).to(attn.device)\n",
    "            attns[torch.arange(B)[:, None, None], torch.arange(H)[None, :, None], index, :] = attn\n",
    "            return (context_in, attns)\n",
    "        else:\n",
    "            return (context_in, None)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask):\n",
    "        B, L_Q, H, D = queries.shape\n",
    "        _, L_K, _, _ = keys.shape\n",
    "\n",
    "        queries = queries.transpose(2, 1)\n",
    "        keys = keys.transpose(2, 1)\n",
    "        values = values.transpose(2, 1)\n",
    "\n",
    "        U_part = self.factor * np.ceil(np.log(L_K)).astype('int').item()  # c*ln(L_k)\n",
    "        u = self.factor * np.ceil(np.log(L_Q)).astype('int').item()  # c*ln(L_q)\n",
    "\n",
    "        U_part = U_part if U_part < L_K else L_K\n",
    "        u = u if u < L_Q else L_Q\n",
    "\n",
    "        scores_top, index = self._prob_QK(queries, keys, sample_k=U_part, n_top=u)\n",
    "\n",
    "        # add scale factor\n",
    "        scale = self.scale or 1. / sqrt(D)\n",
    "        if scale is not None:\n",
    "            scores_top = scores_top * scale\n",
    "        # get the context\n",
    "        context = self._get_initial_context(values, L_Q)\n",
    "        # update the context with selected top_k queries\n",
    "        context, attn = self._update_context(context, values, scores_top, index, L_Q, attn_mask)\n",
    "\n",
    "        return context.contiguous(), attn\n",
    "\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.inner_attention = attention\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_attention(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask\n",
    "        )\n",
    "        out = out.view(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out), attn\n",
    "    \n",
    "# Embed\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import weight_norm\n",
    "import math\n",
    "\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6, 'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        x = self.value_embedding(x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class DataEmbedding_wo_pos(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding_wo_pos, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        x = self.value_embedding(x) + self.temporal_embedding(x_mark)\n",
    "        return self.dropout(x)\n",
    "\n",
    "class DataEmbedding_wo_pos_temp(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding_wo_pos_temp, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        x = self.value_embedding(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "class DataEmbedding_wo_temp(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding_wo_temp, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd29497",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6490c8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformer\n",
    "class Transformer_Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Vanilla Transformer with O(L^2) complexity\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.output_attention = configs.output_attention\n",
    "\n",
    "        # Embedding\n",
    "        if configs.embed_type == 0:\n",
    "            self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                            configs.dropout)\n",
    "            self.dec_embedding = DataEmbedding(configs.dec_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                           configs.dropout)\n",
    "        elif configs.embed_type == 1:\n",
    "            self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                                    configs.dropout)\n",
    "            self.dec_embedding = DataEmbedding(configs.dec_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                                    configs.dropout)\n",
    "        elif configs.embed_type == 2:\n",
    "            self.enc_embedding = DataEmbedding_wo_pos(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                                    configs.dropout)\n",
    "            self.dec_embedding = DataEmbedding_wo_pos(configs.dec_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                                    configs.dropout)\n",
    "\n",
    "        elif configs.embed_type == 3:\n",
    "            self.enc_embedding = DataEmbedding_wo_temp(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                                    configs.dropout)\n",
    "            self.dec_embedding = DataEmbedding_wo_temp(configs.dec_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                                    configs.dropout)\n",
    "        elif configs.embed_type == 4:\n",
    "            self.enc_embedding = DataEmbedding_wo_pos_temp(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                                    configs.dropout)\n",
    "            self.dec_embedding = DataEmbedding_wo_pos_temp(configs.dec_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                                    configs.dropout)\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(False, configs.factor, attention_dropout=configs.dropout,\n",
    "                                      output_attention=configs.output_attention), configs.d_model, configs.n_heads),\n",
    "                    configs.d_model,\n",
    "                    configs.d_ff,\n",
    "                    dropout=configs.dropout,\n",
    "                    activation=configs.activation\n",
    "                ) for l in range(configs.e_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(configs.d_model)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(True, configs.factor, attention_dropout=configs.dropout, output_attention=False),\n",
    "                        configs.d_model, configs.n_heads),\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(False, configs.factor, attention_dropout=configs.dropout, output_attention=False),\n",
    "                        configs.d_model, configs.n_heads),\n",
    "                    configs.d_model,\n",
    "                    configs.d_ff,\n",
    "                    dropout=configs.dropout,\n",
    "                    activation=configs.activation,\n",
    "                )\n",
    "                for l in range(configs.d_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(configs.d_model),\n",
    "            projection=nn.Linear(configs.d_model, configs.c_out, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec,\n",
    "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
    "\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n",
    "\n",
    "        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n",
    "        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return dec_out[:, -self.pred_len:, :], attns\n",
    "        else:\n",
    "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc020a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd5e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16804ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger1 = TensorBoardLogger(\"jupyterNB_logs\", name=\"mymodel_96hr\")\n",
    "logger2 = CSVLogger(\"jupyterNB_logs\", name=\"mymodel_96hr_csv\")\n",
    "model = PytorchLightningModel() \n",
    "trainer = pl.Trainer(max_epochs=500 , gpus=1 , logger=logger2)\n",
    "trainer.fit(model)\n",
    "trainer.test(model)\n",
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdce2285",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'configs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2792178/3327222192.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformer_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLR\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# optimize all cnn parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL1Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# the target label is not one-hotted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# input_shape = (-1,1,28,28)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'configs'"
     ]
    }
   ],
   "source": [
    "model = Transformer_Model()\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.L1Loss()   # the target label is not one-hotted\n",
    "# input_shape = (-1,1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49890d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss = nn.L1Loss()\n",
    "input_shape = (-1,1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "536eb7bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "parameters() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2792178/2613980333.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTransformer_Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: parameters() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "list(Transformer_Model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a731f66a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "modules() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2792178/3182036823.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: modules() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "for module in model.modules():\n",
    "    print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c2423b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'configs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2792178/2829666696.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformer_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'configs'"
     ]
    }
   ],
   "source": [
    "model = Transformer_Model()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3728b0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a694b971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38104017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f50f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f09ee64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class moving_avg(nn.Module):\n",
    "    \"\"\"\n",
    "    Moving average block to highlight the trend of time series\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super(moving_avg, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # padding on the both ends of time series\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "        x = self.avg(x.permute(0, 2, 1))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class series_decomp(nn.Module):\n",
    "    \"\"\"\n",
    "    Series decomposition block\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp, self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        res = x - moving_mean\n",
    "        return res, moving_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c64f679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dlinear\n",
    "class DLinear_Model(nn.Module):\n",
    "    \"\"\"\n",
    "    DLinear\n",
    "    \"\"\"\n",
    "    def __init__(self, configs):\n",
    "        super(Model, self).__init__()\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.pred_len = configs.pred_len\n",
    "\n",
    "        # Decompsition Kernel Size\n",
    "        kernel_size = 25\n",
    "        self.decompsition = series_decomp(kernel_size)\n",
    "        self.individual = configs.individual\n",
    "        self.channels = configs.enc_in\n",
    "\n",
    "        if self.individual:\n",
    "            self.Linear_Seasonal = nn.ModuleList()\n",
    "            self.Linear_Trend = nn.ModuleList()\n",
    "            self.Linear_Decoder = nn.ModuleList()\n",
    "            for i in range(self.channels):\n",
    "                self.Linear_Seasonal.append(nn.Linear(self.seq_len,self.pred_len))\n",
    "                self.Linear_Seasonal[i].weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
    "                self.Linear_Trend.append(nn.Linear(self.seq_len,self.pred_len))\n",
    "                self.Linear_Trend[i].weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
    "                self.Linear_Decoder.append(nn.Linear(self.seq_len,self.pred_len))\n",
    "        else:\n",
    "            self.Linear_Seasonal = nn.Linear(self.seq_len,self.pred_len)\n",
    "            self.Linear_Trend = nn.Linear(self.seq_len,self.pred_len)\n",
    "            self.Linear_Decoder = nn.Linear(self.seq_len,self.pred_len)\n",
    "            self.Linear_Seasonal.weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
    "            self.Linear_Trend.weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [Batch, Input length, Channel]\n",
    "        seasonal_init, trend_init = self.decompsition(x)\n",
    "        seasonal_init, trend_init = seasonal_init.permute(0,2,1), trend_init.permute(0,2,1)\n",
    "        if self.individual:\n",
    "            seasonal_output = torch.zeros([seasonal_init.size(0),seasonal_init.size(1),self.pred_len],dtype=seasonal_init.dtype).to(seasonal_init.device)\n",
    "            trend_output = torch.zeros([trend_init.size(0),trend_init.size(1),self.pred_len],dtype=trend_init.dtype).to(trend_init.device)\n",
    "            for i in range(self.channels):\n",
    "                seasonal_output[:,i,:] = self.Linear_Seasonal[i](seasonal_init[:,i,:])\n",
    "                trend_output[:,i,:] = self.Linear_Trend[i](trend_init[:,i,:])\n",
    "        else:\n",
    "            seasonal_output = self.Linear_Seasonal(seasonal_init)\n",
    "            trend_output = self.Linear_Trend(trend_init)\n",
    "\n",
    "        x = seasonal_output + trend_output\n",
    "        return x.permute(0,2,1) # to [Batch, Output length, Channel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da7c39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d8bcee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc65035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6509dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba4507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce6df4ad",
   "metadata": {},
   "source": [
    "# Pytorch 內建的 Transformer Model ? (example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39dd3277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([485, 5183])\n",
      "torch.Size([485, 5183])\n",
      "torch.Size([120, 5183])\n",
      "torch.Size([120, 5183])\n",
      "torch.Size([120, 5183])\n",
      "torch.Size([120, 5183])\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.from_numpy(Xhat_train).float()\n",
    "y_train = torch.from_numpy(Yhat_train).float()\n",
    "x_val = torch.from_numpy(Xhat_val).float()\n",
    "y_val = torch.from_numpy(Yhat_val).float()\n",
    "x_test = torch.from_numpy(Xhat_test).float()\n",
    "y_test = torch.from_numpy(Yhat_test).float()\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(x_val))\n",
    "print(np.shape(y_val))\n",
    "print(np.shape(x_test))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf56d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = nn.Transformer(nhead=32, num_encoder_layers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9711a79d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 485, 5183]' is invalid for input of size 2513755",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1563678/3781564224.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m485\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5183\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m485\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5183\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[2, 485, 5183]' is invalid for input of size 2513755"
     ]
    }
   ],
   "source": [
    "src = x_train.reshape(1,485,5183)\n",
    "tgt = y_train.reshape(,485,5183)\n",
    "print(np.shape(src))\n",
    "print(np.shape(tgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d50f55b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "the feature number of src and tgt must be equal to d_model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1563678/1148311185.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/chou/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/chou/lib/python3.7/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the feature number of src and tgt must be equal to d_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: the feature number of src and tgt must be equal to d_model"
     ]
    }
   ],
   "source": [
    "out = transformer_model(src, tgt)\n",
    "print(np.shape(out))\n",
    "print(np.shape(out[0]))\n",
    "print(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a988045c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 32, 512])\n"
     ]
    }
   ],
   "source": [
    "src = torch.rand((10, 32, 512))\n",
    "tgt = torch.rand((20, 32, 512))\n",
    "out = transformer_model(src, tgt)\n",
    "print(np.shape(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9fa9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chou",
   "language": "python",
   "name": "chou"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
