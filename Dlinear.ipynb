{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b11ead6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luhung3080/miniconda3/envs/chou/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch ver .  1.11.0+cu113\n",
      "Is CUDA available? True\n",
      "pynio ver .  1.5.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "print(\"pytorch ver . \",torch.__version__)\n",
    "print(\"Is CUDA available?\",torch.cuda.is_available())\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.utils.data as Data\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import xarray as xr\n",
    "import os\n",
    "os.environ['R_HOME'] = '/home/luhung3080/miniconda3/envs/chou/lib/R'\n",
    "from rpy2.robjects import r, numpy2ri\n",
    "numpy2ri.activate()\n",
    "from rpy2.robjects.packages import importr\n",
    "sinkr = importr('sinkr')\n",
    "import Nio\n",
    "print (\"pynio ver . \",Nio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76af21d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('/home/luhung3080/Desktop/PycharmProjects/Data/newdata/result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfc5b209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 5183)\n",
      "(605, 5183)\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "#cal_PMf\n",
    "###\n",
    "u=np.zeros([605,5183])\n",
    "for i in range (0,605):\n",
    "    a=np.array(data['VALUE'][5183*i:5183*i+5183])\n",
    "    for j in range(0,5183):\n",
    "        if a[j]=='NaN' :\n",
    "            a[j]=np.nan\n",
    "    u[i]=a.T\n",
    "print(np.shape(u))\n",
    "###\n",
    "#obs_PMf\n",
    "###\n",
    "v=np.zeros([605,5183])\n",
    "for i in range (0,605):\n",
    "    a=np.array(data['OBS_VALUE'][5183*i:5183*i+5183])\n",
    "    for j in range(0,5183):\n",
    "        if a[j]=='NaN' :\n",
    "            a[j]=np.nan\n",
    "        if a[j]=='A' :\n",
    "            a[j]=np.nan\n",
    "        if a[j]=='*' :\n",
    "            a[j]=np.nan\n",
    "        if a[j]=='x' :\n",
    "            a[j]=np.nan  \n",
    "    v[i]=a.T\n",
    "    \n",
    "print(np.shape(v)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4608c25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"1 EOF ; RMS = 7.7208659\"\n",
      "[1] \"1 EOF ; RMS = 7.71915256\"\n",
      "[1] \"1 EOF ; RMS = 7.71918485\"\n",
      "[1] \"2 EOF ; RMS = 6.84092556\"\n",
      "[1] \"2 EOF ; RMS = 6.84127094\"\n",
      "[1] \"3 EOF ; RMS = 6.47602412\"\n",
      "[1] \"3 EOF ; RMS = 6.4755135\"\n",
      "[1] \"3 EOF ; RMS = 6.47549855\"\n",
      "[1] \"3 EOF ; RMS = 6.47549755\"\n",
      "[1] \"4 EOF ; RMS = 6.2521219\"\n",
      "[1] \"4 EOF ; RMS = 6.25305477\"\n",
      "[1] \"5 EOF ; RMS = 6.04839426\"\n",
      "[1] \"5 EOF ; RMS = 6.0478386\"\n",
      "[1] \"5 EOF ; RMS = 6.047815\"\n",
      "[1] \"5 EOF ; RMS = 6.04781352\"\n",
      "[1] \"6 EOF ; RMS = 5.86823128\"\n",
      "[1] \"6 EOF ; RMS = 5.867931\"\n",
      "[1] \"6 EOF ; RMS = 5.86791602\"\n",
      "[1] \"6 EOF ; RMS = 5.86791411\"\n",
      "[1] \"7 EOF ; RMS = 5.71967578\"\n",
      "[1] \"7 EOF ; RMS = 5.71951606\"\n",
      "[1] \"7 EOF ; RMS = 5.71952637\"\n",
      "[1] \"8 EOF ; RMS = 5.599724\"\n",
      "[1] \"8 EOF ; RMS = 5.60085644\"\n",
      "[1] \"9 EOF ; RMS = 5.48613601\"\n",
      "[1] \"9 EOF ; RMS = 5.48675208\"\n",
      "[1] \"10 EOF ; RMS = 5.37241577\"\n",
      "[1] \"10 EOF ; RMS = 5.37204237\"\n",
      "[1] \"10 EOF ; RMS = 5.37202159\"\n",
      "[1] \"10 EOF ; RMS = 5.37201994\"\n",
      "[1] \"11 EOF ; RMS = 5.27154662\"\n",
      "[1] \"11 EOF ; RMS = 5.27202257\"\n",
      "[1] \"12 EOF ; RMS = 5.19161954\"\n",
      "[1] \"12 EOF ; RMS = 5.19209056\"\n",
      "[1] \"13 EOF ; RMS = 5.12637454\"\n",
      "[1] \"13 EOF ; RMS = 5.12754655\"\n",
      "[1] \"14 EOF ; RMS = 5.06098994\"\n",
      "[1] \"14 EOF ; RMS = 5.06213366\"\n",
      "[1] \"15 EOF ; RMS = 5.00413519\"\n",
      "[1] \"15 EOF ; RMS = 5.00495858\"\n",
      "[1] \"16 EOF ; RMS = 4.94603134\"\n",
      "[1] \"16 EOF ; RMS = 4.94701261\"\n",
      "[1] \"17 EOF ; RMS = 4.89352104\"\n",
      "[1] \"17 EOF ; RMS = 4.89507562\"\n",
      "[1] \"18 EOF ; RMS = 4.84381542\"\n",
      "[1] \"18 EOF ; RMS = 4.84508437\"\n",
      "[1] \"19 EOF ; RMS = 4.79928244\"\n",
      "[1] \"19 EOF ; RMS = 4.80010668\"\n",
      "[1] \"20 EOF ; RMS = 4.76104087\"\n",
      "[1] \"20 EOF ; RMS = 4.76200701\"\n",
      "[1] \"21 EOF ; RMS = 4.72522742\"\n",
      "[1] \"21 EOF ; RMS = 4.72683535\"\n",
      "[1] \"22 EOF ; RMS = 4.68453149\"\n",
      "[1] \"22 EOF ; RMS = 4.68497842\"\n",
      "[1] \"23 EOF ; RMS = 4.63998952\"\n",
      "[1] \"23 EOF ; RMS = 4.64069214\"\n",
      "[1] \"24 EOF ; RMS = 4.60836155\"\n",
      "[1] \"24 EOF ; RMS = 4.60936238\"\n",
      "[1] \"25 EOF ; RMS = 4.5709364\"\n",
      "[1] \"25 EOF ; RMS = 4.57114581\"\n",
      "[1] \"26 EOF ; RMS = 4.53894596\"\n",
      "[1] \"26 EOF ; RMS = 4.53963795\"\n",
      "[1] \"27 EOF ; RMS = 4.50677436\"\n",
      "[1] \"27 EOF ; RMS = 4.5074194\"\n",
      "[1] \"28 EOF ; RMS = 4.47465932\"\n",
      "[1] \"28 EOF ; RMS = 4.47507046\"\n",
      "[1] \"29 EOF ; RMS = 4.44770601\"\n",
      "[1] \"29 EOF ; RMS = 4.44847665\"\n",
      "[1] \"30 EOF ; RMS = 4.42127819\"\n",
      "[1] \"30 EOF ; RMS = 4.42204768\"\n",
      "[1] \"31 EOF ; RMS = 4.40236948\"\n",
      "[1] \"31 EOF ; RMS = 4.40390949\"\n",
      "[1] \"32 EOF ; RMS = 4.3838255\"\n",
      "[1] \"32 EOF ; RMS = 4.38533006\"\n",
      "[1] \"33 EOF ; RMS = 4.3629226\"\n",
      "[1] \"33 EOF ; RMS = 4.36375455\"\n",
      "[1] \"34 EOF ; RMS = 4.34386127\"\n",
      "[1] \"34 EOF ; RMS = 4.34503175\"\n",
      "[1] \"35 EOF ; RMS = 4.31865278\"\n",
      "[1] \"35 EOF ; RMS = 4.31877775\"\n",
      "[1] \"36 EOF ; RMS = 4.29100359\"\n",
      "[1] \"36 EOF ; RMS = 4.29146193\"\n",
      "[1] \"37 EOF ; RMS = 4.26608532\"\n",
      "[1] \"37 EOF ; RMS = 4.26664\"\n",
      "[1] \"38 EOF ; RMS = 4.24682715\"\n",
      "[1] \"38 EOF ; RMS = 4.24721095\"\n",
      "[1] \"39 EOF ; RMS = 4.22916224\"\n",
      "[1] \"39 EOF ; RMS = 4.22997545\"\n",
      "[1] \"40 EOF ; RMS = 4.20837924\"\n",
      "[1] \"40 EOF ; RMS = 4.20915082\"\n",
      "[1] \"41 EOF ; RMS = 4.1931553\"\n",
      "[1] \"41 EOF ; RMS = 4.19458465\"\n",
      "[1] \"42 EOF ; RMS = 4.18070232\"\n",
      "[1] \"42 EOF ; RMS = 4.18260421\"\n",
      "[1] \"43 EOF ; RMS = 4.16820017\"\n",
      "[1] \"43 EOF ; RMS = 4.17043243\"\n",
      "[1] \"44 EOF ; RMS = 4.15426635\"\n",
      "[1] \"44 EOF ; RMS = 4.15468267\"\n",
      "[1] \"45 EOF ; RMS = 4.14104655\"\n",
      "[1] \"45 EOF ; RMS = 4.14277557\"\n",
      "[1] \"46 EOF ; RMS = 4.12969696\"\n",
      "[1] \"46 EOF ; RMS = 4.13106114\"\n",
      "[1] \"47 EOF ; RMS = 4.11746723\"\n",
      "[1] \"47 EOF ; RMS = 4.11871718\"\n",
      "[1] \"48 EOF ; RMS = 4.10580895\"\n",
      "[1] \"48 EOF ; RMS = 4.10736898\"\n",
      "[1] \"49 EOF ; RMS = 4.09371739\"\n",
      "[1] \"49 EOF ; RMS = 4.09487614\"\n",
      "[1] \"50 EOF ; RMS = 4.08250504\"\n",
      "[1] \"50 EOF ; RMS = 4.08432423\"\n",
      "[1] \"51 EOF ; RMS = 4.07240924\"\n",
      "[1] \"51 EOF ; RMS = 4.07403435\"\n",
      "[1] \"52 EOF ; RMS = 4.06028721\"\n",
      "[1] \"52 EOF ; RMS = 4.06201354\"\n",
      "[1] \"53 EOF ; RMS = 4.04489998\"\n",
      "[1] \"53 EOF ; RMS = 4.04560057\"\n",
      "[1] \"54 EOF ; RMS = 4.02941754\"\n",
      "[1] \"54 EOF ; RMS = 4.02965198\"\n",
      "[1] \"55 EOF ; RMS = 4.01150337\"\n",
      "[1] \"55 EOF ; RMS = 4.01182927\"\n",
      "[1] \"56 EOF ; RMS = 3.99706063\"\n",
      "[1] \"56 EOF ; RMS = 3.99729505\"\n",
      "[1] \"57 EOF ; RMS = 3.98912707\"\n",
      "[1] \"57 EOF ; RMS = 3.99096949\"\n",
      "[1] \"58 EOF ; RMS = 3.98229412\"\n",
      "[1] \"58 EOF ; RMS = 3.98435825\"\n",
      "[1] \"59 EOF ; RMS = 3.9754879\"\n",
      "[1] \"59 EOF ; RMS = 3.97766037\"\n",
      "[1] \"60 EOF ; RMS = 3.97033714\"\n",
      "[1] \"60 EOF ; RMS = 3.97226452\"\n",
      "[1] \"61 EOF ; RMS = 3.95799395\"\n",
      "[1] \"61 EOF ; RMS = 3.95850074\"\n",
      "[1] \"62 EOF ; RMS = 3.94710128\"\n",
      "[1] \"62 EOF ; RMS = 3.94810586\"\n",
      "[1] \"63 EOF ; RMS = 3.94300562\"\n",
      "[1] \"63 EOF ; RMS = 3.94581873\"\n",
      "[1] \"64 EOF ; RMS = 3.93981302\"\n",
      "[1] \"64 EOF ; RMS = 3.94220977\"\n",
      "[1] \"65 EOF ; RMS = 3.93437433\"\n",
      "[1] \"65 EOF ; RMS = 3.9363764\"\n",
      "[1] \"66 EOF ; RMS = 3.93080202\"\n",
      "[1] \"66 EOF ; RMS = 3.9330804\"\n",
      "[1] \"67 EOF ; RMS = 3.92728216\"\n",
      "[1] \"67 EOF ; RMS = 3.92972717\"\n",
      "[1] \"68 EOF ; RMS = 3.91941025\"\n",
      "[1] \"68 EOF ; RMS = 3.9206996\"\n",
      "[1] \"69 EOF ; RMS = 3.91125852\"\n",
      "[1] \"69 EOF ; RMS = 3.91227254\"\n",
      "[1] \"70 EOF ; RMS = 3.90051921\"\n",
      "[1] \"70 EOF ; RMS = 3.90106003\"\n",
      "[1] \"71 EOF ; RMS = 3.8882414\"\n",
      "[1] \"71 EOF ; RMS = 3.88861655\"\n",
      "[1] \"72 EOF ; RMS = 3.88227274\"\n",
      "[1] \"72 EOF ; RMS = 3.88400835\"\n",
      "[1] \"73 EOF ; RMS = 3.88009013\"\n",
      "[1] \"73 EOF ; RMS = 3.88275277\"\n",
      "[1] \"74 EOF ; RMS = 3.87778729\"\n",
      "[1] \"74 EOF ; RMS = 3.8800647\"\n",
      "[1] \"75 EOF ; RMS = 3.87358302\"\n",
      "[1] \"75 EOF ; RMS = 3.87534877\"\n",
      "[1] \"76 EOF ; RMS = 3.87129396\"\n",
      "[1] \"76 EOF ; RMS = 3.87379284\"\n",
      "[1] \"77 EOF ; RMS = 3.86645981\"\n",
      "[1] \"77 EOF ; RMS = 3.86817124\"\n",
      "[1] \"78 EOF ; RMS = 3.85985045\"\n",
      "[1] \"78 EOF ; RMS = 3.86189825\"\n",
      "[1] \"79 EOF ; RMS = 3.85443286\"\n",
      "[1] \"79 EOF ; RMS = 3.85590046\"\n",
      "[1] \"80 EOF ; RMS = 3.85099841\"\n",
      "[1] \"80 EOF ; RMS = 3.85362327\"\n",
      "[1] \"81 EOF ; RMS = 3.84808855\"\n",
      "[1] \"81 EOF ; RMS = 3.85028521\"\n",
      "[1] \"82 EOF ; RMS = 3.84342475\"\n",
      "[1] \"82 EOF ; RMS = 3.84532739\"\n",
      "[1] \"83 EOF ; RMS = 3.84194804\"\n",
      "[1] \"83 EOF ; RMS = 3.84535546\"\n",
      "[1] \"84 EOF ; RMS = 3.84010621\"\n",
      "[1] \"84 EOF ; RMS = 3.84233352\"\n",
      "[1] \"85 EOF ; RMS = 3.83319667\"\n",
      "[1] \"85 EOF ; RMS = 3.83349239\"\n",
      "[1] \"86 EOF ; RMS = 3.82490117\"\n",
      "[1] \"86 EOF ; RMS = 3.82553102\"\n",
      "[1] \"87 EOF ; RMS = 3.81970246\"\n",
      "[1] \"87 EOF ; RMS = 3.82089396\"\n",
      "[1] \"88 EOF ; RMS = 3.81568338\"\n",
      "[1] \"88 EOF ; RMS = 3.81717179\"\n",
      "[1] \"89 EOF ; RMS = 3.81465961\"\n",
      "[1] \"89 EOF ; RMS = 3.81767411\"\n",
      "[1] \"90 EOF ; RMS = 3.81341293\"\n",
      "[1] \"90 EOF ; RMS = 3.81578669\"\n",
      "[1] \"91 EOF ; RMS = 3.81370618\"\n",
      "[1] \"91 EOF ; RMS = 3.81654562\"\n",
      "[1] \"92 EOF ; RMS = 3.81089886\"\n",
      "[1] \"92 EOF ; RMS = 3.81343504\"\n",
      "[1] \"93 EOF ; RMS = 3.81030652\"\n",
      "[1] \"93 EOF ; RMS = 3.81333511\"\n",
      "[1] \"94 EOF ; RMS = 3.80702496\"\n",
      "[1] \"94 EOF ; RMS = 3.80860672\"\n",
      "[1] \"95 EOF ; RMS = 3.80446742\"\n",
      "[1] \"95 EOF ; RMS = 3.80672427\"\n",
      "[1] \"96 EOF ; RMS = 3.80141848\"\n",
      "[1] \"96 EOF ; RMS = 3.8030161\"\n",
      "[1] \"97 EOF ; RMS = 3.79989461\"\n",
      "[1] \"97 EOF ; RMS = 3.80168849\"\n",
      "[1] \"98 EOF ; RMS = 3.79553633\"\n",
      "[1] \"98 EOF ; RMS = 3.79699439\"\n",
      "[1] \"99 EOF ; RMS = 3.79475525\"\n",
      "[1] \"99 EOF ; RMS = 3.79783416\"\n",
      "[1] \"100 EOF ; RMS = 3.79207743\"\n",
      "[1] \"100 EOF ; RMS = 3.79345374\"\n",
      "[1] \"101 EOF ; RMS = 3.7864091\"\n",
      "[1] \"101 EOF ; RMS = 3.78728712\"\n",
      "[1] \"102 EOF ; RMS = 3.78417151\"\n",
      "[1] \"102 EOF ; RMS = 3.78662342\"\n",
      "[1] \"103 EOF ; RMS = 3.78213585\"\n",
      "[1] \"103 EOF ; RMS = 3.78404375\"\n",
      "[1] \"104 EOF ; RMS = 3.77894323\"\n",
      "[1] \"104 EOF ; RMS = 3.78102089\"\n",
      "[1] \"105 EOF ; RMS = 3.77578054\"\n",
      "[1] \"105 EOF ; RMS = 3.77714138\"\n",
      "[1] \"106 EOF ; RMS = 3.7724972\"\n",
      "[1] \"106 EOF ; RMS = 3.77404485\"\n",
      "[1] \"107 EOF ; RMS = 3.76939861\"\n",
      "[1] \"107 EOF ; RMS = 3.77074748\"\n",
      "[1] \"108 EOF ; RMS = 3.76646903\"\n",
      "[1] \"108 EOF ; RMS = 3.76876687\"\n",
      "[1] \"109 EOF ; RMS = 3.76294101\"\n",
      "[1] \"109 EOF ; RMS = 3.76475977\"\n",
      "[1] \"110 EOF ; RMS = 3.7616847\"\n",
      "[1] \"110 EOF ; RMS = 3.76393494\"\n",
      "[1] \"111 EOF ; RMS = 3.76042206\"\n",
      "[1] \"111 EOF ; RMS = 3.76223535\"\n",
      "[1] \"112 EOF ; RMS = 3.75782228\"\n",
      "[1] \"112 EOF ; RMS = 3.75942886\"\n",
      "[1] \"113 EOF ; RMS = 3.75380169\"\n",
      "[1] \"113 EOF ; RMS = 3.7551596\"\n",
      "[1] \"114 EOF ; RMS = 3.7530223\"\n",
      "[1] \"114 EOF ; RMS = 3.75563741\"\n",
      "[1] \"115 EOF ; RMS = 3.75006337\"\n",
      "[1] \"115 EOF ; RMS = 3.75106786\"\n",
      "[1] \"116 EOF ; RMS = 3.74764374\"\n",
      "[1] \"116 EOF ; RMS = 3.74922288\"\n",
      "[1] \"117 EOF ; RMS = 3.74245109\"\n",
      "[1] \"117 EOF ; RMS = 3.74338897\"\n",
      "[1] \"118 EOF ; RMS = 3.73993338\"\n",
      "[1] \"118 EOF ; RMS = 3.74185524\"\n",
      "[1] \"119 EOF ; RMS = 3.73642277\"\n",
      "[1] \"119 EOF ; RMS = 3.7378773\"\n",
      "[1] \"120 EOF ; RMS = 3.7321578\"\n",
      "[1] \"120 EOF ; RMS = 3.73383868\"\n",
      "[1] \"121 EOF ; RMS = 3.73045327\"\n",
      "[1] \"121 EOF ; RMS = 3.73261166\"\n",
      "[1] \"122 EOF ; RMS = 3.72855678\"\n",
      "[1] \"122 EOF ; RMS = 3.73035877\"\n",
      "[1] \"123 EOF ; RMS = 3.72622688\"\n",
      "[1] \"123 EOF ; RMS = 3.72806963\"\n",
      "[1] \"124 EOF ; RMS = 3.72575047\"\n",
      "[1] \"124 EOF ; RMS = 3.72874231\"\n",
      "[1] \"125 EOF ; RMS = 3.72499132\"\n",
      "[1] \"125 EOF ; RMS = 3.72714834\"\n",
      "[1] \"126 EOF ; RMS = 3.72538218\"\n",
      "[1] \"126 EOF ; RMS = 3.72805756\"\n",
      "[1] \"127 EOF ; RMS = 3.72677186\"\n",
      "[1] \"127 EOF ; RMS = 3.7303696\"\n",
      "[1] \"128 EOF ; RMS = 3.73174945\"\n",
      "[1] \"1 EOF ; RMS = 7.93972988\"\n",
      "[1] \"1 EOF ; RMS = 7.91889292\"\n",
      "[1] \"1 EOF ; RMS = 7.91917741\"\n",
      "[1] \"2 EOF ; RMS = 7.23175493\"\n",
      "[1] \"2 EOF ; RMS = 7.2315802\"\n",
      "[1] \"2 EOF ; RMS = 7.23168227\"\n",
      "[1] \"3 EOF ; RMS = 6.82849018\"\n",
      "[1] \"3 EOF ; RMS = 6.82967887\"\n",
      "[1] \"4 EOF ; RMS = 6.60575024\"\n",
      "[1] \"4 EOF ; RMS = 6.60708579\"\n",
      "[1] \"5 EOF ; RMS = 6.38271888\"\n",
      "[1] \"5 EOF ; RMS = 6.3821266\"\n",
      "[1] \"5 EOF ; RMS = 6.38202754\"\n",
      "[1] \"5 EOF ; RMS = 6.38196079\"\n",
      "[1] \"5 EOF ; RMS = 6.38192531\"\n",
      "[1] \"5 EOF ; RMS = 6.38190803\"\n",
      "[1] \"5 EOF ; RMS = 6.38189991\"\n",
      "[1] \"6 EOF ; RMS = 6.19143424\"\n",
      "[1] \"6 EOF ; RMS = 6.19381411\"\n",
      "[1] \"7 EOF ; RMS = 6.04996509\"\n",
      "[1] \"7 EOF ; RMS = 6.05149446\"\n",
      "[1] \"8 EOF ; RMS = 5.93489619\"\n",
      "[1] \"8 EOF ; RMS = 5.93662351\"\n",
      "[1] \"9 EOF ; RMS = 5.84405867\"\n",
      "[1] \"9 EOF ; RMS = 5.84452834\"\n",
      "[1] \"10 EOF ; RMS = 5.74327945\"\n",
      "[1] \"10 EOF ; RMS = 5.74301896\"\n",
      "[1] \"10 EOF ; RMS = 5.74309808\"\n",
      "[1] \"11 EOF ; RMS = 5.65520114\"\n",
      "[1] \"11 EOF ; RMS = 5.65529417\"\n",
      "[1] \"12 EOF ; RMS = 5.56983397\"\n",
      "[1] \"12 EOF ; RMS = 5.57035019\"\n",
      "[1] \"13 EOF ; RMS = 5.50827349\"\n",
      "[1] \"13 EOF ; RMS = 5.51058273\"\n",
      "[1] \"14 EOF ; RMS = 5.45839446\"\n",
      "[1] \"14 EOF ; RMS = 5.45966205\"\n",
      "[1] \"15 EOF ; RMS = 5.41716518\"\n",
      "[1] \"15 EOF ; RMS = 5.41876675\"\n",
      "[1] \"16 EOF ; RMS = 5.36900727\"\n",
      "[1] \"16 EOF ; RMS = 5.36956088\"\n",
      "[1] \"17 EOF ; RMS = 5.33021928\"\n",
      "[1] \"17 EOF ; RMS = 5.33158834\"\n",
      "[1] \"18 EOF ; RMS = 5.30413636\"\n",
      "[1] \"18 EOF ; RMS = 5.30627156\"\n",
      "[1] \"19 EOF ; RMS = 5.27988139\"\n",
      "[1] \"19 EOF ; RMS = 5.28198832\"\n",
      "[1] \"20 EOF ; RMS = 5.25029419\"\n",
      "[1] \"20 EOF ; RMS = 5.25231089\"\n",
      "[1] \"21 EOF ; RMS = 5.21991891\"\n",
      "[1] \"21 EOF ; RMS = 5.22087461\"\n",
      "[1] \"22 EOF ; RMS = 5.18303006\"\n",
      "[1] \"22 EOF ; RMS = 5.18378495\"\n",
      "[1] \"23 EOF ; RMS = 5.14654129\"\n",
      "[1] \"23 EOF ; RMS = 5.14720392\"\n",
      "[1] \"24 EOF ; RMS = 5.12394372\"\n",
      "[1] \"24 EOF ; RMS = 5.1259915\"\n",
      "[1] \"25 EOF ; RMS = 5.09706179\"\n",
      "[1] \"25 EOF ; RMS = 5.09838969\"\n",
      "[1] \"26 EOF ; RMS = 5.0724413\"\n",
      "[1] \"26 EOF ; RMS = 5.07504431\"\n",
      "[1] \"27 EOF ; RMS = 5.05564253\"\n",
      "[1] \"27 EOF ; RMS = 5.05806577\"\n",
      "[1] \"28 EOF ; RMS = 5.04696547\"\n",
      "[1] \"28 EOF ; RMS = 5.05061484\"\n",
      "[1] \"29 EOF ; RMS = 5.02928005\"\n",
      "[1] \"29 EOF ; RMS = 5.03065433\"\n",
      "[1] \"30 EOF ; RMS = 5.00469818\"\n",
      "[1] \"30 EOF ; RMS = 5.0051957\"\n",
      "[1] \"31 EOF ; RMS = 4.98608555\"\n",
      "[1] \"31 EOF ; RMS = 4.98877255\"\n",
      "[1] \"32 EOF ; RMS = 4.96442683\"\n",
      "[1] \"32 EOF ; RMS = 4.96725297\"\n",
      "[1] \"33 EOF ; RMS = 4.94909685\"\n",
      "[1] \"33 EOF ; RMS = 4.9509607\"\n",
      "[1] \"34 EOF ; RMS = 4.94370217\"\n",
      "[1] \"34 EOF ; RMS = 4.94730299\"\n",
      "[1] \"35 EOF ; RMS = 4.93276353\"\n",
      "[1] \"35 EOF ; RMS = 4.93586976\"\n",
      "[1] \"36 EOF ; RMS = 4.91844643\"\n",
      "[1] \"36 EOF ; RMS = 4.92031332\"\n",
      "[1] \"37 EOF ; RMS = 4.89962671\"\n",
      "[1] \"37 EOF ; RMS = 4.89980515\"\n",
      "[1] \"38 EOF ; RMS = 4.8844737\"\n",
      "[1] \"38 EOF ; RMS = 4.88628491\"\n",
      "[1] \"39 EOF ; RMS = 4.87954924\"\n",
      "[1] \"39 EOF ; RMS = 4.88410445\"\n",
      "[1] \"40 EOF ; RMS = 4.8689584\"\n",
      "[1] \"40 EOF ; RMS = 4.87148754\"\n",
      "[1] \"41 EOF ; RMS = 4.86119629\"\n",
      "[1] \"41 EOF ; RMS = 4.8645818\"\n",
      "[1] \"42 EOF ; RMS = 4.85304042\"\n",
      "[1] \"42 EOF ; RMS = 4.85627306\"\n",
      "[1] \"43 EOF ; RMS = 4.84503391\"\n",
      "[1] \"43 EOF ; RMS = 4.84768476\"\n",
      "[1] \"44 EOF ; RMS = 4.83122746\"\n",
      "[1] \"44 EOF ; RMS = 4.83101864\"\n",
      "[1] \"44 EOF ; RMS = 4.83113521\"\n",
      "[1] \"45 EOF ; RMS = 4.82333978\"\n",
      "[1] \"45 EOF ; RMS = 4.82649348\"\n",
      "[1] \"46 EOF ; RMS = 4.81875141\"\n",
      "[1] \"46 EOF ; RMS = 4.82246092\"\n",
      "[1] \"47 EOF ; RMS = 4.81702307\"\n",
      "[1] \"47 EOF ; RMS = 4.82105348\"\n",
      "[1] \"48 EOF ; RMS = 4.81077591\"\n",
      "[1] \"48 EOF ; RMS = 4.81242859\"\n",
      "[1] \"49 EOF ; RMS = 4.80289569\"\n",
      "[1] \"49 EOF ; RMS = 4.80434488\"\n",
      "[1] \"50 EOF ; RMS = 4.80099591\"\n",
      "[1] \"50 EOF ; RMS = 4.80575735\"\n",
      "[1] \"51 EOF ; RMS = 4.79351918\"\n",
      "[1] \"51 EOF ; RMS = 4.79525996\"\n",
      "[1] \"52 EOF ; RMS = 4.78932065\"\n",
      "[1] \"52 EOF ; RMS = 4.79382877\"\n",
      "[1] \"53 EOF ; RMS = 4.78818005\"\n",
      "[1] \"53 EOF ; RMS = 4.79236101\"\n",
      "[1] \"54 EOF ; RMS = 4.78907021\"\n",
      "[1] \"54 EOF ; RMS = 4.79469044\"\n",
      "[1] \"55 EOF ; RMS = 4.79373782\"\n",
      "[1] \"55 EOF ; RMS = 4.79892407\"\n",
      "[1] \"56 EOF ; RMS = 4.79462957\"\n",
      "[1] \"56 EOF ; RMS = 4.79888642\"\n",
      "[1] \"57 EOF ; RMS = 4.79120942\"\n",
      "[1] \"57 EOF ; RMS = 4.79365936\"\n",
      "[1] \"58 EOF ; RMS = 4.79382181\"\n"
     ]
    }
   ],
   "source": [
    "XRestruct=sinkr.dineof(u)\n",
    "YRestruct=sinkr.dineof(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ceda5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 5183)\n",
      "(605, 5183)\n"
     ]
    }
   ],
   "source": [
    "XRestruct_Fun=np.array(XRestruct[0])\n",
    "YRestruct_Fun=np.array(YRestruct[0])\n",
    "print(np.shape(XRestruct_Fun))\n",
    "print(np.shape(YRestruct_Fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fac013b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xhat_train\n",
      "(485, 5183)\n",
      "Yhat_train\n",
      "(485, 5183)\n",
      "Xhat_val\n",
      "(120, 5183)\n",
      "Yhat_val\n",
      "(120, 5183)\n",
      "Xhat_test\n",
      "(120, 5183)\n",
      "Yhat_test\n",
      "(120, 5183)\n"
     ]
    }
   ],
   "source": [
    "Xhat=XRestruct_Fun\n",
    "Yhat=YRestruct_Fun\n",
    "Xhat_train = np.zeros([485,5183])\n",
    "Yhat_train = np.zeros([485,5183])\n",
    "Xhat_val = np.zeros([120,5183])\n",
    "Yhat_val = np.zeros([120,5183])\n",
    "Xhat_test = np.zeros([120,5183])\n",
    "Yhat_test = np.zeros([120,5183])\n",
    "\n",
    "for i in range (0,485):\n",
    "    for j in range (0,5183):    \n",
    "        Xhat_train[i][j] = Xhat[i][j]\n",
    "        Yhat_train[i][j] = Yhat[i][j]\n",
    "        \n",
    "for i in range (485,605):\n",
    "    for j in range (0,5183):\n",
    "        Xhat_val[i-485][j] = Xhat[i][j]\n",
    "        Yhat_val[i-485][j] = Yhat[i][j]     \n",
    "        \n",
    "for i in range (485,605):\n",
    "    for j in range (0,5183):\n",
    "        Xhat_test[i-485][j] = Xhat[i][j]\n",
    "        Yhat_test[i-485][j] = Yhat[i][j]\n",
    "print('Xhat_train')\n",
    "print(np.shape(Xhat_train))\n",
    "print('Yhat_train')\n",
    "print(np.shape(Yhat_train))\n",
    "print('Xhat_val')\n",
    "print(np.shape(Xhat_val))\n",
    "print('Yhat_val')\n",
    "print(np.shape(Yhat_val))\n",
    "print('Xhat_test')\n",
    "print(np.shape(Xhat_test))\n",
    "print('Yhat_test')\n",
    "print(np.shape(Yhat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d177d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class moving_avg(nn.Module):\n",
    "    \"\"\"\n",
    "    Moving average block to highlight the trend of time series\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super(moving_avg, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # padding on the both ends of time series\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "        x = self.avg(x.permute(0, 2, 1))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class series_decomp(nn.Module):\n",
    "    \"\"\"\n",
    "    Series decomposition block\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp, self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        res = x - moving_mean\n",
    "        return res, moving_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36db2ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Dlinear\n",
    "# class DLinear_Model(nn.Module):\n",
    "#     \"\"\"\n",
    "#     DLinear\n",
    "#     \"\"\"\n",
    "#     def __init__(self, configs):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.seq_len = configs.seq_len\n",
    "#         self.pred_len = configs.pred_len\n",
    "\n",
    "#         # Decompsition Kernel Size\n",
    "#         kernel_size = 25\n",
    "#         self.decompsition = series_decomp(kernel_size)\n",
    "#         self.individual = configs.individual\n",
    "#         self.channels = configs.enc_in\n",
    "\n",
    "#         if self.individual:\n",
    "#             self.Linear_Seasonal = nn.ModuleList()\n",
    "#             self.Linear_Trend = nn.ModuleList()\n",
    "#             self.Linear_Decoder = nn.ModuleList()\n",
    "#             for i in range(self.channels):\n",
    "#                 self.Linear_Seasonal.append(nn.Linear(self.seq_len,self.pred_len))\n",
    "#                 self.Linear_Seasonal[i].weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
    "#                 self.Linear_Trend.append(nn.Linear(self.seq_len,self.pred_len))\n",
    "#                 self.Linear_Trend[i].weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
    "#                 self.Linear_Decoder.append(nn.Linear(self.seq_len,self.pred_len))\n",
    "#         else:\n",
    "#             self.Linear_Seasonal = nn.Linear(self.seq_len,self.pred_len)\n",
    "#             self.Linear_Trend = nn.Linear(self.seq_len,self.pred_len)\n",
    "#             self.Linear_Decoder = nn.Linear(self.seq_len,self.pred_len)\n",
    "#             self.Linear_Seasonal.weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
    "#             self.Linear_Trend.weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # x: [Batch, Input length, Channel]\n",
    "#         seasonal_init, trend_init = self.decompsition(x)\n",
    "#         seasonal_init, trend_init = seasonal_init.permute(0,2,1), trend_init.permute(0,2,1)\n",
    "#         if self.individual:\n",
    "#             seasonal_output = torch.zeros([seasonal_init.size(0),seasonal_init.size(1),self.pred_len],dtype=seasonal_init.dtype).to(seasonal_init.device)\n",
    "#             trend_output = torch.zeros([trend_init.size(0),trend_init.size(1),self.pred_len],dtype=trend_init.dtype).to(trend_init.device)\n",
    "#             for i in range(self.channels):\n",
    "#                 seasonal_output[:,i,:] = self.Linear_Seasonal[i](seasonal_init[:,i,:])\n",
    "#                 trend_output[:,i,:] = self.Linear_Trend[i](trend_init[:,i,:])\n",
    "#         else:\n",
    "#             seasonal_output = self.Linear_Seasonal(seasonal_init)\n",
    "#             trend_output = self.Linear_Trend(trend_init)\n",
    "\n",
    "#         x = seasonal_output + trend_output\n",
    "#         return x.permute(0,2,1) # to [Batch, Output length, Channel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6641b734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = torch.from_numpy(Xhat_train).float()\n",
    "# y_train = torch.from_numpy(Yhat_train).float()\n",
    "# x_val = torch.from_numpy(Xhat_val).float()\n",
    "# y_val = torch.from_numpy(Yhat_val).float()\n",
    "# x_test = torch.from_numpy(Xhat_test).float()\n",
    "# y_test = torch.from_numpy(Yhat_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77b470a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6adba4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(self, x):\n",
    "    # x: [Batch, Input length, Channel]\n",
    "    seasonal_init, trend_init = self.decompsition(x)\n",
    "    seasonal_init, trend_init = seasonal_init.permute(0,2,1), trend_init.permute(0,2,1)\n",
    "    if self.individual:\n",
    "        seasonal_output = torch.zeros([seasonal_init.size(0),seasonal_init.size(1),self.pred_len],dtype=seasonal_init.dtype).to(seasonal_init.device)\n",
    "        trend_output = torch.zeros([trend_init.size(0),trend_init.size(1),self.pred_len],dtype=trend_init.dtype).to(trend_init.device)\n",
    "        for i in range(self.channels):\n",
    "            seasonal_output[:,i,:] = self.Linear_Seasonal[i](seasonal_init[:,i,:])\n",
    "            trend_output[:,i,:] = self.Linear_Trend[i](trend_init[:,i,:])\n",
    "    else:\n",
    "        seasonal_output = self.Linear_Seasonal(seasonal_init)\n",
    "        trend_output = self.Linear_Trend(trend_init)\n",
    "\n",
    "    x = seasonal_output + trend_output\n",
    "    return x.permute(0,2,1) # to [Batch, Output length, Channel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f29ddd55",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2413844/3495561176.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mepo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "features = torch.from_numpy(Xhat_train)\n",
    "targets = torch.from_numpy(Yhat_train)\n",
    "x_test = torch.from_numpy(Xhat_test)\n",
    "y_test = torch.from_numpy(Yhat_test)\n",
    "\n",
    "\n",
    "rate = 1e-2\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epo = 2001\n",
    "loss = nn.L1Loss()\n",
    "train_error = np.zeros(epo)\n",
    "test_error = np.zeros(epo)\n",
    "\n",
    "\n",
    "for epoch in range (epo):\n",
    "    yhats_train = model(features.float())\n",
    "    train_loss = loss(targets.float() , yhats_train)\n",
    "    train_error[epoch] = train_loss\n",
    "\n",
    "    train_loss.backward() \n",
    "    optimizer.step()      \n",
    "    optimizer.zero_grad()\n",
    "  \n",
    "\n",
    "    if epoch <= 10 or epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f}\")\n",
    "    else :\n",
    "        if epoch >= epo-10 :\n",
    "            print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff5b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7abd294",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        \n",
    "        # define layers\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "    \n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4483e302",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2413844/2233862798.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 0) prepare data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeature_numpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_numpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_numpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "# 0) prepare data\n",
    "feature_numpy, target_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1234)\n",
    "\n",
    "feature = torch.from_numpy(feature_numpy.astype(np.float32))\n",
    "target = torch.from_numpy(target_numpy.astype(np.float32))\n",
    "target = target.view(target.shape[0], 1)\n",
    "\n",
    "n_samples, n_features = feature.shape\n",
    "\n",
    "# 1) model\n",
    "class LinearRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        \n",
    "        # define layers\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "    \n",
    "        return self.linear(x)\n",
    "\n",
    "model = LinearRegression(n_features, 1)\n",
    "\n",
    "# 2) loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) training loop\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    # forward pass and loss\n",
    "    y_predicted = model(feature)\n",
    "    loss = criterion(y_predicted, target)\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    optimizer.step()\n",
    "    \n",
    "    # init optimizer\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item(): .4f}')\n",
    "\n",
    "# show in image\n",
    "predicted = model(feature).detach().numpy()\n",
    "plt.plot(feature_numpy, target_numpy, 'ro')\n",
    "plt.plot(feature_numpy, predicted, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ab974a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chou",
   "language": "python",
   "name": "chou"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
