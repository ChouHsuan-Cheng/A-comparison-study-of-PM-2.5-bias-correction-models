{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c15933a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luhung3080/miniconda3/envs/chou/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch ver .  1.11.0+cu113\n",
      "Is CUDA available? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "print(\"pytorch ver . \",torch.__version__)\n",
    "print(\"Is CUDA available?\",torch.cuda.is_available())\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.utils.data as Data\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37b37424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>date</th>\n",
       "      <th>FCST_TIME</th>\n",
       "      <th>TAU</th>\n",
       "      <th>pm25_cal</th>\n",
       "      <th>pm25_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPA001</td>\n",
       "      <td>2020-02-24 08:00:00</td>\n",
       "      <td>2020-02-24 09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4.9510</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EPA001</td>\n",
       "      <td>2020-02-24 08:00:00</td>\n",
       "      <td>2020-02-24 10:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>4.4674</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EPA001</td>\n",
       "      <td>2020-02-24 08:00:00</td>\n",
       "      <td>2020-02-24 11:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>4.6159</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EPA001</td>\n",
       "      <td>2020-02-24 08:00:00</td>\n",
       "      <td>2020-02-24 12:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>3.9937</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EPA001</td>\n",
       "      <td>2020-02-24 08:00:00</td>\n",
       "      <td>2020-02-24 13:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>3.9602</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092755</th>\n",
       "      <td>EPA080</td>\n",
       "      <td>2021-10-30 08:00:00</td>\n",
       "      <td>2021-11-02 04:00:00</td>\n",
       "      <td>68</td>\n",
       "      <td>3.6190</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092756</th>\n",
       "      <td>EPA080</td>\n",
       "      <td>2021-10-30 08:00:00</td>\n",
       "      <td>2021-11-02 05:00:00</td>\n",
       "      <td>69</td>\n",
       "      <td>3.7908</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092757</th>\n",
       "      <td>EPA080</td>\n",
       "      <td>2021-10-30 08:00:00</td>\n",
       "      <td>2021-11-02 06:00:00</td>\n",
       "      <td>70</td>\n",
       "      <td>4.0454</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092758</th>\n",
       "      <td>EPA080</td>\n",
       "      <td>2021-10-30 08:00:00</td>\n",
       "      <td>2021-11-02 07:00:00</td>\n",
       "      <td>71</td>\n",
       "      <td>3.9015</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092759</th>\n",
       "      <td>EPA080</td>\n",
       "      <td>2021-10-30 08:00:00</td>\n",
       "      <td>2021-11-02 08:00:00</td>\n",
       "      <td>72</td>\n",
       "      <td>2.7468</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3092760 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SITE_ID                 date            FCST_TIME  TAU  pm25_cal  \\\n",
       "0        EPA001  2020-02-24 08:00:00  2020-02-24 09:00:00    1    4.9510   \n",
       "1        EPA001  2020-02-24 08:00:00  2020-02-24 10:00:00    2    4.4674   \n",
       "2        EPA001  2020-02-24 08:00:00  2020-02-24 11:00:00    3    4.6159   \n",
       "3        EPA001  2020-02-24 08:00:00  2020-02-24 12:00:00    4    3.9937   \n",
       "4        EPA001  2020-02-24 08:00:00  2020-02-24 13:00:00    5    3.9602   \n",
       "...         ...                  ...                  ...  ...       ...   \n",
       "3092755  EPA080  2021-10-30 08:00:00  2021-11-02 04:00:00   68    3.6190   \n",
       "3092756  EPA080  2021-10-30 08:00:00  2021-11-02 05:00:00   69    3.7908   \n",
       "3092757  EPA080  2021-10-30 08:00:00  2021-11-02 06:00:00   70    4.0454   \n",
       "3092758  EPA080  2021-10-30 08:00:00  2021-11-02 07:00:00   71    3.9015   \n",
       "3092759  EPA080  2021-10-30 08:00:00  2021-11-02 08:00:00   72    2.7468   \n",
       "\n",
       "         pm25_obs  \n",
       "0            10.0  \n",
       "1            13.0  \n",
       "2            11.0  \n",
       "3            11.0  \n",
       "4             9.0  \n",
       "...           ...  \n",
       "3092755       4.0  \n",
       "3092756       7.0  \n",
       "3092757       7.0  \n",
       "3092758       4.0  \n",
       "3092759       4.0  \n",
       "\n",
       "[3092760 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('/home/luhung3080/Desktop/PycharmProjects/NCHUproject/Transformer/data_final.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0746809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(604, 1704)\n",
      "(604, 5112)\n"
     ]
    }
   ],
   "source": [
    "x1=np.zeros([604,1704])\n",
    "x2=np.zeros([604,5112])\n",
    "\n",
    "#x1 (0th~1703th column as x)\n",
    "for i in range (0,604):\n",
    "    for j in range (0,71):\n",
    "        a=np.array(data['pm25_obs'][5112*i+72*j:5112*i+72*j+24])\n",
    "        for k in range (0,24):\n",
    "            x1[i][j*24+k]=a[k]\n",
    "\n",
    "#x2 (1704th~8519th column as x)\n",
    "for i in range (1,604):\n",
    "    b=np.array(data['pm25_cal'][5112*i:5112*i+5112])\n",
    "    for j in range(0,5112):\n",
    "        x2[i-1][j]=b[j]\n",
    "        \n",
    "print(np.shape(x1))\n",
    "print(np.shape(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf82dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(604, 1704)\n",
      "(604, 5112)\n"
     ]
    }
   ],
   "source": [
    "x1Restruct_Fun=x1\n",
    "x2Restruct_Fun=x2\n",
    "print(np.shape(x1Restruct_Fun))\n",
    "print(np.shape(x2Restruct_Fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1487822d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(601, 5112)\n"
     ]
    }
   ],
   "source": [
    "YRestruct_Fun=np.zeros([601,5112])\n",
    "for j in range (0,71):\n",
    "    for i in range(0,601):\n",
    "        YRestruct_Fun[i][72*j:72*j+24]=x1Restruct_Fun[1+i][24*j:24*j+24]\n",
    "        YRestruct_Fun[i][72*j+24:72*j+48]=x1Restruct_Fun[1+i+1][24*j:24*j+24]\n",
    "        YRestruct_Fun[i][72*j+48:72*j+72]=x1Restruct_Fun[1+i+2][24*j:24*j+24]\n",
    "print(np.shape(YRestruct_Fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4df27046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(601, 6816)\n"
     ]
    }
   ],
   "source": [
    "XRestruct_Fun=np.zeros([601,6816])\n",
    "for i in range (0,601):\n",
    "    for j in range (0,1704):\n",
    "        XRestruct_Fun[i][j]=x1Restruct_Fun[i][j]\n",
    "    for j in range (1704,6816):\n",
    "        XRestruct_Fun[i][j]=x2Restruct_Fun[i][j-1704]\n",
    "print(np.shape(XRestruct_Fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5fa5a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xhat_train\n",
      "(540, 6816)\n",
      "Yhat_train\n",
      "(540, 5112)\n",
      "Xhat_val\n",
      "(61, 6816)\n",
      "Yhat_val\n",
      "(61, 5112)\n",
      "Xhat_test\n",
      "(61, 6816)\n",
      "Yhat_test\n",
      "(61, 5112)\n"
     ]
    }
   ],
   "source": [
    "Xhat=XRestruct_Fun\n",
    "Yhat=YRestruct_Fun\n",
    "Xhat_train = np.zeros([540,6816])\n",
    "Yhat_train = np.zeros([540,5112])\n",
    "Xhat_val = np.zeros([61,6816])\n",
    "Yhat_val = np.zeros([61,5112])\n",
    "Xhat_test = np.zeros([61,6816])\n",
    "Yhat_test = np.zeros([61,5112])\n",
    "\n",
    "for i in range (0,540):\n",
    "    for j in range (0,1704):\n",
    "        Xhat_train[i][j] = Xhat[i][j]\n",
    "    for j in range (0,5112):    \n",
    "        Xhat_train[i][j+1704] = Xhat[i][j+1704]\n",
    "        Yhat_train[i][j] = Yhat[i][j]\n",
    "        \n",
    "for i in range (540,601):\n",
    "    for j in range (0,1704):\n",
    "        Xhat_val[i-540][j] = Xhat[i][j]\n",
    "    for j in range (0,5112):\n",
    "        Xhat_val[i-540][j+1704] = Xhat[i][j+1704]\n",
    "        Yhat_val[i-540][j] = Yhat[i][j]     \n",
    "        \n",
    "for i in range (540,601):\n",
    "    for j in range (0,1704):\n",
    "        Xhat_test[i-540][j] = Xhat[i][j]\n",
    "    for j in range (0,5112):\n",
    "        Xhat_test[i-540][j+1704] = Xhat[i][j+1704]\n",
    "        Yhat_test[i-540][j] = Yhat[i][j]\n",
    "        \n",
    "print('Xhat_train')\n",
    "print(np.shape(Xhat_train))\n",
    "print('Yhat_train')\n",
    "print(np.shape(Yhat_train))\n",
    "print('Xhat_val')\n",
    "print(np.shape(Xhat_val))\n",
    "print('Yhat_val')\n",
    "print(np.shape(Yhat_val))\n",
    "print('Xhat_test')\n",
    "print(np.shape(Xhat_test))\n",
    "print('Yhat_test')\n",
    "print(np.shape(Yhat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53f72fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xhat_train0 = np.zeros([540,11928])\n",
    "Xhat_val0 = np.zeros([61,11928])\n",
    "Xhat_test0 = np.zeros([61,11928])\n",
    "for i in range (0,540):\n",
    "    for j in range (0,6816):\n",
    "        Xhat_train0[i][j] = Xhat_train[i][j]\n",
    "    for j in range (6816,11928):\n",
    "        Xhat_train0[i][j] = Yhat_train[i][j-6816]\n",
    "for i in range (0,61):\n",
    "    for j in range (0,6816):\n",
    "        Xhat_val0[i][j] = Xhat_val[i][j]\n",
    "    for j in range (6816,11928):\n",
    "        Xhat_val0[i][j] = Yhat_val[i][j-6816]\n",
    "for i in range (0,61):\n",
    "    for j in range (0,6816):\n",
    "        Xhat_test0[i][j] = Xhat_test[i][j]\n",
    "    for j in range (6816,11928):\n",
    "        Xhat_test0[i][j] = Yhat_test[i][j-6816]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9f426e",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31ec88c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(Xhat_train0).float()\n",
    "y_train = torch.from_numpy(Yhat_train).float()\n",
    "x_val = torch.from_numpy(Xhat_val0).float()\n",
    "y_val = torch.from_numpy(Yhat_val).float()\n",
    "x_test = torch.from_numpy(Xhat_test0).float()\n",
    "y_test = torch.from_numpy(Yhat_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da0e8ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PytorchLightningModel(pl.LightningModule): # 一定要繼承pl.LightningModule\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(6816,5112)\n",
    "        self.layer2 = nn.Transformer(d_model=5112, nhead=71*72)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ouput = self.layer1(x[:,:6816])\n",
    "        ouput = self.layer2(ouput, x[:,6816:]) \n",
    "        return ouput\n",
    "\n",
    "    def configure_optimizers(self): # 自動訓練時會呼叫此方法來獲取Optimizer.\n",
    "        return optim.Adam(self.parameters(), lr=1e-3) # 這邊注意要調整的參數是`self.parameters()`\n",
    "\n",
    "    def prepare_data(self): # 此方法會在初始化後優先執行。 所以可以在此方法中先將會用到的資料都讀取進來.\n",
    "        self.train_set = Data.TensorDataset(x_train , y_train) \n",
    "        self.test_set = Data.TensorDataset(x_test, y_test)\n",
    "        self.val_set = Data.TensorDataset(x_val, y_val)\n",
    "\n",
    "    # 以下三個方法則是設定進行訓練及驗證時所要使用的Data Loader格式。\n",
    "    def train_dataloader(self):\n",
    "        # return Data.DataLoader(dataset=self.train_set, batch_size= self.batch_size, shuffle=True)\n",
    "        return Data.DataLoader(dataset=self.train_set , batch_size=540 , shuffle=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        # return Data.DataLoader(dataset=self.test_set, batch_size= self.batch_size, shuffle=True)\n",
    "        return Data.DataLoader(dataset=self.test_set , batch_size=61 , shuffle=False)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        #return Data.DataLoader(dataset=self.val_set, batch_size= self.batch_size, shuffle=True)\n",
    "        return Data.DataLoader(dataset=self.val_set , batch_size=61 , shuffle=False)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    def training_step(self, batch, batch_idx): # 定義訓練過程的Step要如何進行\n",
    "        x, y = batch # 從self.train_dataloader()的Data Loader取一個batch出來。\n",
    "        output  = self.forward(x)\n",
    "        loss = nn.L1Loss(reduction='mean')(output, y)\n",
    "        logs = {'loss' : loss }\n",
    "        self.log(\"train_loss_MAE\", loss)\n",
    "        return {'loss' : loss ,'log' : logs }\n",
    "\n",
    "    def test_step(self, batch, batch_idx): #定義 Test 階段\n",
    "        x, y = batch \n",
    "        output  = self.forward(x)\n",
    "        loss = nn.L1Loss(reduction='mean')(output, y)\n",
    "        logs = {'loss' : loss }\n",
    "        self.log(\"test_loss_MAE\", loss)\n",
    "        return {'loss' : loss ,'log' : logs}\n",
    "\n",
    "    # def test_eposh_end(self, outputs):\n",
    "    #     avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "    #     logs = {'test_loss': avg_loss}      \n",
    "    #     #return {'avg_test_loss': avg_loss, 'log': logs, 'progress_bar': logs }\n",
    "    #     return {'avg_test_loss': avg_loss, 'log': logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx): # 定義Validation如何進行，以這邊為例就再加上了計算Acc.\n",
    "        x, y = batch \n",
    "        output  = self.forward(x)\n",
    "        loss = nn.L1Loss(reduction='mean')(output, y)\n",
    "        logs = {'loss' : loss }\n",
    "        self.log(\"val_loss_MAE\", loss)\n",
    "        return {'loss' : loss ,  'log' : logs}\n",
    "    \n",
    "    # def validation_epoch_end(self, outputs): # 在Validation的一個Epoch結束後，計算平均的Loss.\n",
    "    #     avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "    #     logs = {'val_loss': avg_loss}\n",
    "    #     return {'avg_val_loss': avg_loss, 'log' : logs, 'progress_bar': logs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d873ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger1 = TensorBoardLogger(\"jupyterNB_logs\", name=\"Transformer_in1\")\n",
    "logger2 = CSVLogger(\"jupyterNB_logs\", name=\"Transformer_in1_csv\")\n",
    "model = PytorchLightningModel() \n",
    "trainer = pl.Trainer(max_epochs=500 , gpus=1 , logger=logger1)\n",
    "trainer.fit(model)\n",
    "trainer.test(model)\n",
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b3d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/luhung3080/Desktop/PycharmProjects/NCHUproject/Transformer/jupyterNB_logs/Transformer_in1_csv/version_0/metrics.csv\")\n",
    "s=np.array(df['val_loss_MAE'].fillna(np.nanmean(df['val_loss_MAE'])))\n",
    "#print(s)\n",
    "score=np.min(s)\n",
    "print(df[df['val_loss_MAE'] == score].index)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12904aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e4b24",
   "metadata": {},
   "source": [
    "@ terminal\n",
    "\n",
    "(base) luhung3080@luhung3080:\n",
    "\n",
    "conda activate chou\n",
    "\n",
    "cd /home/luhung3080/Desktop/PycharmProjects/NCHUproject/jupyterNB_logs/mymodel\n",
    "\n",
    "tensorboard --logdir=/home/luhung3080/Desktop/PycharmProjects/NCHUproject/jupyterNB_logs/mymodel/version_3 --host=127.0.0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c6c81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chou",
   "language": "python",
   "name": "chou"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
