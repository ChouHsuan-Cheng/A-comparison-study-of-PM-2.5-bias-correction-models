{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3d71b7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch ver .  1.11.0+cu113\n",
      "Is CUDA available? True\n",
      "pynio ver .  1.5.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "print(\"pytorch ver . \",torch.__version__)\n",
    "print(\"Is CUDA available?\",torch.cuda.is_available())\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.utils.data as Data\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import xarray as xr\n",
    "import os\n",
    "os.environ['R_HOME'] = '/home/luhung3080/miniconda3/envs/chou/lib/R'\n",
    "from rpy2.robjects import r, numpy2ri\n",
    "numpy2ri.activate()\n",
    "from rpy2.robjects.packages import importr\n",
    "sinkr = importr('sinkr')\n",
    "import Nio\n",
    "print (\"pynio ver . \",Nio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bdfaf4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>date</th>\n",
       "      <th>FCST_TIME</th>\n",
       "      <th>TAU</th>\n",
       "      <th>pm25_cal</th>\n",
       "      <th>pm25_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPA001</td>\n",
       "      <td>2020-02-24 08:00:00</td>\n",
       "      <td>2020-02-24 09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4.9510</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EPA001</td>\n",
       "      <td>2020-02-24 08:00:00</td>\n",
       "      <td>2020-02-24 10:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>4.4674</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EPA001</td>\n",
       "      <td>2020-02-24 08:00:00</td>\n",
       "      <td>2020-02-24 11:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>4.6159</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EPA001</td>\n",
       "      <td>2020-02-24 08:00:00</td>\n",
       "      <td>2020-02-24 12:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>3.9937</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EPA001</td>\n",
       "      <td>2020-02-24 08:00:00</td>\n",
       "      <td>2020-02-24 13:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>3.9602</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092755</th>\n",
       "      <td>EPA080</td>\n",
       "      <td>2021-10-30 08:00:00</td>\n",
       "      <td>2021-11-02 04:00:00</td>\n",
       "      <td>68</td>\n",
       "      <td>3.6190</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092756</th>\n",
       "      <td>EPA080</td>\n",
       "      <td>2021-10-30 08:00:00</td>\n",
       "      <td>2021-11-02 05:00:00</td>\n",
       "      <td>69</td>\n",
       "      <td>3.7908</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092757</th>\n",
       "      <td>EPA080</td>\n",
       "      <td>2021-10-30 08:00:00</td>\n",
       "      <td>2021-11-02 06:00:00</td>\n",
       "      <td>70</td>\n",
       "      <td>4.0454</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092758</th>\n",
       "      <td>EPA080</td>\n",
       "      <td>2021-10-30 08:00:00</td>\n",
       "      <td>2021-11-02 07:00:00</td>\n",
       "      <td>71</td>\n",
       "      <td>3.9015</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092759</th>\n",
       "      <td>EPA080</td>\n",
       "      <td>2021-10-30 08:00:00</td>\n",
       "      <td>2021-11-02 08:00:00</td>\n",
       "      <td>72</td>\n",
       "      <td>2.7468</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3092760 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SITE_ID                 date            FCST_TIME  TAU  pm25_cal  \\\n",
       "0        EPA001  2020-02-24 08:00:00  2020-02-24 09:00:00    1    4.9510   \n",
       "1        EPA001  2020-02-24 08:00:00  2020-02-24 10:00:00    2    4.4674   \n",
       "2        EPA001  2020-02-24 08:00:00  2020-02-24 11:00:00    3    4.6159   \n",
       "3        EPA001  2020-02-24 08:00:00  2020-02-24 12:00:00    4    3.9937   \n",
       "4        EPA001  2020-02-24 08:00:00  2020-02-24 13:00:00    5    3.9602   \n",
       "...         ...                  ...                  ...  ...       ...   \n",
       "3092755  EPA080  2021-10-30 08:00:00  2021-11-02 04:00:00   68    3.6190   \n",
       "3092756  EPA080  2021-10-30 08:00:00  2021-11-02 05:00:00   69    3.7908   \n",
       "3092757  EPA080  2021-10-30 08:00:00  2021-11-02 06:00:00   70    4.0454   \n",
       "3092758  EPA080  2021-10-30 08:00:00  2021-11-02 07:00:00   71    3.9015   \n",
       "3092759  EPA080  2021-10-30 08:00:00  2021-11-02 08:00:00   72    2.7468   \n",
       "\n",
       "         pm25_obs  \n",
       "0            10.0  \n",
       "1            13.0  \n",
       "2            11.0  \n",
       "3            11.0  \n",
       "4             9.0  \n",
       "...           ...  \n",
       "3092755       4.0  \n",
       "3092756       7.0  \n",
       "3092757       7.0  \n",
       "3092758       4.0  \n",
       "3092759       4.0  \n",
       "\n",
       "[3092760 rows x 6 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('/home/luhung3080/Desktop/PycharmProjects/NCHUproject/Transformer/data_final.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d8ed56",
   "metadata": {},
   "source": [
    "# Y = b0 + b1X1 (96hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "500a1245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 5112)\n",
      "(605, 5112)\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "#cal_PMf  \n",
    "###\n",
    "u=np.zeros([605,5112])\n",
    "for i in range (0,605):\n",
    "    a=np.array(data['pm25_cal'][5112*i:5112*i+5112])\n",
    "    u[i]=a.T\n",
    "\n",
    "###\n",
    "#obs_PMf\n",
    "###\n",
    "v=np.zeros([605,5112])\n",
    "for i in range (0,605):\n",
    "    a=np.array(data['pm25_obs'][5112*i:5112*i+5112])\n",
    "    v[i]=a.T\n",
    "\n",
    "print(np.shape(u))\n",
    "print(np.shape(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f70f68df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 5112)\n",
      "(605, 5112)\n"
     ]
    }
   ],
   "source": [
    "XRestruct_Fun=u\n",
    "YRestruct_Fun=v\n",
    "print(np.shape(XRestruct_Fun))\n",
    "print(np.shape(YRestruct_Fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f440134",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xhat=XRestruct_Fun\n",
    "Yhat=YRestruct_Fun\n",
    "Xhat_train = np.zeros([544,5112])\n",
    "Yhat_train = np.zeros([544,5112])\n",
    "Xhat_test = np.zeros([61,5112])\n",
    "Yhat_test = np.zeros([61,5112])\n",
    "for i in range (0,544):\n",
    "    for j in range (0,5112):\n",
    "        Xhat_train[i][j] = Xhat[i][j]\n",
    "        Yhat_train[i][j] = Yhat[i][j]\n",
    "for i in range (544,605):\n",
    "    for j in range (0,5112):\n",
    "        Xhat_test[i-544][j] = Xhat[i][j]\n",
    "        Yhat_test[i-544][j] = Yhat[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "41acf508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xhat_train\n",
      "(544, 5112)\n",
      "Yhat_train\n",
      "(544, 5112)\n",
      "Xhat_test\n",
      "(61, 5112)\n",
      "Yhat_test\n",
      "(61, 5112)\n"
     ]
    }
   ],
   "source": [
    "print('Xhat_train')\n",
    "#print(Xhat_train)\n",
    "print(np.shape(Xhat_train))\n",
    "print('Yhat_train')\n",
    "#print(Yhat_train)\n",
    "print(np.shape(Yhat_train))\n",
    "print('Xhat_test')\n",
    "#print(Xhat_test)\n",
    "print(np.shape(Xhat_test))\n",
    "print('Yhat_test')\n",
    "#print(Yhat_test)\n",
    "print(np.shape(Yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef064713",
   "metadata": {},
   "source": [
    "# GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07a8f0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Xhat_train\n",
    "y = Yhat_train\n",
    "xt = Xhat_test\n",
    "yt = Yhat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "235f7ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model (x,b0,b1):\n",
    "    # y = b0 +  torch.matmul(x,b1)\n",
    "    y = b0 + b1*x\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c225cb9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training loss 7.0582, Testing loss 7.0548\n",
      "Epoch 1, Training loss 7.0182, Testing loss 6.9978\n",
      "Epoch 2, Training loss 6.9801, Testing loss 6.9427\n",
      "Epoch 3, Training loss 6.9439, Testing loss 6.8895\n",
      "Epoch 4, Training loss 6.9097, Testing loss 6.8382\n",
      "Epoch 5, Training loss 6.8774, Testing loss 6.7889\n",
      "Epoch 6, Training loss 6.8469, Testing loss 6.7415\n",
      "Epoch 7, Training loss 6.8183, Testing loss 6.6962\n",
      "Epoch 8, Training loss 6.7914, Testing loss 6.6530\n",
      "Epoch 9, Training loss 6.7662, Testing loss 6.6119\n",
      "Epoch 10, Training loss 6.7426, Testing loss 6.5728\n",
      "Epoch 20, Training loss 6.5820, Testing loss 6.2933\n",
      "Epoch 30, Training loss 6.5089, Testing loss 6.1695\n",
      "Epoch 40, Training loss 6.4728, Testing loss 6.1211\n",
      "Epoch 50, Training loss 6.4507, Testing loss 6.0999\n",
      "Epoch 60, Training loss 6.4337, Testing loss 6.0831\n",
      "Epoch 70, Training loss 6.4185, Testing loss 6.0659\n",
      "Epoch 80, Training loss 6.4042, Testing loss 6.0477\n",
      "Epoch 90, Training loss 6.3905, Testing loss 6.0300\n",
      "Epoch 100, Training loss 6.3774, Testing loss 6.0124\n",
      "Epoch 110, Training loss 6.3648, Testing loss 5.9954\n",
      "Epoch 120, Training loss 6.3527, Testing loss 5.9789\n",
      "Epoch 130, Training loss 6.3411, Testing loss 5.9627\n",
      "Epoch 140, Training loss 6.3300, Testing loss 5.9470\n",
      "Epoch 150, Training loss 6.3193, Testing loss 5.9321\n",
      "Epoch 160, Training loss 6.3091, Testing loss 5.9174\n",
      "Epoch 170, Training loss 6.2993, Testing loss 5.9036\n",
      "Epoch 180, Training loss 6.2899, Testing loss 5.8901\n",
      "Epoch 190, Training loss 6.2809, Testing loss 5.8774\n",
      "Epoch 200, Training loss 6.2723, Testing loss 5.8651\n",
      "Epoch 210, Training loss 6.2640, Testing loss 5.8528\n",
      "Epoch 220, Training loss 6.2561, Testing loss 5.8412\n",
      "Epoch 230, Training loss 6.2486, Testing loss 5.8301\n",
      "Epoch 240, Training loss 6.2413, Testing loss 5.8196\n",
      "Epoch 250, Training loss 6.2344, Testing loss 5.8095\n",
      "Epoch 260, Training loss 6.2278, Testing loss 5.8000\n",
      "Epoch 270, Training loss 6.2214, Testing loss 5.7909\n",
      "Epoch 280, Training loss 6.2154, Testing loss 5.7822\n",
      "Epoch 290, Training loss 6.2097, Testing loss 5.7739\n",
      "Epoch 300, Training loss 6.2042, Testing loss 5.7659\n",
      "Epoch 310, Training loss 6.1989, Testing loss 5.7584\n",
      "Epoch 320, Training loss 6.1940, Testing loss 5.7511\n",
      "Epoch 330, Training loss 6.1892, Testing loss 5.7445\n",
      "Epoch 340, Training loss 6.1847, Testing loss 5.7379\n",
      "Epoch 350, Training loss 6.1804, Testing loss 5.7319\n",
      "Epoch 360, Training loss 6.1764, Testing loss 5.7258\n",
      "Epoch 370, Training loss 6.1725, Testing loss 5.7200\n",
      "Epoch 380, Training loss 6.1688, Testing loss 5.7145\n",
      "Epoch 390, Training loss 6.1653, Testing loss 5.7093\n",
      "Epoch 400, Training loss 6.1620, Testing loss 5.7042\n",
      "Epoch 410, Training loss 6.1589, Testing loss 5.6996\n",
      "Epoch 420, Training loss 6.1559, Testing loss 5.6952\n",
      "Epoch 430, Training loss 6.1530, Testing loss 5.6912\n",
      "Epoch 440, Training loss 6.1503, Testing loss 5.6872\n",
      "Epoch 450, Training loss 6.1478, Testing loss 5.6835\n",
      "Epoch 460, Training loss 6.1453, Testing loss 5.6797\n",
      "Epoch 470, Training loss 6.1430, Testing loss 5.6766\n",
      "Epoch 480, Training loss 6.1408, Testing loss 5.6733\n",
      "Epoch 490, Training loss 6.1387, Testing loss 5.6705\n",
      "Epoch 500, Training loss 6.1368, Testing loss 5.6675\n",
      "Epoch 510, Training loss 6.1349, Testing loss 5.6647\n",
      "Epoch 520, Training loss 6.1331, Testing loss 5.6619\n",
      "Epoch 530, Training loss 6.1315, Testing loss 5.6593\n",
      "Epoch 540, Training loss 6.1299, Testing loss 5.6571\n",
      "Epoch 550, Training loss 6.1284, Testing loss 5.6548\n",
      "Epoch 560, Training loss 6.1269, Testing loss 5.6525\n",
      "Epoch 570, Training loss 6.1256, Testing loss 5.6504\n",
      "Epoch 580, Training loss 6.1243, Testing loss 5.6487\n",
      "Epoch 590, Training loss 6.1231, Testing loss 5.6470\n",
      "Epoch 600, Training loss 6.1220, Testing loss 5.6453\n",
      "Epoch 610, Training loss 6.1209, Testing loss 5.6438\n",
      "Epoch 620, Training loss 6.1199, Testing loss 5.6422\n",
      "Epoch 630, Training loss 6.1189, Testing loss 5.6408\n",
      "Epoch 640, Training loss 6.1180, Testing loss 5.6394\n",
      "Epoch 650, Training loss 6.1172, Testing loss 5.6382\n",
      "Epoch 660, Training loss 6.1164, Testing loss 5.6369\n",
      "Epoch 670, Training loss 6.1156, Testing loss 5.6357\n",
      "Epoch 680, Training loss 6.1149, Testing loss 5.6347\n",
      "Epoch 690, Training loss 6.1142, Testing loss 5.6337\n",
      "Epoch 700, Training loss 6.1136, Testing loss 5.6329\n",
      "Epoch 710, Training loss 6.1130, Testing loss 5.6321\n",
      "Epoch 720, Training loss 6.1124, Testing loss 5.6312\n",
      "Epoch 730, Training loss 6.1119, Testing loss 5.6304\n",
      "Epoch 740, Training loss 6.1114, Testing loss 5.6297\n",
      "Epoch 750, Training loss 6.1109, Testing loss 5.6290\n",
      "Epoch 760, Training loss 6.1105, Testing loss 5.6285\n",
      "Epoch 770, Training loss 6.1100, Testing loss 5.6279\n",
      "Epoch 780, Training loss 6.1096, Testing loss 5.6273\n",
      "Epoch 790, Training loss 6.1093, Testing loss 5.6269\n",
      "Epoch 800, Training loss 6.1089, Testing loss 5.6265\n",
      "Epoch 810, Training loss 6.1086, Testing loss 5.6261\n",
      "Epoch 820, Training loss 6.1083, Testing loss 5.6255\n",
      "Epoch 830, Training loss 6.1080, Testing loss 5.6252\n",
      "Epoch 840, Training loss 6.1077, Testing loss 5.6248\n",
      "Epoch 850, Training loss 6.1075, Testing loss 5.6244\n",
      "Epoch 860, Training loss 6.1072, Testing loss 5.6243\n",
      "Epoch 870, Training loss 6.1070, Testing loss 5.6241\n",
      "Epoch 880, Training loss 6.1068, Testing loss 5.6236\n",
      "Epoch 890, Training loss 6.1066, Testing loss 5.6234\n",
      "Epoch 900, Training loss 6.1064, Testing loss 5.6233\n",
      "Epoch 910, Training loss 6.1062, Testing loss 5.6230\n",
      "Epoch 920, Training loss 6.1061, Testing loss 5.6228\n",
      "Epoch 930, Training loss 6.1059, Testing loss 5.6226\n",
      "Epoch 940, Training loss 6.1058, Testing loss 5.6226\n",
      "Epoch 950, Training loss 6.1056, Testing loss 5.6224\n",
      "Epoch 960, Training loss 6.1055, Testing loss 5.6221\n",
      "Epoch 970, Training loss 6.1054, Testing loss 5.6222\n",
      "Epoch 980, Training loss 6.1053, Testing loss 5.6220\n",
      "Epoch 990, Training loss 6.1052, Testing loss 5.6219\n",
      "Epoch 1000, Training loss 6.1051, Testing loss 5.6218\n",
      "Epoch 1010, Training loss 6.1050, Testing loss 5.6217\n",
      "Epoch 1020, Training loss 6.1049, Testing loss 5.6217\n",
      "Epoch 1030, Training loss 6.1048, Testing loss 5.6215\n",
      "Epoch 1040, Training loss 6.1047, Testing loss 5.6213\n",
      "Epoch 1050, Training loss 6.1046, Testing loss 5.6212\n",
      "Epoch 1060, Training loss 6.1045, Testing loss 5.6212\n",
      "Epoch 1070, Training loss 6.1045, Testing loss 5.6212\n",
      "Epoch 1080, Training loss 6.1044, Testing loss 5.6210\n",
      "Epoch 1090, Training loss 6.1044, Testing loss 5.6212\n",
      "Epoch 1100, Training loss 6.1043, Testing loss 5.6209\n",
      "Epoch 1110, Training loss 6.1042, Testing loss 5.6208\n",
      "Epoch 1120, Training loss 6.1042, Testing loss 5.6208\n",
      "Epoch 1130, Training loss 6.1041, Testing loss 5.6209\n",
      "Epoch 1140, Training loss 6.1041, Testing loss 5.6208\n",
      "Epoch 1150, Training loss 6.1041, Testing loss 5.6207\n",
      "Epoch 1160, Training loss 6.1040, Testing loss 5.6207\n",
      "Epoch 1170, Training loss 6.1040, Testing loss 5.6208\n",
      "Epoch 1180, Training loss 6.1039, Testing loss 5.6206\n",
      "Epoch 1190, Training loss 6.1039, Testing loss 5.6208\n",
      "Epoch 1200, Training loss 6.1039, Testing loss 5.6206\n",
      "Epoch 1210, Training loss 6.1038, Testing loss 5.6204\n",
      "Epoch 1220, Training loss 6.1038, Testing loss 5.6206\n",
      "Epoch 1230, Training loss 6.1038, Testing loss 5.6207\n",
      "Epoch 1240, Training loss 6.1038, Testing loss 5.6206\n",
      "Epoch 1250, Training loss 6.1037, Testing loss 5.6206\n",
      "Epoch 1260, Training loss 6.1037, Testing loss 5.6206\n",
      "Epoch 1270, Training loss 6.1037, Testing loss 5.6206\n",
      "Epoch 1280, Training loss 6.1037, Testing loss 5.6204\n",
      "Epoch 1290, Training loss 6.1037, Testing loss 5.6204\n",
      "Epoch 1300, Training loss 6.1036, Testing loss 5.6204\n",
      "Epoch 1310, Training loss 6.1036, Testing loss 5.6205\n",
      "Epoch 1320, Training loss 6.1036, Testing loss 5.6205\n",
      "Epoch 1330, Training loss 6.1036, Testing loss 5.6204\n",
      "Epoch 1340, Training loss 6.1036, Testing loss 5.6203\n",
      "Epoch 1350, Training loss 6.1036, Testing loss 5.6204\n",
      "Epoch 1360, Training loss 6.1036, Testing loss 5.6202\n",
      "Epoch 1370, Training loss 6.1036, Testing loss 5.6204\n",
      "Epoch 1380, Training loss 6.1035, Testing loss 5.6205\n",
      "Epoch 1390, Training loss 6.1035, Testing loss 5.6204\n",
      "Epoch 1400, Training loss 6.1035, Testing loss 5.6203\n",
      "Epoch 1410, Training loss 6.1035, Testing loss 5.6203\n",
      "Epoch 1420, Training loss 6.1035, Testing loss 5.6204\n",
      "Epoch 1430, Training loss 6.1035, Testing loss 5.6204\n",
      "Epoch 1440, Training loss 6.1035, Testing loss 5.6203\n",
      "Epoch 1450, Training loss 6.1035, Testing loss 5.6203\n",
      "Epoch 1460, Training loss 6.1035, Testing loss 5.6202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1470, Training loss 6.1035, Testing loss 5.6202\n",
      "Epoch 1480, Training loss 6.1035, Testing loss 5.6202\n",
      "Epoch 1490, Training loss 6.1035, Testing loss 5.6204\n",
      "Epoch 1500, Training loss 6.1035, Testing loss 5.6201\n",
      "Epoch 1510, Training loss 6.1035, Testing loss 5.6203\n",
      "Epoch 1520, Training loss 6.1035, Testing loss 5.6203\n",
      "Epoch 1530, Training loss 6.1034, Testing loss 5.6202\n",
      "Epoch 1540, Training loss 6.1034, Testing loss 5.6203\n",
      "Epoch 1550, Training loss 6.1034, Testing loss 5.6203\n",
      "Epoch 1560, Training loss 6.1034, Testing loss 5.6204\n",
      "Epoch 1570, Training loss 6.1034, Testing loss 5.6203\n",
      "Epoch 1580, Training loss 6.1034, Testing loss 5.6203\n",
      "Epoch 1590, Training loss 6.1034, Testing loss 5.6203\n",
      "Epoch 1600, Training loss 6.1034, Testing loss 5.6204\n",
      "Epoch 1610, Training loss 6.1034, Testing loss 5.6203\n",
      "Epoch 1620, Training loss 6.1034, Testing loss 5.6203\n",
      "Epoch 1630, Training loss 6.1034, Testing loss 5.6204\n",
      "Epoch 1640, Training loss 6.1034, Testing loss 5.6203\n",
      "Epoch 1650, Training loss 6.1034, Testing loss 5.6205\n",
      "Epoch 1660, Training loss 6.1034, Testing loss 5.6202\n",
      "Epoch 1670, Training loss 6.1034, Testing loss 5.6205\n",
      "Epoch 1680, Training loss 6.1034, Testing loss 5.6203\n",
      "Epoch 1690, Training loss 6.1034, Testing loss 5.6204\n",
      "Epoch 1700, Training loss 6.1034, Testing loss 5.6203\n",
      "Epoch 1710, Training loss 6.1034, Testing loss 5.6205\n",
      "Epoch 1720, Training loss 6.1034, Testing loss 5.6205\n",
      "Epoch 1730, Training loss 6.1034, Testing loss 5.6204\n",
      "Epoch 1740, Training loss 6.1034, Testing loss 5.6204\n",
      "Epoch 1750, Training loss 6.1034, Testing loss 5.6204\n",
      "Epoch 1760, Training loss 6.1034, Testing loss 5.6203\n",
      "Epoch 1770, Training loss 6.1034, Testing loss 5.6203\n",
      "Epoch 1780, Training loss 6.1034, Testing loss 5.6205\n",
      "Epoch 1790, Training loss 6.1034, Testing loss 5.6204\n",
      "Epoch 1800, Training loss 6.1034, Testing loss 5.6206\n",
      "Epoch 1810, Training loss 6.1034, Testing loss 5.6204\n",
      "Epoch 1820, Training loss 6.1034, Testing loss 5.6204\n",
      "Epoch 1830, Training loss 6.1034, Testing loss 5.6207\n",
      "Epoch 1840, Training loss 6.1034, Testing loss 5.6205\n",
      "Epoch 1850, Training loss 6.1034, Testing loss 5.6204\n",
      "Epoch 1860, Training loss 6.1034, Testing loss 5.6204\n",
      "Epoch 1870, Training loss 6.1034, Testing loss 5.6203\n",
      "Epoch 1880, Training loss 6.1034, Testing loss 5.6204\n",
      "Epoch 1890, Training loss 6.1034, Testing loss 5.6204\n",
      "Epoch 1900, Training loss 6.1034, Testing loss 5.6206\n",
      "Epoch 1910, Training loss 6.1034, Testing loss 5.6206\n",
      "Epoch 1920, Training loss 6.1034, Testing loss 5.6205\n",
      "Epoch 1930, Training loss 6.1034, Testing loss 5.6204\n",
      "Epoch 1940, Training loss 6.1034, Testing loss 5.6204\n",
      "Epoch 1950, Training loss 6.1034, Testing loss 5.6204\n",
      "Epoch 1960, Training loss 6.1034, Testing loss 5.6205\n",
      "Epoch 1970, Training loss 6.1034, Testing loss 5.6205\n",
      "Epoch 1980, Training loss 6.1034, Testing loss 5.6205\n",
      "Epoch 1990, Training loss 6.1034, Testing loss 5.6205\n",
      "Epoch 1991, Training loss 6.1034, Testing loss 5.6205\n",
      "Epoch 1992, Training loss 6.1034, Testing loss 5.6204\n",
      "Epoch 1993, Training loss 6.1034, Testing loss 5.6204\n",
      "Epoch 1994, Training loss 6.1034, Testing loss 5.6204\n",
      "Epoch 1995, Training loss 6.1034, Testing loss 5.6205\n",
      "Epoch 1996, Training loss 6.1034, Testing loss 5.6206\n",
      "Epoch 1997, Training loss 6.1034, Testing loss 5.6205\n",
      "Epoch 1998, Training loss 6.1034, Testing loss 5.6205\n",
      "Epoch 1999, Training loss 6.1034, Testing loss 5.6204\n",
      "Epoch 2000, Training loss 6.1034, Testing loss 5.6204\n"
     ]
    }
   ],
   "source": [
    "features = torch.from_numpy(x)\n",
    "targets = torch.from_numpy(y)\n",
    "x_test = torch.from_numpy(xt)\n",
    "y_test = torch.from_numpy(yt)\n",
    "\n",
    "# beta0 = torch.randn(6816 , requires_grad = True)\n",
    "# # beta1 = torch.randn([6816 , 6816], requires_grad = True)\n",
    "# beta1 = torch.randn(6816, requires_grad = True)\n",
    "\n",
    "beta0 = torch.ones(5112, requires_grad = True)\n",
    "beta1 = torch.ones(5112, requires_grad = True)\n",
    "\n",
    "rate = 1e-2\n",
    "optimizer = optim.Adam([beta0 , beta1], lr=rate)\n",
    "\n",
    "epo = 2001\n",
    "loss = nn.L1Loss()\n",
    "train_error = np.zeros(epo)\n",
    "test_error = np.zeros(epo)\n",
    "\n",
    "\n",
    "for epoch in range (epo):\n",
    "    yhats_train = model(features.float() , beta0 , beta1)\n",
    "    train_loss = loss(targets.float() , yhats_train)\n",
    "    train_error[epoch] = train_loss\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward() \n",
    "    optimizer.step()    \n",
    "\n",
    "    yhats_test = model(x_test.float(), beta0, beta1) \n",
    "#     for i in range (30):\n",
    "#         for j in range (6816):\n",
    "#             if y_test[i][j] == 0:\n",
    "#                 yhats_test[i][j] = 0\n",
    "    r = abs(yhats_test - y_test)\n",
    "    test_loss = torch.nanmean(r)\n",
    "    # test_loss = loss(y_test , yhats_test)\n",
    "    test_error[epoch] = test_loss\n",
    "\n",
    "    if epoch <= 10 or epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\n",
    "                    f\" Testing loss {test_loss.item():.4f}\")\n",
    "        # print('\\tBeta_0 : ' , beta0)\n",
    "        # print('\\tBeta_1 : ' , beta1)\n",
    "    else :\n",
    "        if epoch >= epo-10 :\n",
    "            print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\n",
    "                        f\" Testing loss {test_loss.item():.4f}\")\n",
    "            # print('\\tBeta_0 : ' , beta0)\n",
    "            # print('\\tBeta_1 : ' , beta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d9d2a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAsjElEQVR4nO3deXhb5Zn38e9tybLjJXYWJ2QhGyUJCQSHuOyFpJS9DEspZWnZ+hbSMgSYaQtt33bodDpvmekGZcmwdmhpoZNCgUIphWGHQB0SCNkgexwIMVmcxEm83u8fR3ZkxYucyJIl/z7XpUvSOY/OuX1k//T40VnM3RERkcyXk+4CREQkORToIiJZQoEuIpIlFOgiIllCgS4ikiUU6CIiWUKBLiKSJRTo0ieY2WozqzezwXHT55uZm9mYmGk3R6cdFdf2cjNrMrMdcbfhKfoxRDqlQJe+ZBVwUcsTMzsMKIhtYGYGXApsjt7He8Pdi+JuH/Zk0SKJUqBLX/Ib2ob0ZcCDcW0+AwwDZgEXmlkkRbWJ7DcFuvQlc4H+ZnaImYWAC4HfxrW5DHgS+EP0+VkprE9kvyjQpa9p6aWfDCwB1rfMMLMC4IvA79y9AZjD3sMuR5vZ1pjbihTVLdKlcLoLEEmx3wAvA2PZe7jlXKAReDr6/CHgOTMrc/fq6LS57n58SioV6Sb10KVPcfc1BF+OngE8Gjf7MqAIWGtmG4D/AXKBi1NapMg+Ug9d+qKvAgPcvdbMWv4GRgAnAacD78a0vZ5g2OXWlFYosg8U6NLnuHt7496fARa4+7OxE83sNuCfzezQ6KRjzGxH3GtnuPvfe6BUkW4xXeBCRCQ7aAxdRCRLKNBFRLKEAl1EJEso0EVEskTa9nIZPHiwjxkzJl2rFxHJSPPmzfvE3cvam5e2QB8zZgyVlZXpWr2ISEYyszUdzdOQi4hIllCgi4hkCQW6iEiW6FWH/jc0NFBVVcXu3bvTXUqvl5+fz8iRI8nNzU13KSLSS/SqQK+qqqK4uJgxY8YQXAlM2uPubNq0iaqqKsaOHZvuckSkl+hVQy67d+9m0KBBCvMumBmDBg3SfzIi0kavCnRAYZ4gbScRidfrAr0ru+sb+bimlsampnSXIiLSq2RcoDfv2sLQ2vdpqk/+cMOmTZsoLy+nvLycAw44gBEjRrQ+r6+v7/S1lZWVzJo1q8t1HHvssckqV0SkjV71pWhCLPgM6onzuA8aNIgFCxYAcPPNN1NUVMQ3v/nN1vmNjY2Ew+1vsoqKCioqKrpcx+uvv56UWkVE4mVcD90Ixo7dm1Oyvssvv5yZM2dy1FFH8e1vf5u33nqLY445hqlTp3LssceybNkyAF588UU+//nPA8GHwZVXXsn06dMZN24ct912W+vyioqKWttPnz6d888/n4kTJ3LJJZe0fkg9/fTTTJw4kWnTpjFr1qzW5YqIdKbX9tB/+OQiFn+4ba/pzU2N5DTtpjm0g5xQ98qfNLw//3LW5G7XUlVVxeuvv04oFGLbtm288sorhMNhnnvuOb773e/yxz/+ca/XLF26lBdeeIHt27czYcIEvv71r++1z/j8+fNZtGgRw4cP57jjjuO1116joqKCq6++mpdffpmxY8dy0UUXdbteEembem2gdyQdO3d88YtfJBQKAVBTU8Nll13GBx98gJnR0NDQ7mvOPPNM8vLyyMvLY8iQIXz88ceMHDmyTZsjjzyydVp5eTmrV6+mqKiIcePGte5fftFFF3H33Xf34E8nItmiy0A3swnAIzGTxgE/cPdfxrQxgquinwHsBC5397f3p7COetJ1O7eRt3UFO4pGU9R/4P6sImGFhYWtj7///e8zY8YMHnvsMVavXs306dPbfU1eXl7r41AoRGNj4z61ERFJVJdj6O6+zN3L3b0cmEYQ2I/FNTsdODh6uwq4K8l1tmrd/zpNF7euqalhxIgRAPz6179O+vInTJjAypUrWb16NQCPPPJI5y8QEYnq7peiJwEr3D3+fLxnAw96YC5QambDklJhHOvBvVwS8e1vf5vvfOc7TJ06tUd61P369ePOO+/ktNNOY9q0aRQXF1NSUpL09YhI9rHuBKOZ3Q+87e63x03/M/ATd381+vx54EZ3r4xrdxVBD55Ro0ZNW7Om7efCkiVLOOSQQzqtobFuJ+FNy9jebwTFA4YkXHsm2bFjB0VFRbg711xzDQcffDA33HDDXu0S2V4ikl3MbJ67t7uPdMI9dDOLAP8A/M++FuLud7t7hbtXlJW1ewWlLuXkpLeHngr33HMP5eXlTJ48mZqaGq6++up0lyQiGaA7e7mcTtA7/7ideeuBA2Oej4xOS7p0j6Gnwg033NBuj1xEpDPdGUO/CPh9B/OeAC61wNFAjbt/tN/VtaMl0LO5hy4isi8S6qGbWSFwMnB1zLSZAO4+G3iaYJfF5QR7wVyR9EpbtXwGKdBFRGIlFOjuXgsMips2O+axA9ckt7QOtBxYpB66iEgbGXcul5aSNeQiItJWxh36Tw9+Kbpp0yZOOukkADZs2EAoFKJlb5y33nqLSCTS6etffPFFIpFI6ylyZ8+eTUFBAZdeemnSaxURiZd5gU7L6Hnyz7bY1elzu/Liiy9SVFTUGugzZ85Meo0iIh3JvCEXMxxL2Rj6vHnzOPHEE5k2bRqnnnoqH30U7Lxz2223MWnSJKZMmcKFF17I6tWrmT17Nr/4xS8oLy/nlVde4eabb+anP/0pANOnT+fGG2/kyCOPZPz48bzyyisA7Ny5kwsuuIBJkyZx7rnnctRRR1FZWdlhPSIiHem9PfS/3AQbFrY7y+p3UEQIIv26t8wDDoPTf5Jwc3fn2muv5fHHH6esrIxHHnmE733ve9x///385Cc/YdWqVeTl5bF161ZKS0uZOXNmm179888/32Z5jY2NvPXWWzz99NP88Ic/5LnnnuPOO+9kwIABLF68mPfee4/y8vLu/UwiIlG9N9B7gbq6Ot577z1OPvlkAJqamhg2LDhFzZQpU7jkkks455xzOOeccxJa3nnnnQfAtGnTWk++9eqrr3LdddcBcOihhzJlypTk/hAi0mf03kDvpCfd9OG71FohJcMO6tES3J3Jkyfzxhtv7DXvqaee4uWXX+bJJ5/kxz/+MQsXtv/fRKyW0+XqVLki0hMybwwdCHZG7/kx9Ly8PKqrq1sDvaGhgUWLFtHc3My6deuYMWMGt9xyCzU1NezYsYPi4mK2b9/erXUcd9xx/OEPfwBg8eLFCX0wiIi0p/f20DvhlpovRXNycpgzZw6zZs2ipqaGxsZGrr/+esaPH8+Xv/xlampqcHdmzZpFaWkpZ511Fueffz6PP/44v/rVrxJaxze+8Q0uu+wyJk2axMSJE5k8ebJOlysi+6Rbp89NpoqKCo/fmyPR08E2fLSIXZ5L/+Hje6q8lGlqaqKhoYH8/HxWrFjB5z73OZYtW9blPu+g0+eK9EWdnT43I3voqRpySYWdO3cyY8YMGhoacHfuvPPOhMJcRCReRga6m2HJP64oLYqLi7XfuYgkRa/7UjSxIaCgh96Xz+fSl392EWlfrwr0/Px8Nm3a1HVYmWF4lgy6dJ+7s2nTJvLz89Ndioj0Ir1qyGXkyJFUVVVRXV3dabvGbR/T1NxMbo2T03Kyrj4mPz+fkSNHprsMEelFelWg5+bmMnbs2C7brb/9m1Rv/JCyb73BkGL1UkVEoJcNuSTKQrlEaGJXfVO6SxER6TUyM9DDEcI0slOBLiLSKiMDPSecS64CXUSkjYQC3cxKzWyOmS01syVmdkzc/BIze9LM3jGzRWbWgxeJhpxwHrmmIRcRkViJfil6K/CMu59vZhGgIG7+NcBidz/LzMqAZWb2kLvXJ7PYFqFoD722XmcsFBFp0WWgm1kJcAJwOUA0pOOD2oFiMzOgCNgM9FjahnLzgEb10EVEYiQy5DIWqAYeMLP5ZnavmRXGtbkdOAT4EFgIXOfuex2cb2ZXmVmlmVV2ta95Z8K5EcI0aQxdRCRGIoEeBo4A7nL3qUAtcFNcm1OBBcBwoBy43cz6xy/I3e929wp3rygrK9vnosO5eURoZKeGXEREWiUS6FVAlbu/GX0+hyDgY10BPOqB5cAqYGLyymwrHMkjrP3QRUTa6DLQ3X0DsM7MJkQnnQQsjmu2NjodMxsKTABWJrHONkLhCGFrprauoadWISKScRLdy+Va4KHoHi4rgSvMbCaAu88GfgT82swWEpwK8UZ3/6QnCgYglAtAfd3uHluFiEimSSjQ3X0BEH+FjNkx8z8ETkleWV3IaQn0upStUkSkt8vII0UJBVf0qWtQoIuItMjQQA/+sWhQD11EpFWGBnrQQ29QD11EpFVmBnp0DL2hXoEuItIiMwM9updLg/ZyERFpldGBXq8euohIqwwN9OheLvpSVESkVWYGenQMvbmxnvrGvc4BJiLSJ2VmoIeDHnrEGtm+W4f/i4hApgZ6KA+ACA1s260zLoqIQKYGejgI9Dwa2LZLPXQREcjwQI/QyDYNuYiIABkf6A1s26UhFxERyNRAj46h51mDeugiIlGZGejhfKClh65AFxGBjA30YLfFfqYxdBGRFhka6EEPvTi3iRr10EVEgEwN9JwwYJTkNrO5tj7d1YiI9AoJBbqZlZrZHDNbamZLzOyYdtpMN7MFZrbIzF5KfqltVgbhPEpym/lkuwJdRAQSv0j0rcAz7n5+9ELRBbEzzawUuBM4zd3XmtmQ5JbZjnAexbnNVO/QCbpERCCBQDezEuAE4HIAd68H4rvFFwOPuvvaaJuNyS2zHaE8isNNVG9RoIuIQGJDLmOBauABM5tvZveaWWFcm/HAADN70czmmdml7S3IzK4ys0ozq6yurt6/ysP5FIaa2FHXyK76pv1blohIFkgk0MPAEcBd7j4VqAVuaqfNNOBM4FTg+2Y2Pn5B7n63u1e4e0VZWdn+VR6OUJgTHCX6iYZdREQSCvQqoMrd34w+n0MQ8PFt/urute7+CfAycHjyymxHOJ9+OUHPXOPoIiIJBLq7bwDWmdmE6KSTgMVxzR4HjjezsJkVAEcBS5JaabxQhHwL9kGv3q5AFxFJdC+Xa4GHonu4rASuMLOZAO4+292XmNkzwLtAM3Cvu7/XIxW3COeT58GQy4dbd/XoqkREMkFCge7uC4CKuMmz49r8J/CfySkrAeEIuQ27KIiEWLNpZ8pWKyLSW2XmkaIA4XyscTejBxWydrMCXUQkcwM9FIHGekYPLGDNptp0VyMiknaZG+jhfGjczehBBazbsovmZk93RSIiaZXBgR6BpnpGDyqkvrGZ9fpiVET6uMwN9FAeNO7mkGHFACz6cFuaCxIRSa/MDfRwPjTWc8iw/oRzjIXrt6a7IhGRtMrgQI9A427yc0McPLSYhevVQxeRvi2DAz0fmhuguZnyA0uYv3YLjU3N6a5KRCRtMjfQQ8F1RWmq5/hPlbF9dyML1m1Na0kiIumUuYEeva4ojbs5/uDBhHKMF5ft5yl5RUQyWAYH+p4eekm/XI4aO5DH31mv/dFFpM/K4EDf00MH+NKnD2Td5l28sXJTGosSEUmfLAj04NS5p04+gNKCXO59ZWUaixIRSZ/MDfTcfsF9Q3BirvzcEF/7zDheWFbNvDVb0liYiEh6ZHCgFwT39XvOtHj5sWMYXBTh355aTJPG0kWkj8n8QG/Yc6bFwrww3zvzEOav3cpv565JU2EiIumRuYEeaQn0tiflOqd8BCeML+M/nlnKWl34QkT6kMwN9HaGXADMjH8/91BycoxrH55Pg44eFZE+IvMDvWHvXvjIAQXc8oUpvLNuKz99dlmKCxMRSY+EAt3MSs1sjpktNbMlZnZMB+0+bWaNZnZ+cstsR6TjQAc447BhXHLUKP7rpZW8sHRjj5cjIpJuifbQbwWecfeJwOHAkvgGZhYCbgGeTV55neikh97i+5+fxKRh/Zn18HxWVu9ISVkiIunSZaCbWQlwAnAfgLvXu/vWdppeC/wRSE13OJQLObl7jaHHys8N8V9fmUZuKIerfjOP7bsbUlKaiEg6JNJDHwtUAw+Y2Xwzu9fMCmMbmNkI4Fzgrs4WZGZXmVmlmVVWVyfhRFq5BZ320AEOHFjA7RdPZdUntdzwyAKd60VEslYigR4GjgDucvepQC1wU1ybXwI3ununu5S4+93uXuHuFWVlZftSb1uRrgMd4NiDBvN/zzyE55Zs5Gd/05ekIpKdwgm0qQKq3P3N6PM57B3oFcDDZgYwGDjDzBrd/U/JKrRduQWdDrnEuvzYMSzbsJ07XljByAEFXHTkqB4tTUQk1boMdHffYGbrzGyCuy8DTgIWx7UZ2/LYzH4N/LnHwxyiQy67um5HsH/6j845lA3bdvN///QeQ/vn8dmJQ3u4QBGR1El0L5drgYfM7F2gHPh3M5tpZjN7rLJERAraHPrfldxQDndcfASHDCvmmofm827V1p6rTUQkxRIKdHdfEB37nuLu57j7Fnef7e6z22l7ubvPSX6p7cjtl/CQS4vCvDD3X/5pBhVFuOKBv7N8o3ZnFJHskLlHigLkFiY85BJrSHE+D155JGbGJffOZc2mxHv5IiK9VWYHejeHXGKNKyviof9zFPWNzVx8z5us39r9DwYRkd4kswN9H4ZcYk04oJjffPUotu1u4OJ75vJRjUJdRDJXZgd6Xn+o275fizh0RAkPXnkkm3bU88XZb2j4RUQyVuYHekMtNDXu12KmjhrA7752FLV1jXxx9hu8//H+fUiIiKRDZgd6fv/gvm7bfi9qyshSHrk6OInkBf/1Bu+s27rfyxQRSaXMDvS85AU6wPihxfzPzGMoygtz4d1zeXbRhqQsV0QkFTI70Ft66LuTE+gAowcV8ug3jmX80CKu/u087nt1Fe46oZeI9H6ZHehJ7qG3GFKcz8NXHcMpk4byoz8v5gePL9Kl7ESk18vsQO+BHnqLfpEQd10yjatOGMdv5q7hknveZOO23Ulfj4hIsmR2oPdQD71FTo7x3TMO4ZdfKmfh+hrOuO1V3ly5qUfWJSKyvzI70PNLgvvdNT26mnOmjuBP1xxH//wwF9/7JrNfWqELZYhIr5PZgZ7Xc0Mu8SYcUMzj/3gcp04eyk/+spSL752r0wWISK+S2YEejgQn6Nq1JSWrK87P5Y6Lj+A/zp/CwqoaTvvly/xp/nrtBSMivUJmBzpA4SDY+UnKVmdmXFBxIH+57gQmDC3m+kcW8PXfvs2GGn1hKiLplfmBXjAYalMX6C1GDSrgkauP4cbTJvLCso187ucv8d+vr6ZJY+sikiaZH+iFZVBbnZZVh3KMr08/iGdvOIGpo0r5lycWcd6dr7FApw0QkTTIgkAfDDvTuyvh6EGFPHjlkdx6YTnrt+7mnDteY9bv57Nu876f2ldEpLsSCnQzKzWzOWa21MyWmNkxcfMvMbN3zWyhmb1uZof3TLntKIwOuaT5i0kz4+zyEbz4ren844xP8ddFGzjp5y/x/55ewpba+rTWJiJ9Q6I99FuBZ9x9InA4sCRu/irgRHc/DPgRcHfySuxCwWBoqtvv86InS1FemG+eOoEXvzWds6YM5+5XVnL8Lf/LLc8sZdOOunSXJyJZrMtAN7MS4ATgPgB3r3f3rbFt3P11d2/Zd3AuMDLJdXasaEhwv2NjylaZiGEl/fjZBYfz1+tP4LOHDGX2Sys4/pYX+PFTi/lQ+6+LSA9IpIc+FqgGHjCz+WZ2r5kVdtL+q8Bf2pthZleZWaWZVVZXJ+mLzJLoZ0fNuuQsL8nGDy3mVxdN5W83nMhphx7Afa+u4jP/8QLX/O5t5q3ZrH3YRSRpEgn0MHAEcJe7TwVqgZvaa2hmMwgC/cb25rv73e5e4e4VZWVl+1hynJIDg/teGugtPjWkiF98qZyXvjWDK48bw8vvV/OFu97g7Dte4/dvrWXb7oZ0lygiGS6RQK8Cqtz9zejzOQQB34aZTQHuBc5299TtdtJ/OFgObF2bslXujwMHFvC9Mycx9zsn8aOzJ7OrvonvPLqQT//bc1z38Hxe+aBa+7KLyD4Jd9XA3TeY2Tozm+Duy4CTgMWxbcxsFPAo8BV3f79nSu1AKBeKh8PW3t1Dj1eYF+Yrx4zhy0eP5t2qGubMq+LxBet5fMGHlBXncerkoZx+6DCOGjuQcCjz9y4VkZ5niYzhmlk5Qe87AqwErgC+BODus83sXuALwJroSxrdvaKzZVZUVHhlZeW+Vx7rgTOguRG++mxylpcmuxuaeG7Jxzz17ke8uKyaXQ1NDCjI5eRJQ5k+YQjHHTSYkoLcdJcpImlkZvM6yteEAr0nJDXQn/pnePcPcNNaMEvOMtNsV30TL71fzTPvfcTzSzayva6RHIPyA0v5zMFlnDB+MIeNKCUSVu9dpC/pLNC7HHLJCEMmBRe5qFkHpaPSXU1S9IuEOO3QAzjt0ANoaGrmnXVbefn9al7+4BNu+98PuPX5D8jPzeHwkaVUjBlAxeiBHDFqgHrwIn1YdgT60EOD+w3vZU2gx8oN5VAxZiAVYwbyT6dMYOvOet5YsYm/r97CvDWbmf3SSpqaV2AGYwcXMnl4CZOH94/eShhYGEn3jyAiKZAdgT5sCoQisOY1mHhGuqvpcaUFEU4/bBinHzYMgJ31jSxYt5XK1VtYuL6Gt9ds4cl3PmxtP6wkn08NKeKgsiIOGlLEQYMLOWhIEUOK87AsGaISkWwJ9Nx+cOBRsOqldFeSFgWRMMceNJhjDxrcOm1LbT2LP9rG4g+3sfijbSzfuIM/VK5jZ31Ta5uivDCjBhYwYkA/RpT2Y2TrfTBtQEGuAl8kg2RHoAN86nPw3L/AphUw6KB0V5N2AwojHPepwRz3qT0h7+58vK2OFdU7WFm9gxXVtazdvJO1m3by+vJPqI0Je4BIKIey4jwGF0UoK84LbkV5rY9LCyKU9MulpF8upQW59MsN6QNAJI2yJ9CnfAme/yHM/w187uZ0V9MrmRkHlORzQEl+m6CHIOxrdjVQtWUX67fuomrLLqq31wW3HXWs37qbBetq2FRb1+GJLXND1hrwJf1y6d8vl8K8MIWREAWRMAWREIV50ftImIK86H0kRL9IiLxwiEg4h7xwDpHoLS+cQySUow8KkQRkT6D3HwYTPw9v3QtHXwNFSTq1QB9hZpQWRCgtiHDoiJIO2zU2NbN5Zz3V2+uo2dnA1l0N1MTctu5sYFv08ebaetZt3snO+iZq6xqprW/a56NgI6F2gj6cQygnh3COEcqxPfchI5STQ27c873a5QTTzSDHIMcMovctzy26bXLMWttZ6+OgnbHneex0YpbTXru22z/uOdbhvLavazvT2sxLfJnxq2g73zqct/frrJN5idUW/+Js/CgfNbCAcWVFSV9u9gQ6wEk/gGVPw99+AOfele5qslI4lMOQ4nyGFOd3+7XuTn1TMzvrmqitb2RnfVNwi4Z9fWMz9U1N1DU0U9/UTH1jM3XRW/A42iZmWpM7Tc1OY7PT1NxMQ5Ozu6GZxuYmmpqbaWwK5u9p4zQ2N7c+b2xy3B0Hmt1pdsBbHkefiyTZzBMP4qbTJyZ9udkV6IMPhmNnwas/h8MvhHEnprsiiWFm5IWDoZUBGbQrpbvj0ZBvCX53Wqe1TPfmtm2a3aMfDjHtoo/bLj9ufXHr7njeXpUmuMz4eR3X01nbzo5J7M7r4hcT+zNn6+fpkOK8HlludgU6wInfhkWPwZ+vh6+/HuwBI7IfWodYsvKff8km2XfceG4/OOuXsHklvPyf6a5GRCRlsi/QAcZNh8MvhtduDY4eFRHpA7Iz0AFO/THkl8CT10FzU9ftRUQyXPYGesFAOO0nsL4S/n5fuqsREelx2RvoAId9EQ76bHDAUU1VuqsREelR2R3oZnDmz4Mhl6e/1fl+ViIiGS67Ax1g4FiY8Z3ggKMlT6a7GhGRHpP9gQ7BqQAOOCzope/amu5qRER6RN8I9FAYzroNajcGZ2QUEclCCQW6mZWa2RwzW2pmS8zsmLj5Zma3mdlyM3vXzI7omXL3w4gj4OhvwLxfw+pX012NiEjSJdpDvxV4xt0nAocDS+Lmnw4cHL1dBfTOM2PN+C6UjoYnZkHDrnRXIyKSVF0GupmVACcA9wG4e727b41rdjbwoAfmAqVmNizZxe63SCGcdStsXgEv3ZLuakREkiqRHvpYoBp4wMzmm9m9ZlYY12YEsC7meVV0WhtmdpWZVZpZZXV19T4XvV8OmgHlX4bXboP189JTg4hID0gk0MPAEcBd7j4VqAVu2peVufvd7l7h7hVlZWm8AMWpP4aiofDY1zX0IiJZI5FArwKq3P3N6PM5BAEfaz1wYMzzkdFpvVO/Ujj7dvhkGfzvv6W7GhGRpOgy0N19A7DOzCZEJ50ELI5r9gRwaXRvl6OBGnf/KLmlJtmnToKKK+GNO2DNG+muRkRkvyW6l8u1wENm9i5QDvy7mc00s5nR+U8DK4HlwD3AN5JdaI84+UdQOgr+NBN2b0t3NSIi+8XiL3GVKhUVFV5ZWZmWdbexdi48cDocej6cd3fnV+QVEUkzM5vn7hXtzesbR4p2ZtTRcOJNsPAP8M7D6a5GRGSfKdABTvgmjD4envpn+GR5uqsREdknCnSAnFAw3BKOwJwroLEu3RWJiHSbAr1FyQg4+07Y8C4898N0VyMi0m0K9FgTz4Ajr4a5d+jc6SKScRTo8U7+VxgxDR6bCRuXprsaEZGEKdDj5ebDBb+B3H7w8MW6IIaIZAwFentKRsAFD8LWNfDH/wNNjemuSESkSwr0jow+Fs74KSz/Gzxzky4wLSK9XjjdBfRqFVfApuXwxu0w6CA4+uvprkhEpEMK9K6c/K+wZTU8853gakcTz0h3RSIi7dKQS1daDjoaPjU46GjVK+muSESkXQr0REQK4ZI5MGAM/P5CqNKVjkSk91GgJ6pwEHzlT1A4GH57Hny8KN0ViYi0oUDvjv7D4NLHg33UHzwHNq1Id0UiIq0U6N01YEwQ6t4ED54NW9d1+RIRkVRQoO+LsgnwlceCqxz991kKdRHpFRTo+2rY4fDlP8LOzcEVjzT8IiJpllCgm9lqM1toZgvMbK/rxplZiZk9aWbvmNkiM7si+aX2Qgd+Gi57Aupr4YEz4KN30l2RiPRh3emhz3D38g6uZXcNsNjdDwemAz8zs0gyCuz1hpfDFU9DThjuPx2W/SXdFYlIH5WsIRcHis3MgCJgM9B3zmg15BD42vMw+GD4/UUw9y6d+0VEUi7RQHfgWTObZ2ZXtTP/duAQ4ENgIXCduzfHNzKzq8ys0swqq6ur97noXqn4gKCnPvHM4GReT39LZ2kUkZRKNNCPd/cjgNOBa8zshLj5pwILgOFAOXC7mfWPX4i73+3uFe5eUVZWtu9V91aRwuBc6sfOgr/fExyAtP3jdFclIn1EQoHu7uuj9xuBx4Aj45pcATzqgeXAKmBiMgvNGDk5cMqP4Ow7YN1bMPs4WP5cuqsSkT6gy0A3s0IzK255DJwCvBfXbC1wUrTNUGACsDK5pWaYqV+Gq16EwjL47Rfg2e9DY326qxKRLJZID30o8KqZvQO8BTzl7s+Y2Uwzmxlt8yPgWDNbCDwP3Ojun/RMyRlkyET42v9CxZXw+m1w/6mweVW6qxKRLGWepr0xKioqvLJyr13as9fix+GJa4MvSj/7PTjyagjpdPQi0j1mNq+D3cd1pGjKTDobZr4GY46Hv34X7v0sfDg/3VWJSBZRoKdS6YFw8SNw/gOwfQPc89lg98baTemuTESygAI91czg0PPgmreCsfW/3wu3lcOrv4CGXemuTkQymAI9XfqVwpk/g2/MhdHHwXM3w68q4J2HoXmvY7JERLqkQE+3sglw8cNw2Z+DqyE9djXcfSIsfUrBLiLdokDvLcZ+Br72Apx3L9Rtg4cvhjuPhvkPaf91EUmIAr03ycmBKV+Ef5wHX7gPQhF4/BvBGPsbd0DdjnRXKCK9mAK9NwqF4bDzYeYrcMkfYeC4YFfHX0yCP/8TVM3T2RxFZC86sqU3M4ODPxfc1v0d3vovWPAQVN4Hg8dD+cUw5UvQf3i6KxWRXkBHimaa3TWw6E/wzu9h7RtgOTDqWDjkLDjk81AyMt0VikgP6uxIUQV6Jtu0At59BBY/AdVLgmnDj4CDT4GxJ8DIT0O4b1w4SqSvUKD3BZ8sh6VPwpI/w4dvgzdDbgGMOgbGnQhjT4QDpgRfvIpIxlKg9zW7tsDq12DVS7DyJfhkWTC934DgXDJjT4SRFTBksnrwIhmms0DXl6LZqN+AYDz9kM8Hz7dvgFUvB+G+6iVY8mQwPRSBoZODYZrhU+GAQ4MvWyOF6atdRPaZeuh9jTtsXRsMy3w4H9a/DR+9ExzM1KLkwCDYyybsuR94EBQNCfa8EZG0UQ9d9jCDAaOD2+Rzg2nNzbB5BWxcDNXvB0M01ctgzevQGHPCsHA+lI6K3kYH9wNGQ8ko6D8MCofoHO8iaaS/Pgm+KB18cHCL1dwM26qCkN+yCrashq1rgh5+VSXs3hq3IAsuuVc0NDgvTWFZcN9vIBQMCIaC+g2A/BLIK4G8YsgrCr68Vc9fZL8p0KVjOTl7euTt2V0ThHtNFWz7EHZ8HIzX7/gYaj+BzSth5yao7+KUBZYDkZhwjxRAbmEwlh8pgHC/4MvbUB6Eo7dQXsy0mHmhyJ42OeFg2RYK7nOi96EIhHKj83KCD5PWxx3dEmwjkkYJBbqZrQa2A01AY3vjN2Y2HfglkAt84u4nJqtI6aXyS+CAw4JbZxrrgz1vdm2BXZth97bgw6BuWxD2dTugbnvwuL4WGnZC/U7Y+QlsrYWG3dBUB4110FQf3HtTan7G7ooPeSzYhTT2QwGLPrbgcbs6+m4r2r71wyPm9fHT2qwvp4v1JfJztbzWY8rzzk9D0eZDLuaxN8e8NnrfUt9eH4zRbdjc2HayN8W039efax9f11RP63bNCe2psV1x28dCcOTX4IRv7tu6O9GdHvqMji78bGalwJ3Aae6+1syGJKM4yRLhCBQPDW7J0twUDfi64AOjzX3dntBvbgr+0LwpCI2mBmhuCO4hOq+zm+9/G8vZ0651nb4n1DoKo/iwaQ1Oj3ve3rTYsGxZ377uABF9bUuAttbWzuP41+1Ve3R66wcNex631hq3uObm4L/FnPCedhAEI3QSpAn8XPv0Mg/+y4Po71XM+7zXdoj+MC3vZcv7Pnj8PtbcuWQNuVwMPOruawHcfWOSlivSvpxQMBxDQborEek1Ej1s0IFnzWyemV3VzvzxwAAzezHa5tLklSgiIolItId+vLuvjw6l/M3Mlrr7y3HLmQacBPQD3jCzue7+fuxCoh8GVwGMGtXBF20iIrJPEuqhu/v66P1G4DHgyLgmVcBf3b02Os7+MnB4O8u5290r3L2irKxs/yoXEZE2ugx0Mys0s+KWx8ApwHtxzR4HjjezsJkVAEcBS5JdrIiIdCyRIZehwGMWfEsbBn7n7s+Y2UwAd5/t7kvM7BngXaAZuNfd40NfRER6kM7lIiKSQTo7l4tOji0ikiUU6CIiWSJtQy5mVg2s2ceXDwbaPWo1zVRX96iu7umtdUHvrS0b6xrt7u3uJpi2QN8fZlbZ0RhSOqmu7lFd3dNb64LeW1tfq0tDLiIiWUKBLiKSJTI10O9OdwEdUF3do7q6p7fWBb23tj5VV0aOoYuIyN4ytYcuIiJxFOgiIlki4wLdzE4zs2VmttzMbkrxug80sxfMbLGZLTKz66LTbzaz9Wa2IHo7I+Y134nWuszMTu3B2lab2cLo+iuj0waa2d/M7IPo/YDodDOz26J1vWtmR/RQTRNitskCM9tmZtenY3uZ2f1mttHM3ouZ1u3tY2aXRdt/YGaX9VBd/2lmS6Prfix6RTDMbIyZ7YrZbrNjXjMt+v4vj9a+Xxc47aCubr9vyf577aCuR2JqWm1mC6LTU7m9OsqG1P6OuXvG3IAQsAIYB0SAd4BJKVz/MOCI6ONi4H1gEnAz8M122k+K1pgHjI3WHuqh2lYDg+Om/QdwU/TxTcAt0cdnAH8huF7W0cCbKXrvNgCj07G9gBOAI4D39nX7AAOBldH7AdHHA3qgrlOAcPTxLTF1jYltF7ect6K1WrT203ugrm69bz3x99peXXHzfwb8IA3bq6NsSOnvWKb10I8Elrv7SnevBx4Gzk7Vyt39I3d/O/p4O8Epgkd08pKzgYfdvc7dVwHL2ftc8j3pbOC/o4//GzgnZvqDHpgLlJrZsB6u5SRghbt3dnRwj20vDy7Isrmd9XVn+5wK/M3dN7v7FuBvwGnJrsvdn3X3lisizwVGdraMaG393X2uB6nwYMzPkrS6OtHR+5b0v9fO6or2si8Aft/ZMnpoe3WUDSn9Hcu0QB8BrIt5XkXngdpjzGwMMBV4MzrpH6P/Ot3f8m8Vqa23vcsEDnX3j6KPNxCcCjnVdbW4kLZ/aOneXtD97ZOO7XYlQU+uxVgzm29mL5nZZ6LTRkRrSUVd3XnfUr29PgN87O4fxExL+faKy4aU/o5lWqD3CmZWBPwRuN7dtwF3AQcB5cBHBP/2pdrx7n4EcDpwjZmdEDsz2hNJyz6qZhYB/gH4n+ik3rC92kjn9umImX0PaAQeik76CBjl7lOBfwJ+Z2b9U1hSr3vf4lxE205DyrdXO9nQKhW/Y5kW6OuBA2Oej4xOSxkzyyV4wx5y90cB3P1jd29y92bgHvYME6SsXm//MoEftwylRO83prquqNOBt93942iNad9eUd3dPimrz8wuBz4PXBINAqJDGpuij+cRjE+Pj9YQOyzTI3Xtw/uWyu0VBs4DHompN6Xbq71sIMW/Y5kW6H8HDjazsdFe34XAE6laeXSM7j5gibv/PGZ67Pjzuey5RN8TwIVmlmdmY4GDCb6MSXZdHV0m8Amg5VvyywguFdhS16XRb9qPBmpi/i3sCW16TuneXjG6u33+CpxiZgOiww2nRKcllZmdBnwb+Ad33xkzvczMQtHH4wi2z8pobdvM7Ojo7+ilMT9LMuvq7vuWyr/XzwFL3b11KCWV26ujbCDVv2P7881uOm4E3w6/T/Bp+70Ur/t4gn+Z3gUWRG9nAL8BFkanPwEMi3nN96K1LmM/v0nvpK5xBHsQvAMsatkuwCDgeeAD4DlgYHS6AXdE61oIVPTgNisENgElMdNSvr0IPlA+AhoIxiW/ui/bh2BMe3n0dkUP1bWcYBy15XdsdrTtF6Lv7wLgbeCsmOVUEATsCuB2okeBJ7mubr9vyf57ba+u6PRfAzPj2qZye3WUDSn9HdOh/yIiWSLThlxERKQDCnQRkSyhQBcRyRIKdBGRLKFAFxHJEgp0EZEsoUAXEckS/x/1Cv+/KWvGiwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1 = plt.figure(1)\n",
    "x=np.linspace(1,epo,epo)\n",
    "plt.plot(x,train_error, label = 'Training')\n",
    "plt.plot(x,test_error, label ='Testing')\n",
    "plt.legend(loc = 2)\n",
    "plt.title('MAE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e282a0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.619952320605696\n"
     ]
    }
   ],
   "source": [
    "print(np.min(test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f386dc4",
   "metadata": {},
   "source": [
    "# LBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c633ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Xhat_train\n",
    "y = Yhat_train\n",
    "xt = Xhat_test\n",
    "yt = Yhat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1b3aa400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model (x,b0,b1):\n",
    "    # y = b0 +  torch.matmul(x,b1)\n",
    "    y = b0 + b1*x\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "199c2c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training loss 101.4670, Testing loss 6.9203\n",
      "Epoch 1, Training loss 98.0855, Testing loss 6.7712\n",
      "Epoch 2, Training loss 95.7815, Testing loss 6.6602\n",
      "Epoch 3, Training loss 94.1688, Testing loss 6.5749\n",
      "Epoch 4, Training loss 92.9872, Testing loss 6.5067\n",
      "Epoch 5, Training loss 92.0642, Testing loss 6.4486\n",
      "Epoch 6, Training loss 91.3211, Testing loss 6.3988\n",
      "Epoch 7, Training loss 90.6118, Testing loss 6.3500\n",
      "Epoch 8, Training loss 89.7013, Testing loss 6.2907\n",
      "Epoch 9, Training loss 88.2536, Testing loss 6.2088\n",
      "Epoch 10, Training loss 86.3419, Testing loss 6.1253\n",
      "Epoch 20, Training loss 81.4149, Testing loss 6.1263\n",
      "Epoch 30, Training loss 81.2164, Testing loss 6.1363\n",
      "Epoch 40, Training loss 81.2069, Testing loss 6.1354\n",
      "Epoch 50, Training loss 81.2065, Testing loss 6.1355\n",
      "Epoch 60, Training loss 81.2063, Testing loss 6.1356\n",
      "Epoch 70, Training loss 81.2062, Testing loss 6.1357\n",
      "Epoch 80, Training loss 81.2062, Testing loss 6.1357\n",
      "Epoch 90, Training loss 81.2062, Testing loss 6.1357\n",
      "Epoch 100, Training loss 81.2061, Testing loss 6.1358\n",
      "Epoch 110, Training loss 81.2061, Testing loss 6.1358\n",
      "Epoch 120, Training loss 81.2061, Testing loss 6.1358\n",
      "Epoch 130, Training loss 81.2061, Testing loss 6.1359\n",
      "Epoch 140, Training loss 81.2061, Testing loss 6.1359\n",
      "Epoch 150, Training loss 81.2061, Testing loss 6.1359\n",
      "Epoch 160, Training loss 81.2061, Testing loss 6.1360\n",
      "Epoch 170, Training loss 81.2061, Testing loss 6.1360\n",
      "Epoch 180, Training loss 81.2061, Testing loss 6.1361\n",
      "Epoch 190, Training loss 81.2061, Testing loss 6.1361\n",
      "Epoch 191, Training loss 81.2061, Testing loss 6.1361\n",
      "Epoch 192, Training loss 81.2061, Testing loss 6.1361\n",
      "Epoch 193, Training loss 81.2061, Testing loss 6.1361\n",
      "Epoch 194, Training loss 81.2061, Testing loss 6.1361\n",
      "Epoch 195, Training loss 81.2061, Testing loss 6.1361\n",
      "Epoch 196, Training loss 81.2061, Testing loss 6.1361\n",
      "Epoch 197, Training loss 81.2061, Testing loss 6.1361\n",
      "Epoch 198, Training loss 81.2061, Testing loss 6.1361\n",
      "Epoch 199, Training loss 81.2061, Testing loss 6.1361\n",
      "Epoch 200, Training loss 81.2061, Testing loss 6.1361\n"
     ]
    }
   ],
   "source": [
    "features = torch.from_numpy(x)\n",
    "targets = torch.from_numpy(y)\n",
    "x_test = torch.from_numpy(xt)\n",
    "y_test = torch.from_numpy(yt)\n",
    "\n",
    "beta0 = torch.ones(5112 , requires_grad = True)\n",
    "# beta0 = torch.randn([244,6816] , requires_grad = True)\n",
    "beta1 = torch.ones(5112 , requires_grad = True)\n",
    "\n",
    "rate = 1e-2\n",
    "optimizer = optim.LBFGS([beta0 , beta1] , lr = rate)\n",
    "\n",
    "epo = 201\n",
    "loss = nn.MSELoss()\n",
    "train_error = np.zeros(epo)\n",
    "test_error = np.zeros(epo)\n",
    "\n",
    "\n",
    "for epoch in range (epo):\n",
    "    # yhats_train = model(features.float() , beta0 , beta1)\n",
    "    # train_loss = loss(targets.float() , yhats_train)\n",
    "    # train_error[epoch] = train_loss\n",
    "\n",
    "    # optimizer.zero_grad()\n",
    "    # if epoch == 0 :\n",
    "    #         train_loss.backward(retain_graph=True) \n",
    "    # else :\n",
    "    #     train_loss.backward()\n",
    "    # # train_loss.backward() \n",
    "    # optimizer.step()    \n",
    "\n",
    "    def closure():\n",
    "        yhats_train = model(features.float() , beta0 , beta1)\n",
    "        train_loss = loss(targets.float() , yhats_train)\n",
    "        train_error[epoch] = train_loss\n",
    "        optimizer.zero_grad()\n",
    "        # if epoch == 0 :\n",
    "        #     train_loss.backward(retain_graph=True) \n",
    "        # else :\n",
    "        #     train_loss.backward()\n",
    "        train_loss.backward(retain_graph=True) \n",
    "        return train_loss\n",
    "    optimizer.step(closure)    \n",
    "\n",
    "    yhats_test = model(x_test.float(), beta0, beta1) \n",
    "#     for i in range (30):\n",
    "#         for j in range (6816):\n",
    "#             if y_test[i][j] == 0:\n",
    "#                 yhats_test[i][j] = 0\n",
    "    r = torch.abs(yhats_test - y_test)\n",
    "    test_loss = torch.nanmean(r)\n",
    "    test_error[epoch] = test_loss\n",
    "\n",
    "    if epoch <= 10 or epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Training loss {train_error[epoch]:.4f},\"\n",
    "                    f\" Testing loss {test_error[epoch]:.4f}\")\n",
    "        # print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\n",
    "        #             f\" Testing loss {test_loss:.4f}\")\n",
    "        # print('\\tBeta_0 : ' , beta0.grad)\n",
    "        # print('\\tBeta_1 : ' , beta1.grad)\n",
    "    else :\n",
    "        if epoch >= epo-10 :\n",
    "            print(f\"Epoch {epoch}, Training loss {train_error[epoch]:.4f},\"\n",
    "                    f\" Testing loss {test_error[epoch]:.4f}\")\n",
    "            # print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\n",
    "            #             f\" Testing loss {test_loss:.4f}\")\n",
    "            # print('\\tBeta_0 : ' , beta0)\n",
    "            # print('\\tBeta_1 : ' , beta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a09ee7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1 = plt.figure(1)\n",
    "x=np.linspace(1,epo,epo)\n",
    "plt.plot(x,train_error, label = 'Training')\n",
    "plt.plot(x,test_error, label ='Testing')\n",
    "plt.legend(loc = 2)\n",
    "plt.title('MAE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4559b4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.061861967280766\n"
     ]
    }
   ],
   "source": [
    "print(np.min(test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d74c2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chou",
   "language": "python",
   "name": "chou"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
